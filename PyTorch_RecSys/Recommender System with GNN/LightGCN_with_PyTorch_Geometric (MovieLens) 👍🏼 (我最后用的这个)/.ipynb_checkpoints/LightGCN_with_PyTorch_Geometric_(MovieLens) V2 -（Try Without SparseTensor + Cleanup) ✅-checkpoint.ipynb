{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2055ad4c",
   "metadata": {},
   "source": [
    "另外一个 LightGCN MovieLens 的 [notebook] (http://localhost:8888/notebooks/PyTorch_RecSys/LightGCN_for_Movie_Rec%20/LightGCN%20for%20Movie%20Recommendation%20by%20Quinn%20Wang.ipynb) 看的实在是太 struggle 了，而且 recall 非常低，肯定是哪里没写对，我一步步 debug ，不如先看一下这个，我突然找到这个也是 Stanford 224W 的，也是 LightGCN， 也是 Movie Lens\n",
    "\n",
    "- Blog: https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e\n",
    "- Code: https://colab.research.google.com/drive/1KKugoFyUdydYC0XRyddcROzfQdMwDcnO?usp=sharing\n",
    "\n",
    "\n",
    "突然发现这个内容好像似曾相识啊.. 难道我很早以前就看过?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d3eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4f076e5",
   "metadata": {},
   "source": [
    "这个 Notebook 是尝试不用 SparseTensor 来写，因为我没有 GPU\n",
    "- 参考这里的 https://colab.research.google.com/drive/1VQTBxJuty7aLMepjEYE-d7E9kjo51CA1?usp=sharing#scrollTo=-aTMoHisNIh_  LightGCNConv 的部分写法\n",
    "- original blog: https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377\n",
    "\n",
    "\n",
    "Result: \n",
    "- training: [train_loss: -1530.55237, val_loss: -1171.65869, val_recall@20: 0.21551, val_precision@20: 0.03761, val_ndcg@20: 0.13316]\n",
    "- [test_loss: -1166.86792, test_recall@20: 0.21978, test_precision@20: 0.03853, test_ndcg@20: 0.13844\n",
    "\n",
    "效果不错呀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ea269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51add8c9",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f2afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import copy\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5bbd8",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b6bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "# Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movie_path = './ml-latest-small/movies.csv'\n",
    "rating_path = './ml-latest-small/ratings.csv'\n",
    "user_path = './ml-latest-small/users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c20490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load user and movie nodes\n",
    "# def load_node_csv(path, index_col):\n",
    "#     \"\"\"Loads csv containing node information\n",
    "\n",
    "#     Args:\n",
    "#         path (str): path to csv file\n",
    "#         index_col (str): column name of index column\n",
    "\n",
    "#     Returns:\n",
    "#         dict: mapping of csv row to node id\n",
    "#     \"\"\"\n",
    "#     df = pd.read_csv(path, index_col=index_col)\n",
    "#     mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "#     return mapping\n",
    "\n",
    "# # 诶这两只是 dictionary? 所以其实跟另一个一样，也是 label encoder 的 manual 写法, \n",
    "# user_mapping = load_node_csv(rating_path, index_col='userId') # 这里其实直接传 user_path 其实也行\n",
    "# movie_mapping = load_node_csv(movie_path, index_col='movieId')\n",
    "\n",
    "\n",
    "# new way\n",
    "\n",
    "rating_df = pd.read_csv(rating_path)\n",
    "\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
    "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5527b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "9723\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.userId.max())\n",
    "print(rating_df.movieId.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e6b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ new -----\n",
    "# load edges between users and movies\n",
    "def load_edge_csv(df, \n",
    "                  src_index_col, \n",
    "                  dst_index_col, \n",
    "                  link_index_col, \n",
    "                  rating_threshold=3):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        path (str): path to csv file\n",
    "        src_index_col (str): column name of users\n",
    "        src_mapping (dict): mapping between row number and user id\n",
    "        dst_index_col (str): column name of items\n",
    "        dst_mapping (dict): mapping between row number and item id\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: 2 by N matrix containing the node ids of N user-item edges\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_index = None\n",
    "    src = [user_id for user_id in  df['userId']]\n",
    "    \n",
    "    num_users = len(df['userId'].unique())\n",
    "    \n",
    "    # dst 全部 offset by num_users ，因为是 bipartite graph\n",
    "#     dst = [(movie_id + num_users) for movie_id in df['movieId']]\n",
    "    # 改回来\n",
    "    dst = [(movie_id) for movie_id in df['movieId']]\n",
    "\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "\n",
    "    # 这里就是把 上面的 src list (user), dst list (item), edge_attr(boolean), 转成 PyG Edge_index 需要的COO 格式\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "    return edge_index\n",
    "\n",
    "# 这里 print 出来之后，直接就是 COO 格式了!! 即 2 x num_edge_pair. 就是 pyG tutorial 的第一个tutorial 里面的\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a1fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edge_index = load_edge_csv(\n",
    "    rating_df,\n",
    "    src_index_col='userId',\n",
    "    dst_index_col='movieId',\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc37da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 都转成 tensor\n",
    "edge_index = torch.LongTensor(edge_index) # 如果不是 SparseTensor， 那么.propagate 需要 longTensor\n",
    "# bidirectiona_edge_index = torch.tensor(bidirectiona_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c7ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9444, 9445, 9485]])\n"
     ]
    }
   ],
   "source": [
    "# 牛逼，这里 print 出来之后，直接就是 COO 格式了!!\n",
    "# Q: 但是这里感觉有个问题... 这里是 bipartite graph， 我如果直接 COO 这样写， user_id = 0 盒 item_id = 0 会被当成同一个 node.?\n",
    "# ?? 有没有可能哪里暗示了是 bipartite graph\n",
    "\n",
    "# 还真是不太对， 怎么会出现 这么大的数\n",
    "# 这下就对了，我上面弄的没有用 encoded 的 rating_df 穿进去，而是重新读了，那么不是 label encoded 确实是会有问题\n",
    "\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c38603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "# num_users, num_movies = len(user_mapping), len(movie_mapping)\n",
    "\n",
    "num_users = len(rating_df['userId'].unique())\n",
    "num_movies = len(rating_df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13f7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bipartate_edge_index_to_edge_index(input_edge_index):\n",
    "    R = torch.zeros((num_users, num_movies))\n",
    "    for i in range(len(input_edge_index[0])):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
    "    adj_mat[: num_users, num_users :] = R.clone()\n",
    "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4845855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
      "torch.Size([2, 99466])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)\n",
    "print(edge_index.size())\n",
    "# bipartate_edge_index = convert_bipartate_edge_index_to_edge_index(edge_index)\n",
    "# print(bipartate_edge_index.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e70928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users 610, num_movies 9724, num_interactions 99466\n"
     ]
    }
   ],
   "source": [
    "# 这里其实是算的  4 分以上的 interaction\n",
    "num_interactions = edge_index.shape[1]\n",
    "print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74cb5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(all_indices, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=1)\n",
    "\n",
    "# 诶，原来 validation 是从test set 里面再 split 出来，我一直以为是从给training set\n",
    "val_indices, test_indices = train_test_split(test_indices, \n",
    "                                             test_size=0.5, \n",
    "                                             random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1aa6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里就是拿到 edge pair index 其实还是 tensor, \n",
    "# 所以这里其实就是 把 edge_index 拆成 training set, validation set, test set... \n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc7e5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_edge_index tensor([[ 239,  102,  225,  ...,   34,  488,  609],\n",
      "        [ 274, 9006,  792,  ...,  260, 1486, 3867]])\n",
      "10334\n",
      "torch.Size([610])\n",
      "torch.Size([9628])\n",
      "tensor(0)\n",
      "tensor(9723)\n",
      "tensor(9723)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_edge_index {train_edge_index}\")\n",
    "print((num_users + num_movies))\n",
    "print(torch.unique(edge_index[0]).size())\n",
    "print(torch.unique(edge_index[1]).size())\n",
    "print(train_edge_index.min())\n",
    "print(train_edge_index.max())\n",
    "print(edge_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e41ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里得把上面的转成 bipartite\n",
    "train_edge_index = convert_bipartate_edge_index_to_edge_index(train_edge_index)\n",
    "val_edge_index = convert_bipartate_edge_index_to_edge_index(val_edge_index)\n",
    "test_edge_index = convert_bipartate_edge_index_to_edge_index(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ced999a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 10331, 10332, 10333],\n",
      "        [  610,   615,   653,  ...,   183,   183,   330]])\n",
      "torch.Size([2, 159144])\n",
      "tensor([[    0,     0,     0,  ..., 10312, 10316, 10327],\n",
      "        [  612,   699,   924,  ...,   247,    49,   183]])\n",
      "torch.Size([2, 19894])\n",
      "tensor([[    0,     0,     0,  ..., 10302, 10307, 10310],\n",
      "        [  656,   734,   746,  ...,   513,   211,   337]])\n",
      "torch.Size([2, 19894])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.size())\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.size())\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbaf5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5d15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5adb1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "# 这里为啥？？\"In PyG >= 1.6.0, we officially introduce better support for sparse-matrix multiplication GNNs, resulting in a lower memory footprint and a faster execution time\"\n",
    "\n",
    "\n",
    "# 这里崩了?? 这是为啥？？\n",
    "# 难道是因为这里其实才是对 bipartate graph 的处理？？ 你看 sparse size 是 num_users + num_movies\n",
    "# 我如果不用呢？\n",
    "\n",
    "# 这里为啥过不来???\n",
    "# 是不是不能用 num_users + num_movies 了，因为我已经处理了 bipartite?? 那应该用啥？\n",
    "# 难道是 row, col 的 index 超出范围了? (num_users + num_movies) = 10334\n",
    "# Solved: load_edge_csv 有个小 bug， 没有用 label encoded 的 id, \n",
    "# train_sparse_edge_index = SparseTensor(row=train_edge_index[0], \n",
    "#                                        col=train_edge_index[1], \n",
    "#                                        sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
    "\n",
    "# val_sparse_edge_index = SparseTensor(row=val_edge_index[0], \n",
    "#                                      col=val_edge_index[1], \n",
    "#                                      sparse_sizes=(num_users + num_movies, num_users + num_movies))\n",
    "\n",
    "# test_sparse_edge_index = SparseTensor(row=test_edge_index[0], \n",
    "#                                       col=test_edge_index[1], \n",
    "#                                       sparse_sizes=(num_users + num_movies, num_users + num_movies))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31f3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_sparse_edge_index.to_torch_sparse_coo_tensor())\n",
    "# print(train_sparse_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8a112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which random samples a mini-batch of positive and negative samples\n",
    "# 因为我 edge_index 改成 bidirection 了，我这里其实是要改一下的，因为不再是 src 全是 user, dst 全是 target 了\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    # structured_negative_sampling(...) 这个是一个 pyG library\n",
    "    # Samples a negative edge :obj:`(i,k)` for every positive edge\n",
    "    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n",
    "    # tuple of the form :obj:`(i,j,k)`.\n",
    "    # 看上面的 print, 其实还是 coo 类似的格式\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    \n",
    "    # 变成 3 x num_edge_pair  的格式， 然后 row0, row1 是 positive, row0, row2 是 negative?\n",
    "    # Q: 他这里怎么知道 negative 是从 movie list 里面拿? 我估计 structured_negative_sampling 知道从 \n",
    "    # dest list 里面选，而不是从 src list 里面选\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    \n",
    "    # Return a k sized list of population elements chosen with replacement.\n",
    "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    \n",
    "    batch = edges[:, indices]\n",
    "    \n",
    "    # 上面 batch print 出来知道长啥样，这个就挺 straightforward \n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3688310d",
   "metadata": {},
   "source": [
    "# Implementing LightGCN\n",
    "\n",
    "## Light Graph Convolution\n",
    "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
    "\n",
    "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
    "\n",
    "$e_u^{(k)}$ : k-th layer user embedding\n",
    "\n",
    "$e_i^{(k)}$ : k-th layer item embedding\n",
    "\n",
    "\n",
    "\n",
    "## Layer Combination and Model Prediction\n",
    "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
    "\\end{equation}\n",
    "\n",
    "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}_{ui} = e_u^Te_i\n",
    "\\end{equation}\n",
    "\n",
    "## Matrix Form\n",
    "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
    "\n",
    "\\begin{equation}\n",
    "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
    "\\end{equation}\n",
    "\n",
    "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
    "\n",
    "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
    "\n",
    "\n",
    "\n",
    "__TODO__: 上面这个有点没看懂，得查一下\n",
    "- https://math.stackexchange.com/questions/3035968/interpretation-of-symmetric-normalised-graph-adjacency-matrix\n",
    "- [拉普拉斯矩阵(Laplacian Matrix) 及半正定性证明](https://www.cnblogs.com/shiyublog/p/9785342.html)\n",
    "- 我大概知道了，按陈学长跟我讲的去复习一下，然后先把 RMSE 的方法弄一下，然后回头再看下面这几个资料\n",
    "    - [SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS](https://arxiv.org/pdf/1609.02907.pdf%EF%BC%89)\n",
    "    - [LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation](https://arxiv.org/pdf/2002.02126.pdf) 尤其 formula 7\n",
    "    - https://en.m.wikipedia.org/wiki/Laplacian_matrix\n",
    "    - PyG GCN Norm Doc [link](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.GCNNorm), [source code](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/transforms/gcn_norm.html#GCNNorm)\n",
    "    - PyG 的 LG_CONV (单层的) Light GCN [link](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/lg_conv.html#LGConv)\n",
    "    - PyG 的Light GCN 整个 network [link](https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/models/lightgcn.html)\n",
    "    - Normalized Adjacency and Laplacian Matrices Cornell Slides [link](https://people.orie.cornell.edu/dpw/orie6334/Fall2016/lecture7.pdf)\n",
    "    - [SO]Interpretation of Symmetric Normalised Graph Adjacency Matrix [link](https://math.stackexchange.com/questions/3035968/interpretation-of-symmetric-normalised-graph-adjacency-matrix)\n",
    "- 这个有几个问题，一个是 bipartate graph 的 Adj Matrix 他是不是没有设置好，\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15380345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defines LightGCN model (with SparseTensor Optimization)\n",
    "# class LightGCN(MessagePassing):\n",
    "#     \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "#         \"\"\"Initializes LightGCN Model\n",
    "\n",
    "#         Args:\n",
    "#             num_users (int): Number of users\n",
    "#             num_items (int): Number of items\n",
    "#             embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "#             K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "#             add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.num_users = num_users\n",
    "#         self.num_items = num_items\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.K = K\n",
    "#         self.add_self_loops = add_self_loops\n",
    "\n",
    "#         # 这边 embedding 就参考 我的 Basic NCF 的那个 notebook \n",
    "#         self.users_emb = nn.Embedding(num_embeddings=self.num_users, \n",
    "#                                       embedding_dim=self.embedding_dim) # e_u^0\n",
    "        \n",
    "#         self.items_emb = nn.Embedding(num_embeddings=self.num_items, \n",
    "#                                       embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "#         # 这啥？哦就是 上面两 embedding 的 initialization 方法， 当然，也可以把 feature 放进来作为初始 embeding\n",
    "#         # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
    "#         nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "#         nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "#     def forward(self, edge_index: SparseTensor):\n",
    "#         \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "#         Args:\n",
    "#             edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "#         Returns:\n",
    "#             tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "#         \"\"\"\n",
    "#         # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "#         # TODO: 这个是啥骚操作? 这边得仔细看一下!!! (上面我有做笔记了.)\n",
    "#         # 这里 print 出来之后，长度可能跟 edge_index 不一样了，因为有加 selfloop， 到时候可以验证一下\n",
    "#         edge_index_norm = gcn_norm(edge_index=edge_index, \n",
    "#                                    add_self_loops=self.add_self_loops)\n",
    "\n",
    "#         # 直接 user, item embedding concat 然后套一曾，然后 rename??\n",
    "#         emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "#         # 哦，不是套一层，而是因为 lightGCN 最后从 多跟 emb_k 算出 emb 是直接加， 所以这里建一个 list\n",
    "#         # 你看后面 propagate 多层 LightGCN layer 的时候，一方面 propagate， 一方面每一层我都 append 到 embs 这个list\n",
    "#         embs = [emb_0]\n",
    "#         emb_k = emb_0\n",
    "\n",
    "#         # multi-scale diffusion\n",
    "#         # 这个跟你用几层 LightGCn 有关，一层，你都 \n",
    "#         # 注意这里，咱们是用 emb_k 作为 node  的 feature 了!!!  \n",
    "#         # TODO: 可以思考一下这里要加真正的 node feature 怎么加？直接 concat? 补进去?\n",
    "#         for i in range(self.K):\n",
    "#             # 他着跟这里讲的不太一样呀？“For bipartite graphs with two independent sets of nodes and indices, and each set holding its own information, this split can be marked by passing the information as a tuple, e.g. x=(x_N, x_M)”\n",
    "#             # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html?highlight=bipartate#the-messagepassing-base-class\n",
    "#             emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
    "#             embs.append(emb_k)\n",
    "\n",
    "#         # 这个到时候可以看一下 dim=1 的 stack 长啥样\n",
    "#         # 可以参考这个 https://www.geeksforgeeks.org/python-pytorch-stack-method/\n",
    "#         # 就是比如 [[1,2,3,4], [5,6,7,8]]\n",
    "#         # stack 完变成[ [1,5], [2,6],[3, 7], [4, 8] ]\n",
    "#         embs = torch.stack(embs, dim=1)\n",
    "        \n",
    "#         # 然后这边就是把上面 stack 完的求均值\n",
    "#         # Q: ?? lightGCN 是求均值吗? 不是应该是 weighted sum?? 不过 sum or avg 应该都不影响结果\n",
    "#         # A: 看 paper 里面， 公式里的 a 其实是 1/(K+1) 那本质上就是 avg 了\n",
    "#         emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "#         # 这个比较 straightforward, 我们上面 embedding 不是用 concat 把 user_emb 和 item_emb 给\n",
    "#         # horizontal 连起来吗， 这里跑完 LightGCN layer 之后，我们就可以在 split 拆开左右两边，拿到各种的 embedding\n",
    "#         # 那其实跟 NCF 还是蛮像的.\n",
    "#         users_emb_final, items_emb_final = torch.split(emb_final, \n",
    "#                                                        [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "#         # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "#         return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "#     # 是不是下面这两个我没有看懂？？\n",
    "#     def message(self, x_j: Tensor) -> Tensor:\n",
    "#         return x_j\n",
    "\n",
    "#     # 是不是下面这个我没有看懂？？\n",
    "#     # 这里也解释的不是很清： https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
    "#     def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
    "#         # computes \\tilde{A} @ x\n",
    "#         # adj_t 是 adj transpose\n",
    "#         # matmul 是 dot product\n",
    "#         return matmul(adj_t, x)\n",
    "\n",
    "# # 试一下只用2层\n",
    "# layers = 3    \n",
    "# model = LightGCN(num_users=num_users, \n",
    "#                  num_items=num_movies, \n",
    "#                  K=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8cbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model (without SparseTensor Optimization)\n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # 这边 embedding 就参考 我的 Basic NCF 的那个 notebook \n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, \n",
    "                                      embedding_dim=self.embedding_dim) # e_u^0\n",
    "        \n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, \n",
    "                                      embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        # 这啥？哦就是 上面两 embedding 的 initialization 方法， 当然，也可以把 feature 放进来作为初始 embeding\n",
    "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: Tensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "        # TODO: 这个是啥骚操作? 这边得仔细看一下!!! (上面我有做笔记了.)\n",
    "        # 这里 print 出来之后，长度可能跟 edge_index 不一样了，因为有加 selfloop， 到时候可以验证一下\n",
    "        # 这个是返回  tuple of size 2, pos0 是 原版 edge_index, pos1 是算好的 norm, 1 x num_of_total_nodes\n",
    "        edge_index_norm = gcn_norm(edge_index=edge_index, \n",
    "                                   add_self_loops=self.add_self_loops)\n",
    "\n",
    "        # 直接 user, item embedding concat 然后套一曾，然后 rename??\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        # 哦，不是套一层，而是因为 lightGCN 最后从 多跟 emb_k 算出 emb 是直接加， 所以这里建一个 list\n",
    "        # 你看后面 propagate 多层 LightGCN layer 的时候，一方面 propagate， 一方面每一层我都 append 到 embs 这个list\n",
    "        embs = [emb_0]\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # multi-scale diffusion\n",
    "        # 这个跟你用几层 LightGCn 有关，一层，你都 \n",
    "        # 注意这里，咱们是用 emb_k 作为 node  的 feature 了!!!  \n",
    "        # TODO: 可以思考一下这里要加真正的 node feature 怎么加？直接 concat? 补进去?\n",
    "        for i in range(self.K):\n",
    "            # 他着跟这里讲的不太一样呀？“For bipartite graphs with two independent sets of nodes and indices, and each set holding its own information, this split can be marked by passing the information as a tuple, e.g. x=(x_N, x_M)”\n",
    "            # https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html?highlight=bipartate#the-messagepassing-base-class\n",
    "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "\n",
    "        # 这个到时候可以看一下 dim=1 的 stack 长啥样\n",
    "        # 可以参考这个 https://www.geeksforgeeks.org/python-pytorch-stack-method/\n",
    "        # 就是比如 [[1,2,3,4], [5,6,7,8]]\n",
    "        # stack 完变成[ [1,5], [2,6],[3, 7], [4, 8] ]\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        \n",
    "        # 然后这边就是把上面 stack 完的求均值\n",
    "        # Q: ?? lightGCN 是求均值吗? 不是应该是 weighted sum?? 不过 sum or avg 应该都不影响结果\n",
    "        # A: 看 paper 里面， 公式里的 a 其实是 1/(K+1) 那本质上就是 avg 了\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "        # 这个比较 straightforward, 我们上面 embedding 不是用 concat 把 user_emb 和 item_emb 给\n",
    "        # horizontal 连起来吗， 这里跑完 LightGCN layer 之后，我们就可以在 split 拆开左右两边，拿到各种的 embedding\n",
    "        # 那其实跟 NCF 还是蛮像的.\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, \n",
    "                                                       [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "# 试一下只用2层\n",
    "layers = 3    \n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_movies, \n",
    "                 K=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1884a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffad4fa8",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
    "\n",
    "\\begin{equation}\n",
    "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{y}_{u}$: predicted score of a positive sample\n",
    "\n",
    "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
    "\n",
    "$\\lambda$: hyperparameter which controls the L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cee24091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看公式，还真是需要 layer 0 embedding 作为一个 bias term.. 有意思了..\n",
    "def bpr_loss(users_emb_final, \n",
    "             users_emb_0, \n",
    "             pos_items_emb_final, \n",
    "             pos_items_emb_0, \n",
    "             neg_items_emb_final, \n",
    "             neg_items_emb_0, \n",
    "             lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5c914",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "We evalaluate our model using the following metrics\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "p: a particular rank position\n",
    "\n",
    "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
    "\n",
    "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
    "\\end{equation}\n",
    "\n",
    "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
    "\n",
    "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
    "\\end{equation}\n",
    "\n",
    "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a6dc66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get N_u\n",
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges 也就是 COO 格式\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary of positive items for each user\n",
    "    \"\"\"\n",
    "    \n",
    "    # key: user_id, val: item_id list\n",
    "    user_pos_items = {}\n",
    "    # 在 COO 格式 edge index 的第二个 dim 来 iterate， 也就是 edge pair 一个个过\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        # 这里就是拿到一个个 user, item edge pair\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        \n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        \n",
    "        user_pos_items[user].append(item)\n",
    "        \n",
    "    # 所以这里只要是 edge_index 里面有连接，就是 positive sample??\n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace2aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (intg): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
    "    \n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n",
    "    \n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa475ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes NDCG@K\n",
    "def NDCGatK_r(groundTruth, r, k):\n",
    "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list): list of lists containing highly rated items of each user\n",
    "        r (list): list of lists indicating whether each top k item recommended to each user\n",
    "            is a top k ground truth item or not\n",
    "        k (int): determines the top k items to compute ndcg on\n",
    "\n",
    "    Returns:\n",
    "        float: ndcg @ k\n",
    "    \"\"\"\n",
    "    assert len(r) == len(groundTruth)\n",
    "\n",
    "    test_matrix = torch.zeros((len(r), k))\n",
    "\n",
    "    for i, items in enumerate(groundTruth):\n",
    "        length = min(len(items), k)\n",
    "        test_matrix[i, :length] = 1\n",
    "    max_r = test_matrix\n",
    "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
    "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
    "    dcg = torch.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[torch.isnan(ndcg)] = 0.\n",
    "    return torch.mean(ndcg).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe2d3e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "# 这一段好好看一下?? 我好奇为什么 BPR loss 往下走的，暗示 recall 没有.\n",
    "\n",
    "# 这边我看上面是直接拿 [train_edge_index] 作为 exclude_edge_index, 因为你是做 evaluation\n",
    "# 他为什么要 exclude?? 哦，因为我 validation 的时候，我的 relevant item 要只看 validation set 里面的? \n",
    "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "\n",
    "    # get ratings between every user and item - shape is num users x num movies\n",
    "    # Matrix product of two tensors. \n",
    "    # 这么神奇？哦，不过也 make sense  (num_users x 64) dot_product (num_item x 64).T 那么每个 entry 其实就是pred rating\n",
    "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "    \n",
    "    # 这里把 rating 从 interaction mat 转成 bipartite adj mat 为了后面好算？\n",
    "    rating_transpose = torch.transpose(rating, 0, 1)\n",
    "    rating_adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
    "    rating_adj_mat[: num_users, num_users :] = rating.clone()\n",
    "    rating_adj_mat[num_users :, : num_users] = rating_transpose.clone()\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        # 这里应该只是转成  user -> positive item list\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            # 这个是为啥？为啥还 * len(item)， 为了平衡吗？非得把 exclude_user 的长度跟 exclude_item 长度一样\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "\n",
    "            \n",
    "            \n",
    "        # set ratings of excluded edges to large negative value\n",
    "        # 这一步崩的?? 想一想我的 bipartite 的处理，怎么去做这个 encoding 的offset 比较好一点...\n",
    "        # 不然老是 index 出错， 我这里先笨方法，直接先 减 num_users 了.. TODO: 得想想有没有更 clean 的方法\n",
    "        # 诶，卧槽，这里忘记改了，这里得拿掉，，我用大 matrix 不需要 offset...\n",
    "        # exclude_items = [item_id - num_users for item_id in exclude_items]\n",
    "        \n",
    "        # 这里就是设成一个非常小的数， 为啥要这个?? 因为下面有个rating\n",
    "        rating_adj_mat[exclude_users, exclude_items] = -(1 << 10) \n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    # 其实这里，我应该只需要前 num_user 个？\n",
    "    _, top_K_items = torch.topk(rating_adj_mat, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    # 得到一个 dict of user -> pos_item list\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list， 那这不是成了 list of list?\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    # r here is the ground truth?? 也就是 pred_relevant_and_is_actually_relevant item list for each user\n",
    "    # 这里是 list of list 的格式\n",
    "    r = []\n",
    "    for user in users:\n",
    "        # 拿到每个 user  的 relevant items\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        # 这啥？哦, python 的 lambda 写法，其实是对 top_K_items[user]， 也就是 recommended top k\n",
    "        # 看有多少是 actually relevant ， 这样 我的  recall 的分子 就拿到了\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        r.append(label)\n",
    "        \n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b69b4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
    "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        k (int): determines the top k items to compute metrics on\n",
    "        lambda_val (float): determines lambda for bpr loss\n",
    "\n",
    "    Returns:\n",
    "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get embeddings\n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(sparse_edge_index)\n",
    "    \n",
    "    edges = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
    "    \n",
    "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
    "    \n",
    "    # bipartite graph 的处理\n",
    "    users_items_emb_final = torch.cat([users_emb_final, items_emb_final], dim=0)\n",
    "    users_items_emb_0 = torch.cat([users_emb_0, items_emb_0], dim=0)\n",
    "    \n",
    "    users_emb_final, users_emb_0 = users_items_emb_final[user_indices], users_items_emb_0[user_indices]\n",
    "    \n",
    "    pos_items_emb_final, pos_items_emb_0 = users_items_emb_final[pos_item_indices], users_items_emb_0[pos_item_indices]\n",
    "    \n",
    "    neg_items_emb_final, neg_items_emb_0 = users_items_emb_final[neg_item_indices], users_items_emb_0[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(users_emb_final, \n",
    "                    users_emb_0, \n",
    "                    pos_items_emb_final, \n",
    "                    pos_items_emb_0,\n",
    "                    neg_items_emb_final, \n",
    "                    neg_items_emb_0, \n",
    "                    lambda_val).item()\n",
    "\n",
    "    #... 这里崩了... 也真是无语.... 改个 bipartite 这么难... \n",
    "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k)\n",
    "\n",
    "    return loss, recall, precision, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0bf54",
   "metadata": {},
   "source": [
    "_---------- maual explore start--------------_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aaf5f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9444, 9445, 9485]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dd17e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "tensor([[    0,     0,     0,  ..., 10331, 10332, 10333],\n",
      "        [  610,   615,   653,  ...,   183,   183,   330]])\n",
      "torch.LongTensor\n",
      "torch.Size([2, 159144])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index.type())\n",
    "print(train_edge_index)\n",
    "print(train_edge_index.type())\n",
    "print(train_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96431507",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index_norm = gcn_norm(edge_index=train_edge_index, \n",
    "                                   add_self_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f7cec5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    0,     0,     0,  ..., 10331, 10332, 10333],\n",
      "        [  610,   615,   653,  ...,   183,   183,   330]]), tensor([0.0057, 0.0084, 0.0059,  ..., 0.0976, 0.0976, 0.0884]))\n",
      "torch.Size([2, 99466])\n",
      "610\n",
      "torch.int64\n",
      "tensor([0.0057, 0.0084, 0.0059,  ..., 0.0976, 0.0976, 0.0884])\n"
     ]
    }
   ],
   "source": [
    "# print(edge_index_norm.size())\n",
    "# print(edge_index_norm.type())\n",
    "print(edge_index_norm)\n",
    "\n",
    "# 估计因为不能这么弄, 他这个格式不一样\n",
    "print(edge_index.size())\n",
    "\n",
    "print(num_users)\n",
    "\n",
    "print(edge_index.dtype)\n",
    "\n",
    "print(edge_index_norm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f100a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6da4769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 诶，他这个是拿 embedding 来算 degree? 没必要把? edge_index  不能算? 不需要啦\n",
    "def get_norm(edge_index):\n",
    "    from_, to_ = edge_index\n",
    "    deg = degree(to_, (num_users + num_movies), dtype=edge_index.dtype)\n",
    "    deg_inv_sqrt = deg.pow(-0.5)\n",
    "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc6a9411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0057, 0.0084, 0.0059,  ..., 0.0976, 0.0976, 0.0884])\n"
     ]
    }
   ],
   "source": [
    "# 这个算出来， 跟 import 的 gcn_norm 的返回的 print(edge_index_norm[1]) 一样的\n",
    "norm = get_norm(train_edge_index)\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82742e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bf0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "343c6328",
   "metadata": {},
   "source": [
    "_---------- maual explore stop--------------_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ba67b",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Your test set performance should be in line with the following (*K=20*):\n",
    "\n",
    "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cee1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define contants\n",
    "ITERATIONS = 10000\n",
    "EPOCHS = 10\n",
    "# ITERATIONS = 500\n",
    "BATCH_SIZE = 1024\n",
    "# 我觉得下面写的有点问题，不然我每个 batch 都是全部数据吧?\n",
    "# BATCH_SIZE = len(train_edge_index[0])\n",
    "\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "# K = 10\n",
    "# K = 10 是不是太多了?? 这个会导致 layer oversmooth? 不过好像没有用这个 K? 哦，不是，这个是 eval metric的 K \n",
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "# LAMBDA = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a841c7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE 1024\n"
     ]
    }
   ],
   "source": [
    "print(f\"BATCH_SIZE {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d3b2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu.\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "# train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
    "\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "# val_sparse_edge_index = val_sparse_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b7f792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 1/10000 [00:05<16:27:38,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0/10000] train_loss: -0.69209, val_loss: -0.66326, val_recall@20: 0.02712, val_precision@20: 0.00419, val_ndcg@20: 0.01274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                     | 201/10000 [01:45<6:06:55,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 200/10000] train_loss: -6.54349, val_loss: -5.02385, val_recall@20: 0.0794, val_precision@20: 0.01456, val_ndcg@20: 0.04522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▍                                                                                   | 401/10000 [03:28<6:05:24,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 400/10000] train_loss: -26.14535, val_loss: -20.74295, val_recall@20: 0.09481, val_precision@20: 0.01783, val_ndcg@20: 0.05815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▏                                                                                 | 601/10000 [05:06<5:54:18,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 600/10000] train_loss: -56.76345, val_loss: -43.9276, val_recall@20: 0.10884, val_precision@20: 0.02148, val_ndcg@20: 0.07147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▉                                                                                | 801/10000 [06:39<5:34:36,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 800/10000] train_loss: -92.58365, val_loss: -72.58499, val_recall@20: 0.11717, val_precision@20: 0.02321, val_ndcg@20: 0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▌                                                                             | 1001/10000 [08:12<4:57:48,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1000/10000] train_loss: -134.93996, val_loss: -105.00739, val_recall@20: 0.13733, val_precision@20: 0.02597, val_ndcg@20: 0.08801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▎                                                                           | 1201/10000 [09:41<4:43:29,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1200/10000] train_loss: -182.3392, val_loss: -140.27936, val_recall@20: 0.14761, val_precision@20: 0.02779, val_ndcg@20: 0.09447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████                                                                          | 1401/10000 [11:10<4:39:11,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1400/10000] train_loss: -228.33195, val_loss: -178.31656, val_recall@20: 0.16028, val_precision@20: 0.02935, val_ndcg@20: 0.09951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▊                                                                        | 1601/10000 [12:39<4:28:40,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1600/10000] train_loss: -274.96378, val_loss: -218.40941, val_recall@20: 0.16628, val_precision@20: 0.03065, val_ndcg@20: 0.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████████▍                                                                      | 1801/10000 [14:11<6:01:43,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 1800/10000] train_loss: -333.42004, val_loss: -256.72653, val_recall@20: 0.16783, val_precision@20: 0.03127, val_ndcg@20: 0.10357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████████▏                                                                    | 2001/10000 [16:02<5:48:25,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2000/10000] train_loss: -401.49152, val_loss: -296.64316, val_recall@20: 0.18939, val_precision@20: 0.03375, val_ndcg@20: 0.11223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██████████████████▉                                                                   | 2201/10000 [18:01<5:28:36,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2200/10000] train_loss: -457.39661, val_loss: -337.33359, val_recall@20: 0.1948, val_precision@20: 0.03407, val_ndcg@20: 0.11369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████████▋                                                                 | 2401/10000 [19:42<4:04:31,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2400/10000] train_loss: -452.58487, val_loss: -374.36536, val_recall@20: 0.198, val_precision@20: 0.03461, val_ndcg@20: 0.11681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████████▎                                                               | 2601/10000 [21:12<4:06:47,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2600/10000] train_loss: -554.84973, val_loss: -414.49774, val_recall@20: 0.19924, val_precision@20: 0.03501, val_ndcg@20: 0.11672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████████                                                              | 2801/10000 [22:42<4:03:44,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 2800/10000] train_loss: -577.86475, val_loss: -453.63278, val_recall@20: 0.20192, val_precision@20: 0.03545, val_ndcg@20: 0.11912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▊                                                            | 3001/10000 [24:12<3:52:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3000/10000] train_loss: -655.05884, val_loss: -491.50644, val_recall@20: 0.20004, val_precision@20: 0.03553, val_ndcg@20: 0.12081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███████████████████████████▌                                                          | 3201/10000 [25:42<3:47:04,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3200/10000] train_loss: -683.01868, val_loss: -524.63269, val_recall@20: 0.20328, val_precision@20: 0.03568, val_ndcg@20: 0.12294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████████████████████▏                                                        | 3401/10000 [27:12<3:36:33,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3400/10000] train_loss: -709.64496, val_loss: -561.19617, val_recall@20: 0.20591, val_precision@20: 0.03595, val_ndcg@20: 0.12404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████████████████████▉                                                       | 3601/10000 [28:42<3:30:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3600/10000] train_loss: -770.69617, val_loss: -593.22345, val_recall@20: 0.20946, val_precision@20: 0.0366, val_ndcg@20: 0.12758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████▋                                                     | 3801/10000 [30:11<3:18:43,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 3800/10000] train_loss: -840.37213, val_loss: -625.78949, val_recall@20: 0.20886, val_precision@20: 0.03676, val_ndcg@20: 0.12659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████▍                                                   | 4001/10000 [31:41<3:18:29,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4000/10000] train_loss: -935.68195, val_loss: -657.03394, val_recall@20: 0.21079, val_precision@20: 0.03679, val_ndcg@20: 0.12747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████████████▏                                                 | 4201/10000 [33:11<3:08:15,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4200/10000] train_loss: -880.8844, val_loss: -692.07233, val_recall@20: 0.21032, val_precision@20: 0.0369, val_ndcg@20: 0.12824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████▊                                                | 4401/10000 [34:41<3:05:16,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4400/10000] train_loss: -933.46802, val_loss: -721.06012, val_recall@20: 0.21082, val_precision@20: 0.03705, val_ndcg@20: 0.12884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████████████████▌                                              | 4601/10000 [36:11<2:59:36,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4600/10000] train_loss: -945.86304, val_loss: -746.67285, val_recall@20: 0.21204, val_precision@20: 0.03719, val_ndcg@20: 0.12927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|█████████████████████████████████████████▎                                            | 4801/10000 [37:41<2:49:17,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 4800/10000] train_loss: -969.49072, val_loss: -772.54907, val_recall@20: 0.21034, val_precision@20: 0.03708, val_ndcg@20: 0.12879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████                                           | 5001/10000 [39:10<2:40:24,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5000/10000] train_loss: -993.11053, val_loss: -800.82843, val_recall@20: 0.21317, val_precision@20: 0.03741, val_ndcg@20: 0.12996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████▋                                         | 5201/10000 [40:39<2:38:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5200/10000] train_loss: -1077.74548, val_loss: -827.60547, val_recall@20: 0.21209, val_precision@20: 0.03718, val_ndcg@20: 0.13057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|██████████████████████████████████████████████▍                                       | 5401/10000 [42:08<2:29:30,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5400/10000] train_loss: -1078.01892, val_loss: -850.48157, val_recall@20: 0.21204, val_precision@20: 0.03737, val_ndcg@20: 0.13075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████████████████████████████▏                                     | 5601/10000 [43:37<2:24:02,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5600/10000] train_loss: -1108.09998, val_loss: -870.46741, val_recall@20: 0.21292, val_precision@20: 0.03731, val_ndcg@20: 0.13072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████████████████████████████████████████████████▉                                    | 5801/10000 [45:07<2:13:38,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 5800/10000] train_loss: -1205.43408, val_loss: -894.19806, val_recall@20: 0.21193, val_precision@20: 0.03726, val_ndcg@20: 0.13053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████████████▌                                  | 6001/10000 [46:38<2:09:07,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6000/10000] train_loss: -1156.79431, val_loss: -912.33191, val_recall@20: 0.21297, val_precision@20: 0.03741, val_ndcg@20: 0.13087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████████████████████████████████▎                                | 6201/10000 [48:07<2:07:40,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6200/10000] train_loss: -1218.30725, val_loss: -934.52173, val_recall@20: 0.21231, val_precision@20: 0.03721, val_ndcg@20: 0.13129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████████████████████████████████                               | 6401/10000 [49:36<2:00:47,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6400/10000] train_loss: -1287.18921, val_loss: -953.46069, val_recall@20: 0.21273, val_precision@20: 0.03733, val_ndcg@20: 0.13178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████████████████████████████████▊                             | 6601/10000 [51:05<1:48:48,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6600/10000] train_loss: -1315.4928, val_loss: -970.90613, val_recall@20: 0.21353, val_precision@20: 0.03741, val_ndcg@20: 0.13171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████▍                           | 6801/10000 [52:46<2:17:48,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 6800/10000] train_loss: -1217.66772, val_loss: -986.20679, val_recall@20: 0.21658, val_precision@20: 0.03759, val_ndcg@20: 0.13265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████████▏                         | 7001/10000 [54:34<1:54:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7000/10000] train_loss: -1270.59619, val_loss: -1001.68701, val_recall@20: 0.21573, val_precision@20: 0.03758, val_ndcg@20: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████████████▉                        | 7201/10000 [56:16<1:39:43,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7200/10000] train_loss: -1376.38965, val_loss: -1021.33923, val_recall@20: 0.21555, val_precision@20: 0.03754, val_ndcg@20: 0.13252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████████▋                      | 7401/10000 [58:02<2:05:23,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7400/10000] train_loss: -1347.19934, val_loss: -1038.31726, val_recall@20: 0.21561, val_precision@20: 0.03761, val_ndcg@20: 0.13294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████▎                    | 7601/10000 [59:36<1:18:33,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7600/10000] train_loss: -1339.99805, val_loss: -1053.19263, val_recall@20: 0.21515, val_precision@20: 0.03745, val_ndcg@20: 0.13231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████████████████████████████████████▌                  | 7801/10000 [1:01:08<1:17:45,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 7800/10000] train_loss: -1341.4873, val_loss: -1070.44177, val_recall@20: 0.21555, val_precision@20: 0.03755, val_ndcg@20: 0.13264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 8001/10000 [1:02:44<1:09:19,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8000/10000] train_loss: -1319.46667, val_loss: -1077.60828, val_recall@20: 0.21512, val_precision@20: 0.03759, val_ndcg@20: 0.13285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████████████████████████████████████████████████▌               | 8201/10000 [1:04:18<58:19,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8200/10000] train_loss: -1397.19678, val_loss: -1091.00171, val_recall@20: 0.21564, val_precision@20: 0.03767, val_ndcg@20: 0.13313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████████████████████████████████████████▏             | 8401/10000 [1:05:52<52:56,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8400/10000] train_loss: -1386.97766, val_loss: -1100.32947, val_recall@20: 0.21516, val_precision@20: 0.03766, val_ndcg@20: 0.13311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████████▉            | 8601/10000 [1:07:25<47:10,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8600/10000] train_loss: -1469.28088, val_loss: -1111.79431, val_recall@20: 0.21537, val_precision@20: 0.03768, val_ndcg@20: 0.13313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████████▋          | 8801/10000 [1:09:05<42:54,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 8800/10000] train_loss: -1471.72412, val_loss: -1119.04016, val_recall@20: 0.21578, val_precision@20: 0.03767, val_ndcg@20: 0.13313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████▍        | 9001/10000 [1:10:47<39:08,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9000/10000] train_loss: -1478.78552, val_loss: -1132.71924, val_recall@20: 0.21595, val_precision@20: 0.0377, val_ndcg@20: 0.13327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████████████████████████████████████████████▏      | 9201/10000 [1:12:25<29:39,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9200/10000] train_loss: -1415.28479, val_loss: -1141.14136, val_recall@20: 0.21567, val_precision@20: 0.03766, val_ndcg@20: 0.13313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████████▊     | 9401/10000 [1:14:06<22:26,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9400/10000] train_loss: -1492.05872, val_loss: -1152.20618, val_recall@20: 0.21553, val_precision@20: 0.03768, val_ndcg@20: 0.13317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████████████████████████████████████████████████▌   | 9601/10000 [1:15:43<14:45,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9600/10000] train_loss: -1406.0127, val_loss: -1160.36646, val_recall@20: 0.2158, val_precision@20: 0.03767, val_ndcg@20: 0.13325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████████▎ | 9801/10000 [1:17:21<07:06,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 9800/10000] train_loss: -1530.55237, val_loss: -1171.65869, val_recall@20: 0.21551, val_precision@20: 0.03761, val_ndcg@20: 0.13316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [1:18:53<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_recall_at_ks = []\n",
    "\n",
    "for iter in tqdm(range(ITERATIONS)):\n",
    "    # forward propagation\n",
    "    # todo: 估计是这里要给他转成 bidirectional 的，这样信息才完整\n",
    "#     bidirectional_train_edge_index = to_bidirectional(train_edge_index)\n",
    "    \n",
    "#     bidirectional_train_sparse_edge_index = SparseTensor(\n",
    "#                                        row=bidirectional_train_edge_index[0], \n",
    "#                                        col=bidirectional_train_edge_index[1], \n",
    "#                                        sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
    "\n",
    "    \n",
    "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(train_edge_index)\n",
    "\n",
    "    # mini batching for eval and calculate loss \n",
    "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, train_edge_index)\n",
    "    # print(f\"user_indices {user_indices}, pos_item_indices {pos_item_indices}, neg_item_indices {neg_item_indices}\")\n",
    "    \n",
    "    # 全部转成 to(device) 的格式\n",
    "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
    "    \n",
    "    \n",
    "    # concat 一下，不然我的 bipartite 处理之后, item 的 range 已经变了\n",
    "    users_items_emb_final = torch.cat([users_emb_final, items_emb_final], dim=0)\n",
    "    users_items_emb_0 = torch.cat([users_emb_0, items_emb_0], dim=0)\n",
    "    \n",
    "    \n",
    "    # 拿到第一层，和最后一层的 user embedding?\n",
    "    users_emb_final, users_emb_0 = users_items_emb_final[user_indices], users_items_emb_0[user_indices]\n",
    "\n",
    "    # 拿到第一层，和最后一层的 positive item embedding?\n",
    "    # TODO; 这里要记得 干脆 user 和 item embedding concat 一下，不然总是出街\n",
    "    pos_items_emb_final, pos_items_emb_0 = users_items_emb_final[pos_item_indices], users_items_emb_0[pos_item_indices]\n",
    "\n",
    "    # 拿到第一层，和最后一层的 negative item embedding?    \n",
    "    neg_items_emb_final, neg_items_emb_0 = users_items_emb_final[neg_item_indices], users_items_emb_0[neg_item_indices]\n",
    "\n",
    "    # loss computation\n",
    "    # TODO；  这边看一下能不能 incorporate RMSE loss 这样也许 recall 就会提高不少\n",
    "    # 当然，要思考一下，他这边怎么去算 RMSE loss? 不过应该是有 edge index 本质上是edge pair 应该是可以算吧?\n",
    "    # Question: BPR loss 需要最后一层和第一层吗？？\n",
    "    train_loss = bpr_loss(users_emb_final, \n",
    "                          users_emb_0, \n",
    "                          pos_items_emb_final,\n",
    "                          pos_items_emb_0, \n",
    "                          neg_items_emb_final, \n",
    "                          neg_items_emb_0, \n",
    "                          LAMBDA)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 这里就是过 validation set\n",
    "    if iter % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        \n",
    "\n",
    "        # 为啥这里需要 val_sparse_edge_index\n",
    "        val_loss, recall, precision, ndcg = evaluation(model, \n",
    "                                                       val_edge_index, \n",
    "                                                       val_edge_index, \n",
    "                                                       [train_edge_index], \n",
    "                                                       K, \n",
    "                                                       LAMBDA)\n",
    "        \n",
    "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
    "\n",
    "        train_losses.append(train_loss.item())\n",
    "        val_losses.append(val_loss)\n",
    "        val_recall_at_ks.append(round(recall, 5))\n",
    "        model.train()\n",
    "\n",
    "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bce6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423573ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dabdd722",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e32fd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label='train')\n",
    "plt.plot(iters, val_losses, label='validation')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training and validation loss curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "203b99c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2 = plt.figure()\n",
    "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('recall_at_k')\n",
    "plt.title('recall_at_k curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9c96a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test_loss: -1166.86792, test_recall@20: 0.21978, test_precision@20: 0.03853, test_ndcg@20: 0.13844\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "model.eval()\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "# test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
    "\n",
    "# bidirectional_test_edge_index = to_bidirectional(test_edge_index)\n",
    "# bidirectional_test_sparse_edge_index = SparseTensor(\n",
    "#                                row=bidirectional_test_edge_index[0], \n",
    "#                                col=bidirectional_test_edge_index[1], \n",
    "#                                sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
    "\n",
    "\n",
    "\n",
    "test_loss, test_recall, test_precision, test_ndcg = evaluation(model, \n",
    "                                                               test_edge_index, \n",
    "                                                               test_edge_index, \n",
    "                                                               [train_edge_index, val_edge_index], \n",
    "                                                               K, \n",
    "                                                               LAMBDA)\n",
    "\n",
    "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ae671",
   "metadata": {},
   "source": [
    "发现上面跑出来 效果也一般般\n",
    "我把原始代码的output 记录一下\n",
    "- [test_loss: -51.5177, test_recall@10: 0.08269, test_precision@10: 0.05815, test_ndcg@10: 0.09033\n",
    "\n",
    "卧槽，改了半天 bipartite，改了个寂寞？ (不过我的 iter 用的 500 而不是 10000 好吧，再试一下)\n",
    "（好像还是不太行，不然我把 bidirectional 拿掉？没有差，好像还是挺差.. 这个真多要歇会儿了... ）\n",
    "\n",
    "[test_loss: -29.82772, test_recall@10: 0.00317, test_precision@10: 0.00163, test_ndcg@10: 0.00212\n",
    "\n",
    "\n",
    "TRY: 我试一下只用一层？？(也不想\n",
    "\n",
    "TRY: 我试一下 threshold 用 >=1\n",
    "- 不行: [test_loss: -51.26439, test_recall@10: 0.00361, test_precision@10: 0.00127, test_ndcg@10: 0.00182\n",
    "- 不过我好像有个地方漏改了，所以其实还是 >=4 。。。难怪跟之前一样\n",
    "- TODO need redo:\n",
    "\n",
    "\n",
    "Thoughts: 我怀疑我还是 sparse tensor 没有理解对\n",
    "\n",
    "TRY: 实在不行，把 Bipartate 的处理拿掉？然后用 label encoded 的再跑一下看一下? 然后threshold 用 >=4, 然后 recall@k 的 k 用 20 (然后看一下 perf 会不会至少跟之前例子是持平的，然后再来试一下 bipartite 我把 threshold 该清楚\n",
    "- [test_loss: -44.70277, test_recall@20: 0.08734, test_precision@20: 0.03558, test_ndcg@20: 0.06751\n",
    "- 那就跟原始结果差不多\n",
    "- 发现 threshold at 4 的时候, training density 好低: \n",
    "            SparseTensor(row=tensor([  0,   0,   0,  ..., 609, 609, 609]),\n",
    "             col=tensor([   0,    5,   43,  ..., 9443, 9444, 9445]),\n",
    "             size=(10334, 10334), nnz=79572, density=0.07%)\n",
    "             \n",
    "            - 不对，我这已经是用 >=1 和 k = 20 来算的了\n",
    "\n",
    "\n",
    "_TOTRY_: 用 Bipartite， 而且 threahold 用 >=1\n",
    "    - 不行， 在前 1500 iter 左右还很低级别就没戏\n",
    "    \n",
    "    \n",
    "_TOTRY_: 改成用原始的 mapping，但是感觉大概率还是不行... 太失望了... \n",
    "\n",
    "\n",
    "还发现一个问题，他这每次 train 都是全部一起弄一个 epoch？但是 loss 用的是 batch 的 err? 不太对呀，不是应该\n",
    "\n",
    "_TOTRY_: 我直接试一下每次 loss 都用整个 batch 的 loss? 而不是 sample batch 的 loss?\n",
    "\n",
    "_TOTRY_\" 我如果不用 sparse matrix?\n",
    "\n",
    "_Update_: 卧槽，改了 formula 6 的正确写法之后，重要弄出来了 :  ✅\n",
    "\n",
    "    - [test_loss: -934.20184, test_recall@20: 0.18721, test_precision@20: 0.0367, test_ndcg@20: 0.10241\n",
    "    - 比原来还是高了不少的 但是真的跑的好久，1h11m... 明天整理一下，然后用 RMSE 试一下\n",
    "    \n",
    "_TOTRY_: 发现我应该先 split train/val/test 再转 adj mat 不然有可能 data leak 因为是 symmetric 的 ✅\n",
    "    - [test_loss: -1165.17944, test_recall@20: 0.19547, test_precision@20: 0.03564, test_ndcg@20: 0.11246\n",
    "    - 比上面的效果好一点，也 make sense. 因为信息更完整\n",
    "\n",
    "_ToTRY_: 试一下我直接用 train 好的 model 而不是 edge index 再 propapage 一遍?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc49db9",
   "metadata": {},
   "source": [
    "# Make New Recommendatios for a Given User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94a3894",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "df = pd.read_csv(movie_path)\n",
    "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
    "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
    "\n",
    "user_pos_items = get_user_positive_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23838f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(user_id, num_recs):\n",
    "    user = user_mapping[user_id]\n",
    "    e_u = model.users_emb.weight[user]\n",
    "    \n",
    "    # 这里 @ 是 dot product\n",
    "    scores = model.items_emb.weight @ e_u\n",
    "\n",
    "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
    "\n",
    "    print()\n",
    "\n",
    "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
    "    titles = [movieid_title[id] for id in movie_ids]\n",
    "    genres = [movieid_genres[id] for id in movie_ids]\n",
    "\n",
    "    print(f\"Here are some suggested movies for user {user_id}\")\n",
    "    for i in range(num_recs):\n",
    "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1614084",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = 1\n",
    "NUM_RECS = 10\n",
    "\n",
    "make_predictions(USER_ID, NUM_RECS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
