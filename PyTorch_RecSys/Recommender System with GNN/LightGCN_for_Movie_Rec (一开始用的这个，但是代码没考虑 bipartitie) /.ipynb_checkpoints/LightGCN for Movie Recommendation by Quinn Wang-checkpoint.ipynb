{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e8c062",
   "metadata": {},
   "source": [
    "来自这个 Meidum Post\n",
    "- [[Medium] LightGCN for Movie Recommendation](https://medium.com/stanford-cs224w/lightgcn-for-movie-recommendation-eb6d112f1e8)\n",
    "-  Code: https://colab.research.google.com/drive/1VfP6JlWbX_AJnx88yN1tM3BYE6XAADiy?usp=sharing\n",
    "\n",
    "\n",
    "可以好好学一学他的 notebook 是怎么设置的, 比如 training loop 这些咋写的, 我觉得我把这个 notebook 讲清楚，应该我还是能有很多 value adding 的空间的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46496072",
   "metadata": {},
   "source": [
    "卧槽， pyG install on Mac 真的是非常不方便。。遇到各种问题，比如我即使用 pytorch 1.11 然后安装 pyg 官方用 conda 安装话，还是会在 import torch_geometric 的时候，遇到 \n",
    "- \"oserror: dlopen(/opt/anaconda3/envs/pyg/lib/python3.7/site-packages/torch_sparse/_convert_cpu.so, 6): symbol not found: __zn2at8internal13_parallel_runexxxrknst3__18functionifvxxmeee\"\n",
    "\n",
    "遇到终于找到一个可以安装的方法: \n",
    "- https://gist.github.com/AnirudhDagar/05e9c51257dda06206a44c3b09aced4b\n",
    "\n",
    "我自己做了一个[视频](https://www.youtube.com/watch?v=UuMjJVqCMQo)，来记录怎么安装, 基本步骤如下: \n",
    "```\n",
    "conda create -n pygeometric python=3.7\n",
    "conda activate pygeometric\n",
    "conda install pytorch torchvision -c pytorch\n",
    "python -c \"import torch; print(torch.__version__)\"\n",
    "conda install -y clang_osx-64 clangxx_osx-64 gfortran_osx-64\n",
    "MACOSX_DEPLOYMENT_TARGET=10.9 CC=clang CXX=clang++\n",
    "pip install torch_scatter\n",
    "python -c \"import torch_scatter; print(torch_scatter.__version__)\"\n",
    "pip install torch_sparse\n",
    "python -c \"import torch_sparse; print(torch_sparse.__version__)\"\n",
    "pip install torch_cluster\n",
    "python -c \"import torch_cluster; print(torch_cluster.__version__)\"\n",
    "pip install torch-spline-conv\n",
    "python -c \"import torch_spline_conv; print(torch_spline_conv.__version__)\"\n",
    "pip install torch_geometric\n",
    "python -c \"import torch_geometric; print(torch_geometric.__version__)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49718b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36210ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 10\n",
    "from sklearn import metrics\n",
    "from tensorly import decomposition # this is used to matrix factorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc5d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.functional import tensordot\n",
    "from torch import nn, optim, Tensor\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, Data, download_url, extract_zip\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c2097",
   "metadata": {},
   "source": [
    "# Configurations\n",
    "\n",
    "Configure the model and training process. These parameters will make more sense as you move along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef52cd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_threshold = 1  #@param {type: \"integer\"}: Ratings equal to or greater than 3 are positive items.\n",
    "\n",
    "config_dict = {\n",
    "    \"num_samples_per_user\": 500,\n",
    "    \"num_users\": 200,\n",
    "\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.1,\n",
    "\n",
    "    \"embedding_size\": 64,\n",
    "    \"num_layers\": 3,\n",
    "    \"K\": 10,\n",
    "    \"mf_rank\": 8,\n",
    "\n",
    "    \"minibatch_per_print\": 100,\n",
    "    \"epochs_per_print\": 1,\n",
    "\n",
    "    \"val_frac\": 0.2,\n",
    "    \"test_frac\": 0.1,\n",
    "\n",
    "    \"model_name\": \"model.pth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec7c79e",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "A great publicly available dataset for training movie recommenders is the MovieLens 1M dataset. The MovieLens 1M dataset consists of 1 million movie ratings of score 1 to 5, from 6000 users and 4000 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52834eb2",
   "metadata": {},
   "source": [
    "这里 data explore 一下，其实也是手动试一下 Create Own Dataset class 里面的一些操作，这样看起来比较直观"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0140cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720f2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这边 explore 一下 data\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "        \n",
    "users = pd.read_table('./ml-1m/users.dat', \n",
    "                  sep='::', \n",
    "                  header=None, \n",
    "                  names=unames,\n",
    "                  engine='python', \n",
    "                  encoding='latin-1')\n",
    "\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('./ml-1m/ratings.dat', \n",
    "                    sep='::', \n",
    "                    header=None, \n",
    "                    names=rnames, \n",
    "                    engine='python',\n",
    "                    encoding='latin-1')\n",
    "\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('./ml-1m/movies.dat', \n",
    "                   sep='::', \n",
    "                   header=None, \n",
    "                   names=mnames, \n",
    "                   engine='python',\n",
    "                   encoding='latin-1')\n",
    "\n",
    "# merge 这里就是 join\n",
    "dat = pd.merge(pd.merge(ratings, users), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "476d7d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000209"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3e1bd14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000209 entries, 0 to 1000208\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   user_id     1000209 non-null  int64 \n",
      " 1   movie_id    1000209 non-null  int64 \n",
      " 2   rating      1000209 non-null  int64 \n",
      " 3   timestamp   1000209 non-null  int64 \n",
      " 4   gender      1000209 non-null  object\n",
      " 5   age         1000209 non-null  int64 \n",
      " 6   occupation  1000209 non-null  int64 \n",
      " 7   zip         1000209 non-null  object\n",
      " 8   title       1000209 non-null  object\n",
      " 9   genres      1000209 non-null  object\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 83.9+ MB\n"
     ]
    }
   ],
   "source": [
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "29769e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978298413</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978220179</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>978199279</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>22903</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978158471</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>95350</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp gender  age  occupation    zip  \\\n",
       "0        1      1193       5  978300760      F    1          10  48067   \n",
       "1        2      1193       5  978298413      M   56          16  70072   \n",
       "2       12      1193       4  978220179      M   25          12  32793   \n",
       "3       15      1193       4  978199279      M   25           7  22903   \n",
       "4       17      1193       5  978158471      M   50           1  95350   \n",
       "\n",
       "                                    title genres  \n",
       "0  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "1  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "2  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "3  One Flew Over the Cuckoo's Nest (1975)  Drama  \n",
       "4  One Flew Over the Cuckoo's Nest (1975)  Drama  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd22b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users['user_id']\n",
    "movies = movies['movie_id']\n",
    "\n",
    "num_users = config_dict[\"num_users\"]\n",
    "# 这里是直选200 个 user? \n",
    "if num_users != -1:\n",
    "    users = users[:num_users]\n",
    "\n",
    "#这里啥意思 这个是不是跟我之前 basic CF 里面的 label encoder 一个意思\n",
    "# 就是把 user_id 和 movie_id 的 range 跳到 从 0 开始的范围\n",
    "user_ids = range(len(users))\n",
    "movie_ids = range(len(movies))\n",
    "\n",
    "# 这么弄好没有有意义呀，直接用 label encoder 不就行，这个弄的太复杂了\n",
    "# 不过我那里 validation 也用 label encoded 好的从 0 开始的 dataset 了\n",
    "# TODO; 到时候试一下 label encoder\n",
    "user_to_id = dict(zip(users, user_ids))\n",
    "movie_to_id = dict(zip(movies, movie_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a5144399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 200)\n"
     ]
    }
   ],
   "source": [
    "print(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3dd1745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 3883)\n"
     ]
    }
   ],
   "source": [
    "print(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5539eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199}\n"
     ]
    }
   ],
   "source": [
    "# 这里就是不用 label encoder 的笨方法，就是 (user_id -> 从0 开始的 user_id) 这样一个 dicitonary\n",
    "print(user_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "368535f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_user 200, num_item 3883\n"
     ]
    }
   ],
   "source": [
    "num_user = users.shape[0]\n",
    "num_item = movies.shape[0]\n",
    "print(f\"num_user {num_user}, num_item {num_item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e6b65c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0        1      1193       5  978300760\n",
       "1        1       661       3  978302109\n",
       "2        1       914       3  978301968\n",
       "3        1      3408       4  978300275\n",
       "4        1      2355       5  978824291"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "01782cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the adjacency matrix\n",
    "\n",
    "# 这 rat 也是表示 rating 的意思，好棒，直接说是 adjascency matrix 多方便...\n",
    "rat = torch.zeros(num_user, num_item)\n",
    "\n",
    "# 所以这里是开始 build adjacency matrix?\n",
    "for index, row in ratings.iterrows():\n",
    "    # 选前三个，因为第四个 col 是 timestamp 我们需要用 \n",
    "    user, movie, rating = row[:3]\n",
    "    \n",
    "    if num_users != -1:\n",
    "        if user not in user_to_id: break\n",
    "    \n",
    "    # create ratings matrix where (i, j) entry represents the ratings\n",
    "    # of movie j given by user i.\n",
    "    # 所以这里 rat 还是用 从 0 开始的 encoded 的 movie_id, 和 user_id 比较 rat adj matrix 的shape 是 boundary\n",
    "    rat[user_to_id[user], movie_to_id[movie]] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a84bbb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 3., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 3.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([200, 3883])\n"
     ]
    }
   ],
   "source": [
    "print(rat)\n",
    "print(rat.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2a032be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: 诶，神奇了... edge_index 不是应该是 COO 格式，怎么变成直接用 adj matrix???\n",
    "data_before_transform = Data(edge_index = rat.clone(), #TODO ??? 这个不对呀，应该是 COO 格式的!! 这里 clone 一下不然，会直接把前面 rat 也改了\n",
    "            raw_edge_index = rat.clone(), # 这个是干啥的？ 哦，后面 _sample_pos_neg 有用到 自定义的几个 kv pair, 下面几个也是\n",
    "            data = ratings,\n",
    "            users = users,\n",
    "            items = movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "57339028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 3., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 3.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(data_before_transform['edge_index']) # ?? 怎么还长这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f91efc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = trans_ml(data_before_transform, [rating_threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1d7dde86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['items', 'edge_index', 'users', 'data', 'raw_edge_index']\n"
     ]
    }
   ],
   "source": [
    "print(data.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d0e3e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index => tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "raw_edge_index => tensor([[5., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [5., 3., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 3.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "data =>          user_id  movie_id  rating  timestamp\n",
      "0              1      1193       5  978300760\n",
      "1              1       661       3  978302109\n",
      "2              1       914       3  978301968\n",
      "3              1      3408       4  978300275\n",
      "4              1      2355       5  978824291\n",
      "...          ...       ...     ...        ...\n",
      "1000204     6040      1091       1  956716541\n",
      "1000205     6040      1094       5  956704887\n",
      "1000206     6040       562       5  956704746\n",
      "1000207     6040      1096       4  956715648\n",
      "1000208     6040      1097       4  956715569\n",
      "\n",
      "[1000209 rows x 4 columns]\n",
      "users => 0        1\n",
      "1        2\n",
      "2        3\n",
      "3        4\n",
      "4        5\n",
      "      ... \n",
      "195    196\n",
      "196    197\n",
      "197    198\n",
      "198    199\n",
      "199    200\n",
      "Name: user_id, Length: 200, dtype: int64\n",
      "items => 0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "3878    3948\n",
      "3879    3949\n",
      "3880    3950\n",
      "3881    3951\n",
      "3882    3952\n",
      "Name: movie_id, Length: 3883, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for key, item in data:\n",
    "    print(f'{key} => {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aeb475a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#但是 transform 之后，还是不是 COO 格式呀... 这个感觉还是不对..\n",
    "# 除非后面 model 的用法，是比较神奇，不然。.\n",
    "# 这里比较快的做法，应该是 adj matrix 转成 edge pair list, 然后直接 transpose\n",
    "print(data['edge_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "262a25fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  199,  199,  199],\n",
      "        [   0,   47,  148,  ..., 2982, 3339, 3682]])\n"
     ]
    }
   ],
   "source": [
    "# 这里有个办法: https://discuss.pytorch.org/t/adjacency-matrix-to-edge-index-solution/148343\n",
    "print(data['edge_index'].clone().nonzero().t().contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279074e4",
   "metadata": {},
   "source": [
    "_-------------------------------------------------------_\n",
    "\n",
    "上面 explore 一下 data 不然下面这个 dataset 怎么弄的不是很直观"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4855dcf",
   "metadata": {},
   "source": [
    "# Create Own Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae84b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是啥？？ pre-processing 用的？\n",
    "def trans_ml(dat, thres):\n",
    "    \"\"\"\n",
    "    Transform function that assign non-negative entries >= thres 1, and non-\n",
    "    negative entries <= thres 0. Keep other entries the same.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 这边好笨呀，因为他传进来长这样  data = self.transform(data, [rating_threshold])\n",
    "    # 所以这里又  thre[0] 来吧 rating_threshold 这个 int 拿出来... 无语。..\n",
    "    thres = thres[0]\n",
    "    # 拿到 edge_index 但是他这里其实是存的 adj matrix 不是 COO format\n",
    "    # 难道是这里转成 COO?\n",
    "    matrix = dat['edge_index']\n",
    "    matrix[(matrix < thres) & (matrix > -1)] = 0\n",
    "    matrix[(matrix >= thres)] = 1\n",
    "    # TOTRY: 试一下是不是这里出问题了? 这里Adj Matrix 转成 COO 看下一会不会崩。试了一下，不会但是 recall@k 还是上不去..\n",
    "    # 没事，明天继续看\n",
    "    # dat['edge_index'] = matrix.clone().nonzero().t().contiguous()\n",
    "    dat['edge_index'] = matrix\n",
    "    return dat\n",
    "\n",
    "\n",
    "# Q: Dataset 是什么 class? A: 哦 from torch_geometric.data import Dataset, 所以是给 graph 用的一个 dataset呗\n",
    "class MovieLens(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None,\n",
    "            transform_args=None, pre_transform_args=None):\n",
    "        \"\"\"\n",
    "        root = where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (process data).\n",
    "        \"\"\"\n",
    "        super(MovieLens, self).__init__(root, transform, pre_transform)\n",
    "        self.transform = transform\n",
    "        self.pre_transform = pre_transform\n",
    "        self.transform_args = transform_args\n",
    "        self.pre_transform_args = pre_transform_args\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # 这边写 ml-1m.zip 没有问题，因为 这里就是看 <root_dir>/<raw> 里面有没有这个文件，就是提前下载好也行\n",
    "        return [\"ml-1m.zip\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data_movielens.pt\"]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        download_url(DATA_PATH, self.raw_dir)\n",
    "\n",
    "    # 这一步干啥？ 就是从 file 里面读出来，然后转成 pandas dataframe\n",
    "    # process() 的第一步就是 call 这个\n",
    "    def _load(self):\n",
    "        print(self.raw_dir)\n",
    "        # extract_zip(self.raw_paths[0], self.raw_dir)\n",
    "        # 这里就是 unsip\n",
    "        with zipfile.ZipFile(self.raw_paths[0], 'r') as zip_ref:\n",
    "            zip_ref.extractall(self.raw_dir)\n",
    "            \n",
    "        unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "        \n",
    "        users = pd.read_table(self.raw_dir+'/ml-1m/users.dat', \n",
    "                              sep='::', \n",
    "                              header=None, \n",
    "                              names=unames,\n",
    "                              engine='python', \n",
    "                              encoding='latin-1')\n",
    "        \n",
    "        rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "        ratings = pd.read_table(self.raw_dir+'/ml-1m/ratings.dat', \n",
    "                                sep='::', \n",
    "                                header=None, \n",
    "                                names=rnames, \n",
    "                                engine='python',\n",
    "                                encoding='latin-1')\n",
    "        \n",
    "        mnames = ['movie_id', 'title', 'genres']\n",
    "        movies = pd.read_table(self.raw_dir+'/ml-1m/movies.dat', \n",
    "                               sep='::', \n",
    "                               header=None, \n",
    "                               names=mnames, \n",
    "                               engine='python',\n",
    "                               encoding='latin-1')\n",
    "        \n",
    "        # 参考上面 data exploration， 这个就是拼成一个 有下面这些 column 的 dataframe\n",
    "        # user_id, movie_id, rating, timestamp, gender, age, occupation, zip, title, genres\n",
    "        dat = pd.merge(pd.merge(ratings, users), movies)\n",
    "\n",
    "        return users, ratings, movies, dat\n",
    "\n",
    "    def process(self):\n",
    "        print('run process')\n",
    "        # load information from file\n",
    "        users, ratings, movies, dat = self._load()\n",
    "\n",
    "        # 以为你 users 和 movies 本身就是 pandas df, 然后这里就是获取 unique users 和 movies  的响应的 id\n",
    "        users = users['user_id']\n",
    "        movies = movies['movie_id']\n",
    "\n",
    "        num_users = config_dict[\"num_users\"]\n",
    "        if num_users != -1:\n",
    "            users = users[:num_users]\n",
    "\n",
    "        user_ids = range(len(users))\n",
    "        movie_ids = range(len(movies))\n",
    "\n",
    "        user_to_id = dict(zip(users, user_ids))\n",
    "        movie_to_id = dict(zip(movies, movie_ids))\n",
    "\n",
    "        # get adjacency info\n",
    "        self.num_user = users.shape[0]\n",
    "        self.num_item = movies.shape[0]\n",
    "\n",
    "        # initialize the adjacency matrix\n",
    "        rat = torch.zeros(self.num_user, self.num_item)\n",
    "\n",
    "        # 所以这里是开始 build adjacency matrix?\n",
    "        for index, row in ratings.iterrows():\n",
    "            user, movie, rating = row[:3]\n",
    "            if num_users != -1:\n",
    "                if user not in user_to_id: break\n",
    "            # create ratings matrix where (i, j) entry represents the ratings\n",
    "            # of movie j given by user i.\n",
    "            rat[user_to_id[user], movie_to_id[movie]] = rating\n",
    "\n",
    "        # create Data object\n",
    "        # 这个又是  from torch_geometric.data 里面的\n",
    "        data = Data(edge_index = rat,\n",
    "                    raw_edge_index = rat.clone(),\n",
    "                    data = ratings,\n",
    "                    users = users,\n",
    "                    items = movies)\n",
    "\n",
    "        # apply any pre-transformation\n",
    "        # 我们应该是没有这个\n",
    "        if self.pre_transform is not None:\n",
    "            data = self.pre_transform(data, self.pre_transform_args)\n",
    "\n",
    "        # apply any post_transformation\n",
    "        # if self.transform is not None:\n",
    "        #     # data = self.transform(data, self.transform_args)\n",
    "        data = self.transform(data, [rating_threshold])\n",
    "\n",
    "        # save the processed data into .pt file\n",
    "        # A PT file is a machine learning model created using PyTorch\n",
    "        torch.save(data, osp.join(self.processed_dir, f'data_movielens.pt'))\n",
    "        print('process finished')\n",
    "      \n",
    "    def len(self):\n",
    "        \"\"\"\n",
    "        return the number of examples in your graph\n",
    "        # 这个是啥意思？number of examples?? 这个咋定义?\n",
    "        \"\"\"\n",
    "        # TODO: how to define number of examples\n",
    "        # 我估计可以拿 上面 dat 的 shape\n",
    "        \n",
    "        users, ratings, movies, dat = self._load()\n",
    "        \n",
    "        return dat.shape[0]\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"\n",
    "        The logic to load a single graph\n",
    "        \"\"\"\n",
    "        # 把我们上面存的 .pt file load 出来就行\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_movielens.pt'))\n",
    "        return data\n",
    "\n",
    "    def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n",
    "        \"\"\"\n",
    "        Return two mask matrices (M, N) that represents edges present in the\n",
    "        train and validation set\n",
    "        可以看下他这里怎么 split 的..\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.num_user, self.num_item\n",
    "        except AttributeError:\n",
    "            data = self.get()\n",
    "            self.num_user = len(data[\"users\"].unique())\n",
    "            self.num_item = len(data[\"items\"].unique())\n",
    "            \n",
    "        # get number of edges masked for training and validation\n",
    "        num_train_replaced = round((test_frac + val_frac) * self.num_user * self.num_item)\n",
    "        num_val_show = round(val_frac * self.num_user * self.num_item)\n",
    "\n",
    "        # edges masked during training\n",
    "        # 这里 training 时候的数据怎么处理要注意的\n",
    "        indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n",
    "        indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n",
    "        \n",
    "        # sample part of edges from training stage to be unmasked during\n",
    "        # validation\n",
    "        indices_val_user = np.random.choice(indices_user, num_val_show)\n",
    "        indices_val_item = np.random.choice(indices_item, num_val_show)\n",
    "\n",
    "        train_mask = torch.ones(self.num_user, self.num_item)\n",
    "        train_mask[indices_user, indices_item] = 0\n",
    "\n",
    "        val_mask = train_mask.clone()\n",
    "        val_mask[indices_val_user, indices_val_item] = 1\n",
    "\n",
    "        test_mask = torch.ones_like(train_mask)\n",
    "\n",
    "        return train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931f4e4",
   "metadata": {},
   "source": [
    "# LightGCN neiborhood aggregation layer\n",
    "\n",
    "Starting with the initial embeddings $E^{(0)}$ and the bipartite graph, we iterate over each node to perform neighborhood aggregation. Note that LightGCN uses **a simple weighted sum aggregator** and **avoids the heavy-lifting feature transformation and nonlinear activation**.\n",
    "\n",
    "Within each layer, for each user in the graph, we compute its updated embedding as the weighted sum of embeddings from all its neighboring items (movies) following the formula below:\n",
    "$$ \\textbf{e}_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|} \\sqrt{|N_i|}} \\textbf{e}_i^{(k)} $$\n",
    "where $ \\textbf{e}_u^{(k)} $ and $ \\textbf{e}_i^{(k)} $ are the user and item (movie) node embeddings at the k-th layer. $ |N_u| $ and $ |N_i| $ are the user and item nodes’ number of neighbors.\n",
    "\n",
    "Similarly, for each item, the updated embedding is computed using weighted sum of its neighboring users:\n",
    "$$ \\textbf{e}_i^{(k+1)} = \\sum_{i \\in N_i} \\frac{1}{\\sqrt{|N_i|} \\sqrt{|N_u|}} \\textbf{e}_u^{(k)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089de44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    r\"\"\"The neighbor aggregation operator from the `\"LightGCN: Simplifying and\n",
    "    Powering Graph Convolution Network for Recommendation\"\n",
    "    <https://arxiv.org/abs/2002.02126#>`_ paper\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample, or :obj:`-1` to derive\n",
    "            the size from the first input(s) to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_users (int): Number of users for recommendation.\n",
    "        num_items (int): Number of items to recommend.\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int,\n",
    "                 num_users: int, \n",
    "                 num_items: int, \n",
    "                 **kwargs):\n",
    "        \n",
    "        super(LightGCNConv, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass  # There are no layer parameters to learn.\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj) -> Tensor:\n",
    "        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n",
    "        user_item = torch.zeros(self.num_users, self.num_items, device=x.device)\n",
    "        \n",
    "        # 这个是啥？\n",
    "        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n",
    "        \n",
    "        user_neighbor_counts = torch.sum(user_item, axis=1)\n",
    "        \n",
    "        item_neightbor_counts = torch.sum(user_item, axis=0)\n",
    "\n",
    "        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n",
    "        weights = user_item / torch.sqrt(user_neighbor_counts.repeat(self.num_items, 1).T * \n",
    "                                         item_neightbor_counts.repeat(self.num_users, 1))\n",
    "        \n",
    "        weights = torch.nan_to_num(weights, nan=0)\n",
    "        \n",
    "        # Q：这边 @ 是啥？ A: a @ b 就是 a dot b 也就是 dot product 的意思. ref: https://stackoverflow.com/questions/6392739/what-does-the-at-symbol-do-in-python\n",
    "        # Q: 这边 item 跑哪去了?\n",
    "        out = torch.cat((weights.T @ x[:self.num_users], weights @ x[self.num_users:]), 0)\n",
    "        return out\n",
    "\n",
    "    # Q: 这是啥？ print 好看的? A: Python __repr__() function returns the object representation in string format.\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24eb1e",
   "metadata": {},
   "source": [
    "# LightGCN model\n",
    "\n",
    "At layer combination, instead of taking the embedding of the final layer, LightGCN computes **a weighted sum of the embeddings at different layers**:\n",
    "$$ \\textbf{e}_u = \\sum_{k=0}^K \\alpha_k \\textbf{e}_u^{(k)} $$\n",
    "$$ \\textbf{e}_i = \\sum_{k=0}^K \\alpha_k \\textbf{e}_i^{(k)} $$\n",
    "with $ \\alpha \\ge 0 $. Here, alpha values can either be learned as network parameters, or set as empirical hyperparameters. It has been found that $ \\alpha = \\frac{1}{K + 1} $ works well.\n",
    "\n",
    "LightGCN predicts based on the inner product of the final user and item (movie) embeddings:\n",
    "$$ \\hat{y}_{ui} = \\textbf{e}_u^T \\textbf{e}_i $$\n",
    "This inner product measures the similarity between the user and movie, therefore allowing us to understand how likely it is for the user to like the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345b444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 config: dict,\n",
    "                 device=None,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_users  = config[\"n_users\"]\n",
    "        self.num_items  = config[\"m_items\"]\n",
    "        self.embedding_size = config[\"embedding_size\"]\n",
    "        self.in_channels = self.embedding_size\n",
    "        self.out_channels = self.embedding_size\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "\n",
    "        # 0-th layer embedding.\n",
    "        self.embedding_user_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users + self.num_items,\n",
    "            embedding_dim=self.embedding_size)\n",
    "        self.alpha = None\n",
    "\n",
    "        # random normal init seems to be a better choice when lightGCN actually\n",
    "        # don't use any non-linear activation function\n",
    "        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n",
    "        print('use NORMAL distribution initilizer')\n",
    "\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(LightGCNConv(\n",
    "                self.embedding_size, self.embedding_size,\n",
    "                num_users=self.num_users, num_items=self.num_items, **kwargs))\n",
    "\n",
    "        for _ in range(1, self.num_layers):\n",
    "            self.convs.append(\n",
    "                LightGCNConv(\n",
    "                        self.embedding_size, self.embedding_size, \n",
    "                        num_users=self.num_users, num_items=self.num_items,\n",
    "                        **kwargs))\n",
    "\n",
    "        self.device = None\n",
    "        if device is not None:\n",
    "            self.convs.to(device)\n",
    "            self.device = device\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Adj, *args, **kwargs) -> Tensor:\n",
    "        xs: List[Tensor] = []\n",
    "\n",
    "        # 这里感觉写的有点问题，没有把 layers of gcn 连起来， 不对其实有？：\n",
    "        # 参考: (尤其第一个)\n",
    "        # - https://www.kaggle.com/code/dipanjandas96/lightgcn-pytorch-from-scratch\n",
    "        # - https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e \n",
    "        #   - 发现这个也是 movie lens 呢: https://colab.research.google.com/drive/1KKugoFyUdydYC0XRyddcROzfQdMwDcnO?usp=sharing\n",
    "        # - https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/models/lightgcn.html\n",
    "        edge_index = torch.nonzero(edge_index)\n",
    "        for i in range(self.num_layers):\n",
    "            # 诶，这里就是连 LightGCNConv 了好像, 你看把上一层的 embedding x\n",
    "            # 传到下一层，然后把新的 embedding 加到 array/list 里面, 所以是有连的\n",
    "            x = self.convs[i](x, edge_index, *args, **kwargs)\n",
    "            if self.device is not None:\n",
    "                x = x.to(self.device)\n",
    "            xs.append(x)\n",
    "        xs = torch.stack(xs)\n",
    "        \n",
    "        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n",
    "        if self.device is not None:\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "            xs = xs.to(self.device)\n",
    "        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n",
    "        \n",
    "        # TODO: 这里算出来的 x 最好还要过一层 linear layer: self.out = nn.Linear(64, 1)?\n",
    "        # 然后我的 target 也要改一下，不能是 binary 而是 5 分制的 score\n",
    "        # 我觉得manually paying forward run\n",
    "        # thoughts： 我觉得这里后面其实不应该 item , user 直接✖️， 而是两个 embedding 各自\n",
    "        # 都要补一个 weight vector 然后再 dot product 然后要跟最后的 score 比，而不是直接拿 relevance \n",
    "        # 这个 binary 来比? 诶，可是他上面LightGCNConv不是已经给 embedding 有 weight 了?\n",
    "        return x\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, num_layers={self.num_layers})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f13c16",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "The utility functions allow us to retrieve embeddings and compute user-item similarities. These will become userful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b320a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUsersRating(model, users, data):\n",
    "    \"\"\" Get the embedding of users\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number, which is 1-indexed)\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "    \"\"\"\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(), data[\"edge_index\"])\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    items_emb = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users.long()]\n",
    "    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n",
    "    print(f\"getUsersRating rating {rating}\")\n",
    "    return rating\n",
    "\n",
    "def getEmbedding(model, users, pos, neg, data, mask):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    \"\"\"\n",
    "    # assuming we always search for users and items by their indices (instead of\n",
    "    # user/item number)\n",
    "    all_users_items = model(model.embedding_user_item.weight.clone(), data[\"edge_index\"] * mask)\n",
    "    all_users = all_users_items[:len(data[\"users\"])]\n",
    "    all_items = all_users_items[len(data[\"users\"]):]\n",
    "    users_emb = all_users[users]\n",
    "    pos_emb = all_items[pos]\n",
    "    neg_emb = all_items[neg]\n",
    "    n_user = len(data[\"users\"])\n",
    "    users_emb_ego = model.embedding_user_item(users)\n",
    "    \n",
    "    # offset the index to fetch embedding from user_item\n",
    "    pos_emb_ego = model.embedding_user_item(pos + n_user)\n",
    "    neg_emb_ego = model.embedding_user_item(neg + n_user)\n",
    "    \n",
    "    # ego 是啥？\n",
    "    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a8a15",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking loss (BPR loss)\n",
    "\n",
    "To train the LightGCN model, we need an objective function that aligns with our goal for movie recommendation. We use the Bayesian Personalized Ranking (BPR) loss, which encourages observed user-item predictions to have increasingly higher values than unobserved ones, along with $ L_2 $ regularization:\n",
    "$$ L_{BPR} = - \\sum_{u=1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) + \\lambda ||\\textbf{E}^{(0)} ||^2 $$\n",
    "where $ \\textbf{E}^{(0)} $ is a matrix with column vectors being the 0-th layer embeddings to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bef79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Personalized Ranking (BPR) loss \n",
    "# Q: 为什么用这个? \n",
    "# - https://towardsdatascience.com/recommender-system-using-bayesian-personalized-ranking-d30e98bba0b9\n",
    "# - https://d2l.ai/chapter_recommender-systems/ranking.html\n",
    "\n",
    "# Q: 能不能不用这个， 直接用 RMSE, 两个 embedding 弄完直接连 linear layer?? 不过这个是 \n",
    "# heterogenous graph, 得看一下怎么弄. 这里其实不需要 heterogenous graph，\n",
    "# \n",
    "# 大概看了下公式， BPR 就是一个有 negative sample 的 cross-entropy\n",
    "\n",
    "def bpr_loss(model, users, pos, neg, data, mask):\n",
    "    \"\"\" \n",
    "    INPUT:\n",
    "        model: the LightGCN model you are training on\n",
    "        users: this is the user index (note: use 0-indexed and not user number,\n",
    "            which is 1-indexed)\n",
    "        pos: positive index corresponding to an item that the user like\n",
    "            (0-indexed, note to index items starting from 0)\n",
    "        neg: negative index corresponding to an item that the user doesn't like\n",
    "        data: the entire data, used to fetch all users and all items\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "    OUTPUT:\n",
    "        loss, reg_loss\n",
    "    \"\"\"\n",
    "    # assuming we always sample the same number of positive and negative sample\n",
    "    # per user\n",
    "    assert len(users) == len(pos) and len(users) == len(neg)\n",
    "    \n",
    "    # 这了每个 return item 分别是啥呀？\n",
    "    (users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0) = getEmbedding(model, \n",
    "                                                                              users.long(), \n",
    "                                                                              pos.long(),\n",
    "                                                                              neg.long(), \n",
    "                                                                              data, \n",
    "                                                                              mask)\n",
    "    \n",
    "    reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
    "                        posEmb0.norm(2).pow(2)  +\n",
    "                        negEmb0.norm(2).pow(2))/float(len(users))\n",
    "\n",
    "    pos_scores = torch.mul(users_emb, pos_emb)\n",
    "    pos_scores = torch.sum(pos_scores, dim=1)\n",
    "    neg_scores = torch.mul(users_emb, neg_emb)\n",
    "    neg_scores = torch.sum(neg_scores, dim=1)\n",
    "    \n",
    "    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n",
    "    \n",
    "    return loss, reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222d5d4",
   "metadata": {},
   "source": [
    "# Personalized top K precision and recall\n",
    "\n",
    "To evaluate training progress and model performance, we compute the **top K precision and recall** scores. Specifically, for each user, we rank movie items in order of decreasing similarity and choose the best K to recommend. Then, we compute the precision and recall of those K recommendations against ground truth items that the user likes and dislikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6237411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personalized_topk(pred, K, user_indices, edge_index):\n",
    "    \"\"\"Computes TopK precision and recall.\n",
    "\n",
    "    Args:\n",
    "        TODO: 这个 pred 到底是谁？ 是test set 里每个 user 对每个 item 的判断吗？好像是来自getUsersRating\n",
    "        pred: Predicted similarities between user and item. ?? \n",
    "        K: Number of items to rank.\n",
    "        user_indices: Indices of users for each prediction in `pred`.\n",
    "        edge_index: User and item connection matrix.\n",
    "\n",
    "    Returns:\n",
    "        Average Top K precision and recall for users in `user_indices`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # user_id -> list of predicted items\n",
    "    per_user_preds = collections.defaultdict(list)\n",
    "    \n",
    "    for index, user in enumerate(user_indices):\n",
    "        per_user_preds[user.item()].append(pred[index].item())\n",
    "        \n",
    "    precisions = 0.0\n",
    "    recalls = 0.0\n",
    "    \n",
    "    for user, preds in per_user_preds.items():\n",
    "        # 如果 user interact 的 item 小于 K, 怎么处理, 他这里是随便选？直到塞满？这个我跟 NCF 的那个写法就很不一样了\n",
    "        # 我那边是直接不塞， 比如 4 个预测相关，总共有5 个 relevant, 就不用 K 用 5, 这个无形间还是会增加不少差距的\n",
    "        # TODO: 这里明天试着改一下，这里我觉得很有问题, 他这里是对 predicted relevant item 来塞到 10?\n",
    "        while len(preds) < K:\n",
    "            preds.append(random.choice(range(edge_index.shape[1])))\n",
    "        \n",
    "        # 这步是啥，不是很懂\n",
    "        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n",
    "        \n",
    "        # 这步也不是很懂，没有去看 edge 怎么处理的\n",
    "        correct_preds = edge_index[user, top_items].sum().item()\n",
    "        \n",
    "        total_pos = edge_index[user].sum().item()\n",
    "        \n",
    "        precisions += correct_preds / K\n",
    "        \n",
    "        recalls += correct_preds / total_pos if total_pos != 0 else 0\n",
    "    \n",
    "    num_users = len(user_indices.unique())\n",
    "    return precisions / num_users, recalls / num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9d3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample_pos_neg(data, mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        mask: Masking matrix indicating edges present in the current\n",
    "            train / validation / test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples.\n",
    "    \"\"\"\n",
    "    print(\"=====Starting to sample=====\")\n",
    "    start = time.time()\n",
    "    samples = []\n",
    "    all_items = set(range(len(data[\"items\"])))\n",
    "    for user_index, user in enumerate(data[\"users\"]):\n",
    "        pos_items = set(\n",
    "            torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n",
    "        unknown_items = all_items.difference(\n",
    "                set(\n",
    "                    torch.nonzero(\n",
    "                        data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n",
    "        neg_items = all_items.difference(\n",
    "            set(pos_items)).difference(set(unknown_items))\n",
    "        unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n",
    "        if len(unknown_items.union(pos_items)) == 0 or \\\n",
    "                len(unknown_items.union(neg_items)) == 0:\n",
    "            continue\n",
    "        for _ in range(num_samples_per_user):\n",
    "            if len(pos_items.intersection(unmasked_items)) == 0:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                pos_item_index = random.choice(\n",
    "                    list(pos_items.intersection(unmasked_items)))\n",
    "            if len(neg_items.intersection(unmasked_items)) == 0:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(unknown_items.intersection(unmasked_items)))\n",
    "            else:\n",
    "                neg_item_index = random.choice(\n",
    "                    list(neg_items.intersection(unmasked_items)))\n",
    "            samples.append((user_index, pos_item_index, neg_item_index))\n",
    "    end = time.time()\n",
    "    print(f\"=====Sampling completed (took {end - start} seconds)=====\")\n",
    "    return torch.tensor(samples, dtype=torch.int32)\n",
    "\n",
    "def sample_pos_neg(data, train_mask, val_mask, test_mask, num_samples_per_user):\n",
    "    \"\"\"Samples (user, positive item, negative item) tuples per user.\n",
    "\n",
    "    If a user does not have a postive (negative) item, we choose an item\n",
    "    with unknown liking (an item without raw rating data).\n",
    "\n",
    "    Args:\n",
    "        data: Dataset object containing edge_index and raw ratings matrix.\n",
    "        train_mask: Masking matrix indicating edges present in train set.\n",
    "        val_mask: Masking matrix indicating edges present in validation set.\n",
    "        test_mask: Masking matrix indicating edges present in test set.\n",
    "        num_samples_per_user: Number of samples to generate for each user.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor object of (user, positive item, negative item) samples for\n",
    "        train, validation and test.\n",
    "    \"\"\"\n",
    "    train_samples = _sample_pos_neg(data, train_mask, num_samples_per_user)\n",
    "    val_samples = _sample_pos_neg(data, val_mask, num_samples_per_user)\n",
    "    test_samples = _sample_pos_neg(data, test_mask, num_samples_per_user)\n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a654fc5",
   "metadata": {},
   "source": [
    "# Prep Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18549286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Users: 200\n",
      "#Items: 3883\n",
      "use NORMAL distribution initilizer\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 6.090041160583496 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 5.583359003067017 seconds)=====\n",
      "=====Starting to sample=====\n",
      "=====Sampling completed (took 5.980459928512573 seconds)=====\n",
      "#Training samples: 100000 #Validation samples: 100000 #Test samples: 100000\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# getcwd: get current working directory in absolute path\n",
    "root = os.getcwd()\n",
    "\n",
    "movielens = MovieLens(root=root, transform=trans_ml)\n",
    "\n",
    "data = movielens.get()\n",
    "\n",
    "train_mask, val_mask, test_mask = movielens.train_val_test_split(val_frac=config_dict[\"val_frac\"],\n",
    "                                                                 test_frac=config_dict[\"test_frac\"])\n",
    "\n",
    "n_users = len(data[\"users\"].unique())\n",
    "m_items = len(data[\"items\"].unique())\n",
    "print(f\"#Users: {n_users}\")\n",
    "print(f\"#Items: {m_items}\")\n",
    "\n",
    "model_config = {\n",
    "    \"n_users\": n_users,\n",
    "    \"m_items\": m_items,\n",
    "    \"embedding_size\": config_dict[\"embedding_size\"],\n",
    "    \"num_layers\": config_dict[\"num_layers\"],\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lightGCN = LightGCN(model_config, device=device)\n",
    "\n",
    "num_samples_per_user = config_dict[\"num_samples_per_user\"]\n",
    "epochs = config_dict[\"epochs\"]\n",
    "batch_size = config_dict[\"batch_size\"]\n",
    "lr = config_dict[\"lr\"]\n",
    "weight_decay = config_dict[\"weight_decay\"]\n",
    "\n",
    "K = config_dict[\"K\"]\n",
    "\n",
    "lightGCN.to(device)\n",
    "\n",
    "samples_train, samples_val, samples_test =  sample_pos_neg(data, train_mask, val_mask, test_mask,\n",
    "                                                          num_samples_per_user)\n",
    "\n",
    "# 这边就是把这些 tensor 往  GPU 里面推，如果有 GPU\n",
    "samples_train=samples_train.to(device)\n",
    "samples_val=samples_val.to(device)\n",
    "samples_test=samples_test.to(device)\n",
    "\n",
    "train_mask=train_mask.to(device)\n",
    "val_mask=val_mask.to(device)\n",
    "test_mask=test_mask.to(device)\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "print(f\"#Training samples: {len(samples_train)}\",\n",
    "      f\"#Validation samples: {len(samples_val)}\",\n",
    "      f\"#Test samples: {len(samples_test)}\")\n",
    "\n",
    "optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n",
    "print(\"Optimizer:\", optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08a324",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "281f4dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the 0 epoch\n",
      "getUsersRating rating tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5001, 0.4999, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.4999, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5001, 0.4999, 0.5000]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Training on epoch 0 minibatch 1/782 completed\n",
      " bpr_loss on current minibatch is 0.271874, and regularization loss is --.\n",
      " Top K precision = 0.08749999999999998, recall = 0.0077243154779485105.\n",
      "getUsersRating rating tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Training on epoch 0 minibatch 101/782 completed\n",
      " bpr_loss on current minibatch is -0.235162, and regularization loss is --.\n",
      " Top K precision = 0.086734693877551, recall = 0.007464925852287229.\n",
      "getUsersRating rating tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Training on epoch 0 minibatch 201/782 completed\n",
      " bpr_loss on current minibatch is -0.445101, and regularization loss is --.\n",
      " Top K precision = 0.08653846153846151, recall = 0.007898596878855161.\n",
      "getUsersRating rating tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Training on epoch 0 minibatch 301/782 completed\n",
      " bpr_loss on current minibatch is -0.562357, and regularization loss is --.\n",
      " Top K precision = 0.07777777777777771, recall = 0.008289249373449221.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cv/sr64_lv93tn9y_hb2n8z35140000gn/T/ipykernel_44581/486200138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data, train_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpr_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlightGCN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#         reg_loss = reg_loss * weight_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         loss = loss + reg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cv/sr64_lv93tn9y_hb2n8z35140000gn/T/ipykernel_44581/1427064920.py\u001b[0m in \u001b[0;36mbpr_loss\u001b[0;34m(model, users, pos, neg, data, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                                               \u001b[0mneg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                                               \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                                                               mask)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
      "\u001b[0;32m/var/folders/cv/sr64_lv93tn9y_hb2n8z35140000gn/T/ipykernel_44581/1903920200.py\u001b[0m in \u001b[0;36mgetEmbedding\u001b[0;34m(model, users, pos, neg, data, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# assuming we always search for users and items by their indices (instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# user/item number)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mall_users_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_user_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"edge_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mall_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyg/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cv/sr64_lv93tn9y_hb2n8z35140000gn/T/ipykernel_44581/1496903935.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# 诶，这里就是连 LightGCNConv 了好像, 你看把上一层的 embedding x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# 传到下一层，然后把新的 embedding 加到 array/list 里面, 所以是有连的\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pyg/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cv/sr64_lv93tn9y_hb2n8z35140000gn/T/ipykernel_44581/243975893.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Compute weight for aggregation: 1 / sqrt(N_u * N_i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         weights = user_item / torch.sqrt(user_neighbor_counts.repeat(self.num_items, 1).T * \n\u001b[0;32m---> 48\u001b[0;31m                                          item_neightbor_counts.repeat(self.num_users, 1))\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "epochs_tracked = []\n",
    "train_topks = []\n",
    "val_topks = []\n",
    "loss_plot = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Training on the {} epoch\".format(epoch))\n",
    "    lightGCN.train()\n",
    "    loss_sum = 0\n",
    "    # Shuffle the order of rows.\n",
    "    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n",
    "    \n",
    "    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        current_batch = samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n",
    "\n",
    "        # Shuffle the order of rows.\n",
    "        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n",
    "        users = current_batch[:, 0:1]\n",
    "        pos = current_batch[:, 1:2]\n",
    "        neg = current_batch[:, 2:3]\n",
    "\n",
    "        loss, reg_loss = bpr_loss(lightGCN, users, pos, neg, data, train_mask)\n",
    "        reg_loss = reg_loss * weight_decay\n",
    "        loss = loss + reg_loss\n",
    "        loss_sum += loss.detach()\n",
    "        \n",
    "        loss_plot.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n",
    "            all_users = torch.linspace(start=0, end=n_users - 1, steps=n_users).long()\n",
    "            user_indices = current_batch[:, 0]\n",
    "            user_indices = user_indices.repeat(2).long()\n",
    "            item_indices = torch.cat((current_batch[:, 1], current_batch[:, 2])).long()\n",
    "            \n",
    "            pred = getUsersRating(lightGCN,\n",
    "                                  all_users,\n",
    "                                  data)[user_indices, item_indices]\n",
    "            \n",
    "            truth = data[\"edge_index\"][user_indices, item_indices]\n",
    "            \n",
    "            topk_precision, topk_recall = personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "            print(\"Training on epoch {} minibatch {}/{} completed\\n\".format(epoch, batch_idx+1,\n",
    "                                                                            math.ceil(len(samples_train) / batch_size)),\n",
    "                  \"bpr_loss on current minibatch is {}, and regularization loss is {}.\\n\".format(round(float(loss.detach().cpu()), 6),\n",
    "                                                                                                 round(float(reg_loss.detach().cpu()), 6)),\n",
    "                  \"Top K precision = {}, recall = {}.\".format(topk_precision, topk_recall))\n",
    "\n",
    "    if epoch % config_dict[\"epochs_per_print\"] == 0:\n",
    "        epochs_tracked.append(epoch)\n",
    "\n",
    "        # evaluation on both the trainisng and validation set\n",
    "        lightGCN.eval()\n",
    "        \n",
    "        # predict on the training set\n",
    "        users = samples_train[:, 0:1]\n",
    "        user_indices = samples_train[:, 0]\n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        item_indices = torch.cat((samples_train[:, 1], samples_train[:, 2])).long()\n",
    "        \n",
    "        pred = getUsersRating(lightGCN,\n",
    "                              users[:,0],\n",
    "                              data)[user_indices, item_indices]\n",
    "        \n",
    "        truth = data[\"edge_index\"][users.long()[:,0]][user_indices, item_indices]\n",
    "\n",
    "        train_topk_precision, train_topk_recall = personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "        train_topks.append((train_topk_precision, train_topk_recall))\n",
    "\n",
    "        # predict on the validation set\n",
    "        users_val = samples_val[:, 0:1]\n",
    "        pos_val = samples_val[:, 1:2]\n",
    "        neg_val = samples_val[:, 2:3]\n",
    "\n",
    "        loss_val, reg_loss_val = bpr_loss(lightGCN, users_val, pos_val, neg_val, data, val_mask)\n",
    "        \n",
    "        reg_loss_val = reg_loss_val * weight_decay\n",
    "\n",
    "        # predict on the validation set\n",
    "        user_indices = samples_val[:, 0]\n",
    "        \n",
    "        user_indices = user_indices.repeat(2).long()\n",
    "        \n",
    "        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n",
    "        \n",
    "        pred_val = getUsersRating(lightGCN,\n",
    "                                  users_val[:,0],\n",
    "                                  data)[user_indices, item_indices]\n",
    "        \n",
    "        truth_val = data[\"edge_index\"][users_val.long()[:,0]][user_indices, item_indices]\n",
    "        \n",
    "        val_topk_precision, val_topk_recall = personalized_topk(pred_val, K, user_indices, data[\"edge_index\"])\n",
    "        \n",
    "        val_topks.append((val_topk_precision, val_topk_recall))\n",
    "\n",
    "        print(\"\\nTraining on {} epoch completed.\\n\".format(epoch),\n",
    "              \"Average bpr_loss on train set is {} for the current epoch.\\n\".format(round(float(loss_sum/len(samples_train)), 6)),\n",
    "              \"Training top K precision = {}, recall = {}.\\n\".format(train_topk_precision, train_topk_recall),\n",
    "              \"Average bpr_loss on the validation set is {}, and regularization loss is {}.\\n\".format(round(float((loss_val+reg_loss_val)/len(samples_val)), 6),\n",
    "                                                                                                      round(float(reg_loss_val/len(samples_val)), 6)),\n",
    "              \"Validation top K precision = {}, recall = {}.\\n\".format(val_topk_precision, val_topk_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_tracked, [precision for precision, _ in train_topks], label=\"Train\")\n",
    "\n",
    "plt.plot(epochs_tracked, [precision for precision, _ in val_topks], label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} precision\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8caad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebe08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs_tracked, [recall for _, recall in train_topks],\n",
    "         label=\"Train\")\n",
    "plt.plot(epochs_tracked, [recall for _, recall in val_topks],\n",
    "         label=\"Val\")\n",
    "plt.ylabel(f\"Top {K} recall\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2d76e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed after 10 epochs\n",
      "getUsersRating rating tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        ...,\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Average bpr_loss on the test set is 7e-06, and regularization loss is 0.0.\n",
      " Top K precision = 0.08699999999999994, recall = 0.007430810538437454.\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\n",
    "lightGCN.eval()\n",
    "print(\"Training completed after {} epochs\".format(epochs))\n",
    "\n",
    "users_test = samples_test[:, 0:1]\n",
    "pos_test = samples_test[:, 1:2]\n",
    "neg_test = samples_test[:, 2:3]\n",
    "\n",
    "loss_test, reg_loss_test = bpr_loss(lightGCN, users_test, pos_test, neg_test, data, test_mask)\n",
    "\n",
    "reg_loss_test = reg_loss_test * weight_decay\n",
    "\n",
    "# predict on the test set\n",
    "user_indices = samples_test[:, 0]\n",
    "user_indices = user_indices.repeat(2).long()\n",
    "item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n",
    "\n",
    "pred_test = getUsersRating(lightGCN, users_test[:,0], data)[user_indices, item_indices]\n",
    "\n",
    "truth_test = data[\"edge_index\"][users_test.long()[:,0]][user_indices, item_indices]\n",
    "\n",
    "test_topk_precision, test_topk_recall = personalized_topk(pred_test, K, user_indices, data[\"edge_index\"])\n",
    "\n",
    "print(\"Average bpr_loss on the test set is {}, and regularization loss is {}.\\n\"\n",
    "      .format(\n",
    "          round(float((loss_test+reg_loss_test)/len(samples_test)), 6),\n",
    "          round(float(reg_loss_test/len(samples_test)), 6)\n",
    "      ),\n",
    "      \"Top K precision = {}, recall = {}.\".format(test_topk_precision, test_topk_recall))\n",
    "\n",
    "# Save model embeddings.\n",
    "torch.save(lightGCN, config_dict[\"model_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e8bf8",
   "metadata": {},
   "source": [
    "# Run matrix factorization as baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9d6bb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(user_item, rank):\n",
    "    \"\"\"Runs matrix factorization on `user_item` and get user-item similarities.\n",
    "\n",
    "    Args:\n",
    "        user_item: User-item connectivity matrix.\n",
    "        rank: Number of numbers to represent a user / item.\n",
    "\n",
    "    Returns:\n",
    "        User-item similarities.\n",
    "    \"\"\"\n",
    "    weights, (user_factors, item_factors) = decomposition.parafac(user_item, rank)\n",
    "    similarities = user_factors @ item_factors.T\n",
    "    return 1 / (1 + np.exp(- similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2f839e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (PARAFAC matrix factorization) produces  Top K precision = 0.03699999999999999, recall = 0.002789248078607412.\n"
     ]
    }
   ],
   "source": [
    "# Compute baseline metrics using matrix factorization.\n",
    "baseline_pred = matrix_factorization(\n",
    "        data[\"edge_index\"].detach().cpu().numpy(),\n",
    "        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n",
    "\n",
    "baseline_topk_precision, baseline_topk_recall = personalized_topk(baseline_pred, \n",
    "                                                                  K, \n",
    "                                                                  user_indices, \n",
    "                                                                  data[\"edge_index\"])\n",
    "\n",
    "print(\"Baseline (PARAFAC matrix factorization) produces \",\n",
    "      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n",
    "                                                  baseline_topk_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为什么这里拿一个 item 都这么困难？？\n",
    "# 参考下这里: GNN Project #2 - Creating a Custom Dataset in Pytorch Geometric\n",
    "#      https://www.youtube.com/watch?v=QLIkOtKS4os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d34f5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba775e19",
   "metadata": {},
   "source": [
    "# Running Notes: \n",
    "Sep/10/2022\n",
    "卧槽, 这个代码好复杂， 不知道这个作者写了多少个小时，我都看懵了...\n",
    "- 我觉得我这个代码能讲一遍我就很厉害了\n",
    "- 有的还真是看不懂，一个是 PyG 不熟悉，还有真的是 python 水平有待提高..\n",
    "- 一点点啃，看下需要多久. (我是 sep/09 开始认真看的) 给自己两三个礼拜吧\n",
    "- 我觉得还得结合着 pyG [官方文档](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html)看，不然有点难懂 \n",
    "- 还有看一下他这边 node feature 怎么用上的?\n",
    "- TODO: 思考一个问题，是不是他的 edge 没有处理好，他这里基本上是 >3 变成有，<3 是没有，那么就变成跟我的 RMSE 的 NCF 做法，他丢失了非常多的信息了， 所以得研究一下怎么改\n",
    "今天先休息吧，明天继续啃\n",
    "\n",
    "Sep/12/2022 \n",
    "- 发现一个 GNN 视频，讲的还不错呢, 也是讲 PyG, 哈哈，可以学习一下: https://www.youtube.com/c/DeepFindr/videos ， 但是他图片讲的不错，没有想我这样仔细讲代码\n",
    "- 这里是个 Kumo.ai 的创始人的 example: https://github.com/rusty1s/examples\n",
    "- 发现 AntonioLonga 的视频真的好像过的挺细的，有机会可以看一下\n",
    "\n",
    "- 如果还看不懂，就得把 Lindsey AI 的视频看一下: https://www.youtube.com/watch?v=-UjytpbqX4A&t=2016s\n",
    "- 我觉得把 BPR loss 改成 RMSE 应该差不多？然后也是要 random sample 一下？\n",
    "\n",
    "Sep/14/2022\n",
    "- 可能都不是 BPR 的问题，你看这个 https://www.kaggle.com/code/dipanjandas96/lightgcn-pytorch-from-scratch, 基本上思路一样，只是不用 PyG 写，然后可能一些细节不太一样，这个能跑到 0.2152 的 recall@10\n",
    "- 我觉得 evaluation personalized_topk() 这个是不是太有问题了\n",
    "- follow 的好辛苦.. 这代码写的真多没法看... 而且 python 的 type 交代的非常不清楚，就得一点点挖.. 实在不行，我用 pycharm 来看?\n",
    "试了一下，效果不是很好，因为 pyTorch 底层貌似是 c， 所以其实 click thru 也看不到啥\n",
    "- 也许最好的办法，还是 manually step thru 一下一个简单的 dataset\n",
    "- 我自己开了一个 Data Exploration 的 section 把, create dataset 那部分自己过了一下，就感觉清晰很多，所以还是要一步步过, 明天继续"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ae8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6415f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
