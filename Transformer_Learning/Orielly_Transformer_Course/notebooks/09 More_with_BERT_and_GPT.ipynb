{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "265db32f",
   "metadata": {},
   "source": [
    "## 9.1 Siamese BERT-networks for semantic searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6d93f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "from random import sample, seed, shuffle\n",
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "89f2aca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/eac3273a8097dda671e3bea1db32c616e74f36a306c65b4858171c98d6db83e9.084aa7284f3a51fa1c8f0641aa04c47d366fbd18711f29d0a995693cfdbc9c9e\n",
      "All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at deepset/roberta-base-squad2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/81c80edb4c6cefa5cae64ccfdb34b3b309ecaf60da99da7cd1c17e24a5d36eb5.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/b87d46371731376b11768b7839b1a5938a4f77d6bd2d9b683f167df0026af432.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/special_tokens_map.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c9d2c178fac8d40234baa1833a3b1903d393729bf93ea34da247c07db24900d0.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/e8a600814b69e3ee74bb4a7398cc6fef9812475010f16a6c9f151b2c2772b089.451739a2f3b82c3375da0dfc6af295bedc4567373b171f514dd09a4cc4b31513\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.10961687564849854,\n",
       " 'start': 545,\n",
       " 'end': 591,\n",
       " 'answer': 'data scientist, start-up founder, and educator'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON = 'Sinan Ozdemir'\n",
    "\n",
    "# Note this is NOT an efficient way to search on google. This is done simply for education purposes\n",
    "google_html = BeautifulSoup(requests.get(f'https://www.google.com/search?q={PERSON}').text).get_text()[:1024]\n",
    "\n",
    "nlp = pipeline('question-answering', \n",
    "               model='deepset/roberta-base-squad2', \n",
    "               tokenizer='deepset/roberta-base-squad2', \n",
    "               max_length=10)\n",
    "\n",
    "nlp(f'Who is {PERSON}?', google_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04e779f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 documents/paragraphs\n"
     ]
    }
   ],
   "source": [
    "# textbook about insects\n",
    "text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode()\n",
    "\n",
    "# Only keep documents of at least 100 characters\n",
    "documents = list(filter(lambda x: len(x) > 100, text.split('\\r\\n\\r\\n')))\n",
    "\n",
    "documents = np.array(documents)\n",
    "\n",
    "print(f'There are {len(documents)} documents/paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "28bc736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertModel.\n",
      "\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
      "loading configuration file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Didn't find file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/added_tokens.json. We won't load it.\n",
      "loading file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/vocab.txt\n",
      "loading file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/tokenizer.json\n",
      "loading file None\n",
      "loading file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/special_tokens_map.json\n",
      "loading file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/tokenizer_config.json\n",
      "loading configuration file /Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"/Users/sinanozdemir/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-v4/\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model pre-trained on an asymmetric semantic search task\n",
    "# We use the Bi-Encoder to encode all the documents, so that we can use it with sematic search\n",
    "bi_encoder = SentenceTransformer('msmarco-distilbert-base-v4')\n",
    "bi_encoder.max_seq_length = 256     # Truncate long documents to 256 tokens\n",
    "\n",
    "bi_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19c7a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d81e2f97594224b422f6704aa90de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([79, 768])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documents are encoded by calling model.encode(). This takes about 5 minutes on my laptop\n",
    "document_embeddings = bi_encoder.encode(documents, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "de7b4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = 'How many horns does a flea have?'  # a natural language query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ec83525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 14, 'score': 0.489949107170105},\n",
       " {'corpus_id': 19, 'score': 0.24793732166290283},\n",
       " {'corpus_id': 21, 'score': 0.18478815257549286}]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the query using the bi-encoder and find relevant documents\n",
    "question_embedding = bi_encoder.encode(QUESTION, convert_to_tensor=True)\n",
    "\n",
    "# Number of documents to retrieve with the bi-encoder\n",
    "hits = util.semantic_search(question_embedding, document_embeddings, top_k=3)[0]\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ada5d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many horns does a flea have?\n",
      "\n",
      "Document 1 Cos_Sim 0.490:\n",
      "\n",
      "When examined by a microscope, the flea is a pleasant object. The body\r\n",
      "is curiously adorned with a suit of polished armour, neatly jointed, and\r\n",
      "beset with a great number of sharp pins almost like the quills of a\r\n",
      "porcupine: it has a small head, large eyes, two horns, or feelers, which\r\n",
      "proceed from the head, and four long legs from the breast; they are very\r\n",
      "hairy and long, and have several joints, which fold as it were one\r\n",
      "within another.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.248:\n",
      "\n",
      "The Chego is a very small animal, about one fourth the size of a common\r\n",
      "flea: it is very troublesome, in warm climates, to the poor blacks, such\r\n",
      "as go barefoot, and the slovenly: it penetrates the skin, under which it\r\n",
      "lays a bunch of eggs, which swell to the bigness of a small pea.\n",
      "\n",
      "\n",
      "Document 3 Cos_Sim 0.185:\n",
      "\n",
      "\r\n",
      "This is one of the largest of the insect tribe. It is met with in\r\n",
      "different countries, and of various sizes, from two or three inches to\r\n",
      "nearly a foot in length: it somewhat resembles a lobster, and casts its\r\n",
      "skin, as the lobster does its shell.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Question: {QUESTION}\\n')\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    \n",
    "    print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e32cdde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8524739146232605, 'start': 259, 'end': 262, 'answer': 'two'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer the question from the top document\n",
    "nlp(QUESTION, str(documents[hits[0]['corpus_id']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "901b68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called an \"Open Book Q/A\" System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc6128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f376c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset adversarial_qa (/Users/sinanozdemir/.cache/huggingface/datasets/adversarial_qa/adversarialQA/1.0.0/92356be07b087c5c6a543138757828b8d61ca34de8a87807d40bbc0e6c68f04b)\n"
     ]
    }
   ],
   "source": [
    "# load up the adversarial_qa dataset from the Q/A use-case\n",
    "training_qa = load_dataset('adversarial_qa', 'adversarialQA', split='train')\n",
    "\n",
    "good_training_data = []\n",
    "bad_training_data = []\n",
    "    \n",
    "last_example = None\n",
    "for example in training_qa:\n",
    "    if last_example and example['context'] != last_example['context']:\n",
    "        bad_training_data.append((example['question'], last_example['context'], 0.0))  #  add neutral examples\n",
    "    # question, context, label is 1 if should be matched together\n",
    "    good_training_data.append((example['question'], example['context'], 1.0))\n",
    "    last_example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "40ca4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2647)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_training_data), len(bad_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "379d8a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What letter designates what Ektachrome is designed for?',\n",
       " 'Some high-speed black-and-white films, such as Ilford Delta 3200 and Kodak T-MAX P3200, are marketed with film speeds in excess of their true ISO speed as determined using the ISO testing method. For example, the Ilford product is actually an ISO 1000 film, according to its data sheet. The manufacturers do not indicate that the 3200 number is an ISO rating on their packaging. Kodak and Fuji also marketed E6 films designed for pushing (hence the \"P\" prefix), such as Ektachrome P800/1600 and Fujichrome P1600, both with a base speed of ISO 400.',\n",
       " 1.0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_training_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "920aa0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What film beside Ektachrome and Fujichorme is designed for pushing?',\n",
       " 'The Weston Cadet (model 852 introduced in 1949), Direct Reading (model 853 introduced 1954) and Master III (models 737 and S141.3 introduced in 1956) were the first in their line of exposure meters to switch and utilize the meanwhile established ASA scale instead. Other models used the original Weston scale up until ca. 1955. The company continued to publish Weston film ratings after 1955, but while their recommended values often differed slightly from the ASA film speeds found on film boxes, these newer Weston values were based on the ASA system and had to be converted for use with older Weston meters by subtracting 1/3 exposure stop as per Weston\\'s recommendation. Vice versa, \"old\" Weston film speed ratings could be converted into \"new\" Westons and the ASA scale by adding the same amount, that is, a film rating of 100 Weston (up to 1955) corresponded with 125 ASA (as per ASA PH2.5-1954 and before). This conversion was not necessary on Weston meters manufactured and Weston film ratings published since 1956 due to their inherent use of the ASA system; however the changes of the ASA PH2.5-1960 revision may be taken into account when comparing with newer ASA or ISO values.',\n",
       " 0.0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_training_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "441fddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/training/overview.html for more information on training\n",
    "\n",
    "seed(42)  # seed our upcoming sample\n",
    "\n",
    "sampled_training_data = sample(good_training_data, 500) + sample(bad_training_data, 500)\n",
    "\n",
    "shuffle(sampled_training_data)  # shuffle our data around\n",
    "\n",
    "training_index = int(.8 * len(sampled_training_data))  # Get an 80/20 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "067c6bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': '',\n",
       " 'texts': ('What changed after the eigth century?',\n",
       "  'There is disagreement about the origin of the term, but general consensus that \"cardinalis\" from the word cardo (meaning \\'pivot\\' or \\'hinge\\') was first used in late antiquity to designate a bishop or priest who was incorporated into a church for which he had not originally been ordained. In Rome the first persons to be called cardinals were the deacons of the seven regions of the city at the beginning of the 6th century, when the word began to mean “principal,” “eminent,” or \"superior.\" The name was also given to the senior priest in each of the \"title\" churches (the parish churches) of Rome and to the bishops of the seven sees surrounding the city. By the 8th century the Roman cardinals constituted a privileged class among the Roman clergy. They took part in the administration of the church of Rome and in the papal liturgy. By decree of a synod of 769, only a cardinal was eligible to become pope. In 1059, during the pontificate of Nicholas II, cardinals were given the right to elect the pope under the Papal Bull In nomine Domini. For a time this power was assigned exclusively to the cardinal bishops, but the Third Lateran Council in 1179 gave back the right to the whole body of cardinals. Cardinals were granted the privilege of wearing the red hat by Pope Innocent IV in 1244.'),\n",
       " 'label': 1.0}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the training examples\n",
    "train_examples = [InputExample(texts=t[:2], label=t[2]) for t in sampled_training_data[:training_index]]\n",
    "\n",
    "train_examples[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d22f57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the train dataset, a dataloader and the train loss\n",
    "# A data loader is the object that specifically shuffles/grabs batches of data from a Dataset\n",
    "# We don't usually have to explicitly create one using the Trainer because it has a default loader built in\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(bi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "baa099e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 31]), torch.Size([32, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(question_batch, context_batch), labels = next(iter(train_dataloader))  # get a sample batch of data\n",
    "\n",
    "question_batch['input_ids'].shape, context_batch['input_ids'].shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e306f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2af814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation data, sentences1 and sentences2 are lists of questions and context respectively and scores are 0 or 1\n",
    "sentences1, sentences2, scores = zip(*sampled_training_data[training_index:])\n",
    "\n",
    "# evaluator will evaluate embedding closeness\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9343a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044913287672261"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator)  # initial evalaution (higher embedding similarity is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8269f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884ac6caebcd42b2855e5f86d6d8475f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd510a8cc3f47e0929f0af9d830bce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ir/results/config.json\n",
      "Model weights saved in ir/results/pytorch_model.bin\n",
      "tokenizer config file saved in ir/results/tokenizer_config.json\n",
      "Special tokens file saved in ir/results/special_tokens_map.json\n",
      "Configuration saved in ir/results/config.json\n",
      "Model weights saved in ir/results/pytorch_model.bin\n",
      "tokenizer config file saved in ir/results/tokenizer_config.json\n",
      "Special tokens file saved in ir/results/special_tokens_map.json\n",
      "Configuration saved in ir/results/config.json\n",
      "Model weights saved in ir/results/pytorch_model.bin\n",
      "tokenizer config file saved in ir/results/tokenizer_config.json\n",
      "Special tokens file saved in ir/results/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd5461bf82b46aeb42d0bb127d8ff20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ir/results/config.json\n",
      "Model weights saved in ir/results/pytorch_model.bin\n",
      "tokenizer config file saved in ir/results/tokenizer_config.json\n",
      "Special tokens file saved in ir/results/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model using the fit method\n",
    "bi_encoder.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], \n",
    "    output_path='ir/results',\n",
    "    epochs=2, \n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a20fdca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5050109764878448"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator)  # final evalaution (higher embedding similarity is better)\n",
    "# Not a huge jump in performance with 2 epochs. We could try more data or more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cefe5dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ir/results/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"ir/results/\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ir/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertModel.\n",
      "\n",
      "All the weights of DistilBertModel were initialized from the model checkpoint at ir/results/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
      "Didn't find file ir/results/added_tokens.json. We won't load it.\n",
      "loading file ir/results/vocab.txt\n",
      "loading file ir/results/tokenizer.json\n",
      "loading file None\n",
      "loading file ir/results/special_tokens_map.json\n",
      "loading file ir/results/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# load fine-tuned IR model\n",
    "finetuned_bi_encoder = SentenceTransformer('ir/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b62e97a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d544cd18c74c529ef5fbf4fd6acd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many horns does a flea have?\n",
      "\n",
      "Document 1 Cos_Sim 0.492:\n",
      "\n",
      "When examined by a microscope, the flea is a pleasant object. The body\r\n",
      "is curiously adorned with a suit of polished armour, neatly jointed, and\r\n",
      "beset with a great number of sharp pins almost like the quills of a\r\n",
      "porcupine: it has a small head, large eyes, two horns, or feelers, which\r\n",
      "proceed from the head, and four long legs from the breast; they are very\r\n",
      "hairy and long, and have several joints, which fold as it were one\r\n",
      "within another.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.250:\n",
      "\n",
      "The Chego is a very small animal, about one fourth the size of a common\r\n",
      "flea: it is very troublesome, in warm climates, to the poor blacks, such\r\n",
      "as go barefoot, and the slovenly: it penetrates the skin, under which it\r\n",
      "lays a bunch of eggs, which swell to the bigness of a small pea.\n",
      "\n",
      "\n",
      "Document 3 Cos_Sim 0.187:\n",
      "\n",
      "\r\n",
      "This is one of the largest of the insect tribe. It is met with in\r\n",
      "different countries, and of various sizes, from two or three inches to\r\n",
      "nearly a foot in length: it somewhat resembles a lobster, and casts its\r\n",
      "skin, as the lobster does its shell.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Slightly more confident results!\n",
    "\n",
    "document_embeddings = finetuned_bi_encoder.encode(documents, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "question_embedding = finetuned_bi_encoder.encode(QUESTION, convert_to_tensor=True)\n",
    "\n",
    "# Get document hits\n",
    "hits = util.semantic_search(question_embedding, document_embeddings, top_k=3)[0]\n",
    "\n",
    "print(f'Question: {QUESTION}\\n')\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    \n",
    "    print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7585813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gutenberg_to_documents(gutenberg_url, bi_encoder):\n",
    "    text = urlopen(gutenberg_url).read().decode()\n",
    "    documents = np.array(list(filter(lambda x: len(x) > 100, text.split('\\r\\n\\r\\n'))))\n",
    "    print(f'There are {len(documents)} documents/paragraphs')\n",
    "    return documents, bi_encoder.encode(documents)\n",
    "\n",
    "def retrieve_relevant_documents(bi_encoder, query, documents, document_embeddings, hits=3):\n",
    "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    hits = util.semantic_search(query_embedding, document_embeddings, top_k=hits)[0]\n",
    "\n",
    "    for i, hit in enumerate(hits):\n",
    "        print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "        print('\\n')\n",
    "    print(f\"Answer from Top Document: {nlp(query, str(documents[hits[0]['corpus_id']]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc99564c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1402 documents/paragraphs\n"
     ]
    }
   ],
   "source": [
    "banks_to_bassoon_documents, banks_to_bassoon_embeddings = gutenberg_to_documents(\n",
    "    'https://www.gutenberg.org/cache/epub/27480/pg27480.txt', finetuned_bi_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "30d5a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Cos_Sim 0.754:\n",
      "\n",
      "BANSHEE (Irish _bean sidhe_; Gaelic _ban sith_, \"woman of the fairies\"), a\n",
      "supernatural being in Irish and general Celtic folklore, whose mournful\n",
      "screaming, or \"keening,\" at night is held to foretell the death of some\n",
      "member of the household visited. In Ireland legends of the banshee belong\n",
      "more particularly to certain families in whose records periodic visits from\n",
      "the spirit are chronicled. A like ghostly informer figures in Brittany\n",
      "folklore. The Irish banshee is held to be the distinction only of families\n",
      "of pure Milesian descent. The Welsh have the banshee under the name _gwrach\n",
      "y Rhibyn_ (witch of Rhibyn). Sir Walter Scott mentions a belief in the\n",
      "banshee as existing in the highlands of Scotland (_Demonology and\n",
      "Witchcraft_, p. 351). A Welsh death-portent often confused with the gwrach\n",
      "y Rhibyn and banshee is the _cyhyraeth_, the groaning spirit.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.324:\n",
      "\n",
      "BANNU, a town and district of British India, in the Derajat division of the\n",
      "North-West Frontier Province. The town (also called Edwardesabad and\n",
      "Dhulipnagar) lies in the north-west corner of the district, in the valley\n",
      "of the Kurram river. Pop. (1901) 14,300. It forms the base for all punitive\n",
      "expeditions to the Tochi Valley and Waziri frontier.\n",
      "\n",
      "\n",
      "Answer from Top Document: {'score': 0.04472850263118744, 'start': 76, 'end': 94, 'answer': 'supernatural being'}\n"
     ]
    }
   ],
   "source": [
    "retrieve_relevant_documents(finetuned_bi_encoder,\n",
    "    'What is a banshee?', banks_to_bassoon_documents, banks_to_bassoon_embeddings, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f3931a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Cos_Sim 0.797:\n",
      "\n",
      "[3] The date 1876 is taken as being that when the Imperial Bank of Germany\r\n",
      "came into full operation.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.573:\n",
      "\n",
      "Similar banks had been established in Middelburg, (March 28th, 1616), in\r\n",
      "Hamburg (1619) and in Rotterdam (February 9th, 1635). Of these the Bank of\r\n",
      "Hamburg carried on much the largest business and survived the longest. It\r\n",
      "was not till the 15th of February 1873 that its existence was closed by the\r\n",
      "act of the German parliament which decreed that Germany should possess a\r\n",
      "gold standard, and thus removed those conditions of the local medium of\r\n",
      "exchange--silver coins of very different intrinsic values--whose\r\n",
      "circulation had provided an ample field for the operations of the bank. The\r\n",
      "business of the Bank of Hamburg had been conducted in absolute accordance\r\n",
      "with the regulations under which it was founded.\n",
      "\n",
      "\n",
      "Answer from Top Document: {'score': 0.1893429160118103, 'start': 13, 'end': 17, 'answer': '1876'}\n"
     ]
    }
   ],
   "source": [
    "retrieve_relevant_documents(finetuned_bi_encoder,\n",
    "    'When was the Imperial Bank of Germany founded?', banks_to_bassoon_documents, banks_to_bassoon_embeddings, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361af40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0bb96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53187d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193f2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de5138c6",
   "metadata": {},
   "source": [
    "## 9.2 Teaching GPT multiple tasks at once with prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c74f0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, GPT2LMHeadModel, pipeline, \\\n",
    "                         GPT2Tokenizer\n",
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463affd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06be4764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96512, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                 Summary  \\\n",
       "0  Great taffy at a great price.  There was a wid...             Great taffy   \n",
       "1  This taffy is so good.  It is very soft and ch...  Wonderful, tasty taffy   \n",
       "2  Right now I'm mostly just sprouting this so my...              Yay Barley   \n",
       "3  This is a very healthy dog food. Good for thei...        Healthy Dog Food   \n",
       "4  good flavor! these came securely packed... the...       fresh and greasy!   \n",
       "\n",
       "   Score  \n",
       "0      5  \n",
       "1      5  \n",
       "2      5  \n",
       "3      5  \n",
       "4      4  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/snap/amazon-fine-food-reviews?select=Reviews.csv\n",
    "\n",
    "reviews = pd.read_csv('../data/reviews.csv')\n",
    "\n",
    "print(reviews.shape)\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c02af40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Histogram of Review Length'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews['Text'].str.len().plot(kind='hist', title='Histogram of Review Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d355929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Histogram of Summary Length'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews['Summary'].str.len().plot(kind='hist', title='Histogram of Summary Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e068184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Histogram of Summary Length'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# remove very short and very long summaries\n",
    "reviews = reviews[(reviews['Summary'].str.len() >= 10) & (reviews['Summary'].str.len() < 25)]\n",
    "\n",
    "reviews['Summary'].str.len().plot(kind='hist', title='Histogram of Summary Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a4b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "683c807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['Sentiment'] = reviews['Score'].map(lambda x: 'positive' if x >= 4 else 'neutral' if x == 3 else 'negative')\n",
    "\n",
    "# Take 1,000 examples from each sentiment group\n",
    "reviews = reviews.groupby('Sentiment', group_keys=False).apply(lambda x: x.sample(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "afe1936d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAR8UlEQVR4nO3dfbBd133W8e+DlDiO3CQWru+4klu5QbS1Y5riO07SQLlFDBbQQR4ag4LdyMUzosUNTXCnIzPMpNBRx6V1oRhMq6ZB6lTUVUwYqTFtbVRugQy2YyduZFlxrImNo1jYaUJeFIobmR9/nOXmjHz1to90jpT1/czcOWuvs9Ze69yztJ+793lRqgpJUn/+1KwnIEmaDQNAkjplAEhSpwwASeqUASBJnVo+6wmczCWXXFJr1qwZ1PerX/0qK1asOLMTkhrXl86mSdfXo48++odV9c0nanPOB8CaNWt45JFHBvVdXFxkYWHhzE5IalxfOpsmXV9J/ufJ2ngJSJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXqpAGQ5ANJXkjy+FjdyiQPJHmq3V48dt/tSQ4meTLJdWP11yTZ1+77V0ly5h+OJOlUncoZwHZg/TF1W4C9VbUW2Nu2SXIlsBG4qvW5O8my1uffApuBte3n2H1KkqbopAFQVf8V+MIx1RuAHa28A7h+rP6eqnqxqp4GDgLXJrkMeF1V/Y8a/QcEvzbWR5I0A0M/CTxXVYcBqupwkktb/SrgwbF2h1rd11r52PolJdnM6GyBubk5FhcXB03yhS98ibt27h7UdxJXr3r91MfU9M1qfYFrbJr2ffZLMxn3itcvG3zsO1Vn+qsglrquXyeoX1JVbQO2AczPz9fQj0PftXM3d+6b/rddPHPjwtTH1PTNan2Ba2yabt5y30zG3b5+xVn/qpGh7wJ6vl3Wod2+0OoPAZePtVsNPNfqVy9RL0makaEBsAfY1MqbgN1j9RuTXJDkCkYv9j7cLhd9Jclb27t/3jXWR5I0Ayc9f03yG8ACcEmSQ8D7gDuAXUluAZ4FbgCoqv1JdgFPAEeBW6vqpbarH2X0jqILgd9uP5KkGTlpAFTVO49z17rjtN8KbF2i/hHgTac1O0nSWeMngSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdmigAkrw3yf4kjyf5jSSvSbIyyQNJnmq3F4+1vz3JwSRPJrlu8ulLkoYaHABJVgH/EJivqjcBy4CNwBZgb1WtBfa2bZJc2e6/ClgP3J1k2WTTlyQNNekloOXAhUmWA68FngM2ADva/TuA61t5A3BPVb1YVU8DB4FrJxxfkjTQ8qEdq+qzSX4eeBb4I+D+qro/yVxVHW5tDie5tHVZBTw4totDre4VkmwGNgPMzc2xuLg4aI5zF8JtVx8d1HcSQ+er88us1he4xqZpVs/xkSNHzvrzPDgA2rX9DcAVwBeBDya56URdlqirpRpW1TZgG8D8/HwtLCwMmuNdO3dz577BD3GwZ25cmPqYmr5ZrS9wjU3TzVvum8m429evYOix71RNcgnorwBPV9XnquprwIeA7wWeT3IZQLt9obU/BFw+1n81o0tGkqQZmCQAngXemuS1SQKsAw4Ae4BNrc0mYHcr7wE2JrkgyRXAWuDhCcaXJE1gktcAHkpyL/Ax4CjwcUaXbS4CdiW5hVFI3NDa70+yC3iitb+1ql6acP6SpIEmuoBZVe8D3ndM9YuMzgaWar8V2DrJmJKkM8NPAktSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6NVEAJHlDknuTfDLJgSRvS7IyyQNJnmq3F4+1vz3JwSRPJrlu8ulLkoaa9AzgF4HfqarvBL4bOABsAfZW1Vpgb9smyZXARuAqYD1wd5JlE44vSRpocAAkeR3wfcCvAlTVH1fVF4ENwI7WbAdwfStvAO6pqher6mngIHDt0PElSZOZ5Azg24HPAf8uyceTvD/JCmCuqg4DtNtLW/tVwGfG+h9qdZKkGVg+Yd8/D7y7qh5K8ou0yz3HkSXqasmGyWZgM8Dc3ByLi4uDJjh3Idx29dFBfScxdL46v8xqfYFrbJpm9RwfOXLkrD/PkwTAIeBQVT3Utu9lFADPJ7msqg4nuQx4Yaz95WP9VwPPLbXjqtoGbAOYn5+vhYWFQRO8a+du7tw3yUMc5pkbF6Y+pqZvVusLXGPTdPOW+2Yy7vb1Kxh67DtVgy8BVdX/Aj6T5Dta1TrgCWAPsKnVbQJ2t/IeYGOSC5JcAawFHh46viRpMpP++fJuYGeSVwOfBn6YUajsSnIL8CxwA0BV7U+yi1FIHAVuraqXJhxfkjTQRAFQVY8B80vcte447bcCWycZU5J0ZvhJYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tTEAZBkWZKPJ/lw216Z5IEkT7Xbi8fa3p7kYJInk1w36diSpOHOxBnAjwMHxra3AHurai2wt22T5EpgI3AVsB64O8myMzC+JGmAiQIgyWrgbwDvH6veAOxo5R3A9WP191TVi1X1NHAQuHaS8SVJwy2fsP+/BH4S+KaxurmqOgxQVYeTXNrqVwEPjrU71OpeIclmYDPA3Nwci4uLgyY3dyHcdvXRQX0nMXS+Or/Man2Ba2yaZvUcHzly5Kw/z4MDIMkPAC9U1aNJFk6lyxJ1tVTDqtoGbAOYn5+vhYVT2f0r3bVzN3fumzTjTt8zNy5MfUxN36zWF7jGpunmLffNZNzt61cw9Nh3qiZZvW8H/maSvw68Bnhdkl8Hnk9yWfvr/zLghdb+EHD5WP/VwHMTjC9JmsDg1wCq6vaqWl1Vaxi9uPt7VXUTsAfY1JptAna38h5gY5ILklwBrAUeHjxzSdJEzsb56x3AriS3AM8CNwBU1f4ku4AngKPArVX10lkYX5J0Cs5IAFTVIrDYyp8H1h2n3VZg65kYU5I0GT8JLEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerU4ABIcnmS/5LkQJL9SX681a9M8kCSp9rtxWN9bk9yMMmTSa47Ew9AkjTMJGcAR4Hbquq7gLcCtya5EtgC7K2qtcDetk27byNwFbAeuDvJskkmL0kabnAAVNXhqvpYK38FOACsAjYAO1qzHcD1rbwBuKeqXqyqp4GDwLVDx5ckTWb5mdhJkjXA9wAPAXNVdRhGIZHk0tZsFfDgWLdDrW6p/W0GNgPMzc2xuLg4aF5zF8JtVx8d1HcSQ+er88us1he4xqZpVs/xkSNHzvrzPHEAJLkI+A/Ae6rqy0mO23SJulqqYVVtA7YBzM/P18LCwqC53bVzN3fuOyMZd1qeuXFh6mNq+ma1vsA1Nk03b7lvJuNuX7+Coce+UzXRu4CSvIrRwX9nVX2oVT+f5LJ2/2XAC63+EHD5WPfVwHOTjC9JGm6SdwEF+FXgQFX9wthde4BNrbwJ2D1WvzHJBUmuANYCDw8dX5I0mUnOX98O/BCwL8ljre4fA3cAu5LcAjwL3ABQVfuT7AKeYPQOolur6qUJxpckTWBwAFTVf2fp6/oA647TZyuwdeiYkqQzx08CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp6YeAEnWJ3kyycEkW6Y9viRpZKoBkGQZ8G+AvwZcCbwzyZXTnIMkaWTaZwDXAger6tNV9cfAPcCGKc9BkgQsn/J4q4DPjG0fAt5ybKMkm4HNbfNIkicHjncJ8IcD+w6Wn532iJqRmawvcI314Pt/duL19W0nazDtAMgSdfWKiqptwLaJB0seqar5SfcjLcX1pbNpGutr2peADgGXj22vBp6b8hwkSUw/AD4KrE1yRZJXAxuBPVOegySJKV8CqqqjSX4M+F1gGfCBqtp/Foec+DKSdAKuL51NZ319peoVl+AlSR3wk8CS1CkDQJI61U0AJHlDkn8wtv0tSe6d5Zx0fkryI0ne1co3J/mWsfve76fbdaYkWZPk7w7se+SkbXp5DSDJGuDDVfWmWc9F3ziSLAI/UVWPzHou+saTZIHR+vqBJe5bXlVHT9D3SFVddKL9nzNnAC3pDiT5lST7k9yf5MIkb0zyO0keTfLfknxna//GJA8m+WiSf/Zy2iW5KMneJB9Lsi/Jy181cQfwxiSPJfm5Nt7jrc9DSa4am8tikmuSrEjygTbGx8f2pfNUe94/mWRHkk8kuTfJa5Osa8/xvvacX9Da35Hkidb251vdTyX5iSTvAOaBnW1dXdjWznySH03yz8fGvTnJXa18U5KHW59fbt+RpW8gA45n29t6ern/y3+93wH8xbZW3tvW0QeT/BZw/wmOd6emqs6JH2ANcBR4c9veBdwE7AXWtrq3AL/Xyh8G3tnKPwIcaeXlwOta+RLgIKNPIK8BHj9mvMdb+b3AP23ly4BPtfLPADe18huATwErZv278mfidVbA29v2B4B/wugrSv5sq/s14D3ASuBJvn6m/IZ2+1OM/ioDWATmx/a/yCgUvpnR9169XP/bwF8Avgv4LeBVrf5u4F2z/r34c1bW2ekcz7YD7xjr//LxbIHRlYuX629m9IHalW17yePd+D5O9HPOnAE0T1fVY638KKNf4vcCH0zyGPDLjA7QAG8DPtjK/35sHwF+JskngP/M6PuH5k4y7i7ghlb+22P7/avAljb2IvAa4FtP7yHpHPSZqvpIK/86sI7R2vtUq9sBfB/wZeD/Au9P8reA/3OqA1TV54BPJ3lrkj8NfAfwkTbWNcBH27paB3z75A9J56DTOZ6djgeq6gutPOR49yem/V1AJ/PiWPklRg/ki1X15tPYx42M/vq6pqq+luQZRgfu46qqzyb5fJI/B/wd4O+3uwL8YFUN/TI6nZtO6YWvGn1w8VpGB+mNwI8Bf/k0xvlNRn9QfBL4j1VVSQLsqKrbT3POOv+czvHsKO2SfFsjrz7Bfr86Vj7t4924c+0M4FhfBp5OcgOMfjFJvrvd9yDwg628cazP64EX2i/j+/n6N+J9BfimE4x1D/CTwOural+r+13g3e0JIcn3TPqAdE741iRva+V3MvrLaU2SP9Pqfgj4/SQXMVoP/4nRJaE3L7GvE62rDwHXtzF+s9XtBd6R5FKAJCuTnPRbG/UN4UTHs2cYnRnC6CvyX9XKJztuHe94d0rO9QCAUcLdkuQPgP18/f8PeA/wj5I8zOg06kutficwn+SR1veTAFX1eeAjSR5P8nNLjHMvoyDZNVb304yeiE+0F4x/+kw+MM3MAWBTO21eCfwL4IcZnZrvA/4f8EuM/uF9uLX7fUavFR1rO/BLL78IPH5HVf1v4Ang26rq4Vb3BKPXHO5v+32AYZcBdH463vHsV4C/1I5nb+Hrf+V/Ajia5A+SLLX+ljzenarz9m2gSV4L/FE7rd7I6AVh36WjE4pvB5b+xLn2GsDpuAb41+3yzBeBvzfb6UjS+eW8PQOQJE3mfHgNQJJ0FhgAktQpA0CSOmUASFKnDABJ6tT/B1sUAOpOVqOxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews['Sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e489d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ecc72e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"distilgpt2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL = 'distilgpt2'\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(MODEL)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#add two prompts, one for each task\n",
    "SENTIMENT_PROMPT = 'Sentiment Task'\n",
    "SUMMARIZE_PROMPT = 'Summarize Task'\n",
    "SENTIMENT_TOKEN = '\\nSentiment:'\n",
    "SUMMARIZE_TOKEN = '\\nSummarize:'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "690adf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['sentiment_text'] = f'{SENTIMENT_PROMPT}\\nReview: ' + reviews['Text'] + SENTIMENT_TOKEN +  ' ' + reviews['Sentiment'].astype(str)\n",
    "\n",
    "reviews['summarize_text'] = f'{SUMMARIZE_PROMPT}\\nReview: ' + reviews['Text'] + SUMMARIZE_TOKEN +  ' ' + reviews['Summary'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d23b7afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentiment Task\\nReview: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\\nSentiment: negative',\n",
       " 'Sentiment Task\\nReview: Was very excited for these to come, however when I got them. I was NOT happy, not a good flavor or texture.\\nSentiment: negative']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['sentiment_text'].head(2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cdee58b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Task\n",
      "Review: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment Task\\nReview: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\\nSentiment: negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d804737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summarize Task\\nReview: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\\nSummarize: Not bad, but bland',\n",
       " 'Summarize Task\\nReview: Was very excited for these to come, however when I got them. I was NOT happy, not a good flavor or texture.\\nSummarize: NOT my favorite']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['summarize_text'].head(2).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b7fe460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Task\n",
      "Review: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\n",
      "Summarize: Not bad, but bland\n"
     ]
    }
   ],
   "source": [
    "print('Summarize Task\\nReview: I just made this for lunch. It had almost no flavor, although it smelled heavenly for the first few minutes of cooking.\\nSummarize: Not bad, but bland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "657237e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "reviews = reviews.sample(frac=1)\n",
    "\n",
    "training_examples = reviews['summarize_text'].tolist() + reviews['sentiment_text'].tolist()\n",
    "\n",
    "# 6,000 = 2 prompts per 1,000 examples from the 3 sentiment groups\n",
    "print(len(training_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34df23c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0f8b3f369a4edca294dd7c92f3a384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_task_df = pd.DataFrame({'text': training_examples})\n",
    "\n",
    "data = Dataset.from_pandas(multi_task_df)\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "data = data.map(preprocess, batched=True)\n",
    "\n",
    "data = data.train_test_split(train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c356604",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "365f7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb033e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b8b5abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 18:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.018805980682373,\n",
       " 'eval_runtime': 56.4334,\n",
       " 'eval_samples_per_second': 21.264,\n",
       " 'eval_steps_per_second': 0.673}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2_multitask\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=2, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data['train'],\n",
    "    eval_dataset=data['test'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e34721f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 4800\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 31:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.900600</td>\n",
       "      <td>2.751847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.746900</td>\n",
       "      <td>2.701665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./gpt2_multitask/checkpoint-150\n",
      "Configuration saved in ./gpt2_multitask/checkpoint-150/config.json\n",
      "Model weights saved in ./gpt2_multitask/checkpoint-150/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./gpt2_multitask/checkpoint-300\n",
      "Configuration saved in ./gpt2_multitask/checkpoint-300/config.json\n",
      "Model weights saved in ./gpt2_multitask/checkpoint-300/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./gpt2_multitask/checkpoint-300 (score: 2.7016654014587402).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=2.927398376464844, metrics={'train_runtime': 1913.6154, 'train_samples_per_second': 5.017, 'train_steps_per_second': 0.157, 'total_flos': 136927662833664.0, 'train_loss': 2.927398376464844, 'epoch': 2.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ad5ebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38' max='38' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38/38 00:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.7016654014587402,\n",
       " 'eval_runtime': 54.8621,\n",
       " 'eval_samples_per_second': 21.873,\n",
       " 'eval_steps_per_second': 0.693,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0457ee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./gpt2_multitask\n",
      "Configuration saved in ./gpt2_multitask/config.json\n",
      "Model weights saved in ./gpt2_multitask/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea18d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b656986c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./gpt2_multitask copy/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"distilgpt2\",\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file ./gpt2_multitask copy/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./gpt2_multitask copy.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = GPT2LMHeadModel.from_pretrained('./gpt2_multitask')\n",
    "\n",
    "generator = pipeline('text-generation', model=loaded_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ba9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "58e48142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "neutral\n",
      "Nature goodness\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sample, score, summary = reviews.sample(1)[['Text', 'Sentiment', 'Summary']].values[0]\n",
    "\n",
    "print(text_sample)\n",
    "print(score)\n",
    "print(summary)\n",
    "\n",
    "num_tokens = len(tokenizer(text_sample)['input_ids'])\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9ecb17d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_text_sample = f'{SENTIMENT_PROMPT}\\nReview: {text_sample}{SENTIMENT_TOKEN}'\n",
    "summarize_text_sample = f'{SUMMARIZE_PROMPT}\\nReview: {text_sample}{SUMMARIZE_TOKEN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a02c3e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment:\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "fb5354f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize:\n"
     ]
    }
   ],
   "source": [
    "print(summarize_text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b913bc4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "687eb473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "for generated_text in generator(sentiment_text_sample, num_return_sequences=1, max_length=num_tokens + 1):\n",
    "    print(generated_text['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "73126886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize: Great chips!!  Just the right size\n",
      "----\n",
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize: Great, but not as strong as real\n",
      "----\n",
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize: Geez! Good! Excellent Chips\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for generated_text in generator(summarize_text_sample, num_return_sequences=3, max_length=num_tokens + 20):\n",
    "    print(generated_text['generated_text'])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a0452f41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model=GPT2LMHeadModel.from_pretrained('gpt2'), tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "255df2d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 39, but ``max_length`` is set to 30. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment: Would\n",
      "-------\n",
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment: Very\n",
      "-------\n",
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment: Good\n",
      "-------\n",
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment:\n",
      "\n",
      "-------\n",
      "Sentiment Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Sentiment: These\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for generated_text in generator(sentiment_text_sample, num_return_sequences=5, max_length=num_tokens + 1):\n",
    "    print(generated_text['generated_text'])\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "009716c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize:\n",
      "As with all my orders I always\n",
      "----\n",
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize: Great taste. Very smooth and not overly\n",
      "----\n",
      "Summarize Task\n",
      "Review: Really great tasting chips. I really did not expect them to be as hard as they were. Good if they are cover with a cheese sauce.\n",
      "Summarize: Definitely a good chip. The chips are\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for generated_text in generator(summarize_text_sample, num_return_sequences=3, max_length=num_tokens + 20):\n",
    "    print(generated_text['generated_text'])\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3316a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
