{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97eac2b0",
   "metadata": {},
   "source": [
    "## 4.1 Introduction to BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57bdf2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5408f5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Let's load a vanilla BERT-base model. \n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa999e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "955f8436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 199 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "embeddings.word_embeddings.weight                       (30522, 768)\n",
      "embeddings.position_embeddings.weight                     (512, 768)\n",
      "embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "embeddings.LayerNorm.weight                                   (768,)\n",
      "embeddings.LayerNorm.bias                                     (768,)\n",
      "\n",
      "==== First Encoder ====\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                             (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "pooler.dense.weight                                       (768, 768)\n",
      "pooler.dense.bias                                             (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "named_params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(named_params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in named_params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Encoder ====\\n')\n",
    "for p in named_params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in named_params[-2:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b19444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pooler is a separate linear and tanh activated layer that acts on the [CLS] token's representation\n",
    "# This pooled_output is often used as a representation for the entire sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e411b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a6505c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bert-base uncased tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e01cf7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8254, 2319, 7459, 1037, 3376, 2154, 102]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Sinan loves a beautiful day')  # tokenize a simple sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0da83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tokens through the model\n",
    "\n",
    "#1 Turn tokens_with_unknown_words into a tensor (will be size (8,))\n",
    "#2 Unsqueeze a first dimension to simulate batches. Resulting shape is (1, 8)\n",
    "response = model(torch.tensor(tokenizer.encode('Sinan loves a beautiful day')).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9d4299db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2327,  0.1515, -0.0448,  ..., -0.5192,  0.4195,  0.2948],\n",
       "         [ 0.3051, -0.6614,  0.2500,  ..., -0.9809,  0.2551,  0.2400],\n",
       "         [-0.3610, -0.8759,  0.4542,  ..., -1.1120,  0.1791,  0.0664],\n",
       "         ...,\n",
       "         [ 0.0689, -0.0364,  0.4940,  ..., -0.6558,  0.2227, -0.3868],\n",
       "         [-0.2657, -0.4257,  0.0056,  ...,  0.1352,  0.3596, -0.4585],\n",
       "         [ 0.6100,  0.0263, -0.2532,  ..., -0.0680, -0.3901, -0.3541]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.8777, -0.4542, -0.6286,  0.7511,  0.3151, -0.0913,  0.9175,  0.3766,\n",
       "         -0.3059, -1.0000, -0.0577,  0.7535,  0.9913,  0.2113,  0.9418, -0.5328,\n",
       "         -0.0568, -0.5698,  0.4090, -0.6096,  0.7876,  0.9995,  0.3670,  0.2453,\n",
       "          0.4620,  0.9465, -0.6802,  0.9342,  0.9614,  0.7060, -0.5755,  0.2076,\n",
       "         -0.9910, -0.1697, -0.8018, -0.9952,  0.3786, -0.7309, -0.0599, -0.0186,\n",
       "         -0.8722,  0.3377,  0.9999, -0.0416,  0.3039, -0.2458, -1.0000,  0.2803,\n",
       "         -0.8856,  0.5071,  0.5182,  0.3099,  0.0669,  0.5149,  0.4535,  0.2464,\n",
       "         -0.0333,  0.1802, -0.2397, -0.5966, -0.5891,  0.4319, -0.6395, -0.9313,\n",
       "          0.4686,  0.1766, -0.1505, -0.2957, -0.0514, -0.1576,  0.8782,  0.2825,\n",
       "          0.1316, -0.8860,  0.1212,  0.2367, -0.4869,  1.0000, -0.3583, -0.9821,\n",
       "          0.5884,  0.2668,  0.4513,  0.3816, -0.0514, -1.0000,  0.3832, -0.1374,\n",
       "         -0.9907,  0.1855,  0.6004, -0.1374,  0.3874,  0.4813, -0.3741, -0.4017,\n",
       "         -0.3040, -0.5284, -0.3583, -0.2307,  0.0355, -0.3318, -0.2008, -0.3483,\n",
       "          0.2099, -0.4482, -0.6539,  0.3030, -0.2450,  0.7254,  0.2816, -0.3301,\n",
       "          0.4079, -0.9599,  0.6782, -0.3683, -0.9862, -0.4576, -0.9919,  0.7549,\n",
       "         -0.2049, -0.2972,  0.9678, -0.0692,  0.2751, -0.1389, -0.5539, -1.0000,\n",
       "         -0.5388, -0.3930,  0.1323, -0.2860, -0.9817, -0.9473,  0.6096,  0.9473,\n",
       "          0.1899,  0.9998, -0.4162,  0.9608,  0.0330, -0.2275,  0.3574, -0.4356,\n",
       "          0.6688,  0.2626, -0.6718,  0.1865, -0.1303,  0.4140, -0.4800, -0.3361,\n",
       "         -0.3105, -0.9495, -0.3550,  0.9570, -0.3836, -0.4769,  0.5362, -0.2674,\n",
       "         -0.5366,  0.8518,  0.3751,  0.4419, -0.1930,  0.4464,  0.1023,  0.5376,\n",
       "         -0.8681,  0.1531,  0.3970, -0.2881, -0.5797, -0.9841, -0.3196,  0.4932,\n",
       "          0.9899,  0.8004,  0.2937,  0.5190, -0.2158,  0.4647, -0.9605,  0.9846,\n",
       "         -0.2993,  0.3152, -0.3622,  0.2491, -0.8298, -0.0492,  0.8649, -0.5621,\n",
       "         -0.8109,  0.0596, -0.4256, -0.4160, -0.6402,  0.4875, -0.3528, -0.4344,\n",
       "         -0.1472,  0.9358,  0.9607,  0.8050, -0.2240,  0.6120, -0.9213, -0.3720,\n",
       "          0.1944,  0.2549,  0.2056,  0.9949, -0.3452, -0.1319, -0.9423, -0.9890,\n",
       "         -0.0635, -0.8755, -0.0717, -0.6739,  0.5520, -0.1817,  0.0886,  0.3924,\n",
       "         -0.9839, -0.8045,  0.4063, -0.3791,  0.5224, -0.2002,  0.7146,  0.8403,\n",
       "         -0.5794,  0.6525,  0.8934, -0.6888, -0.7708,  0.7749, -0.2771,  0.8685,\n",
       "         -0.7006,  0.9929,  0.6825,  0.5335, -0.9562, -0.3845, -0.8773, -0.4100,\n",
       "         -0.1682, -0.2743,  0.5831,  0.4320,  0.3957,  0.7450, -0.6908,  0.9976,\n",
       "         -0.8594, -0.9585, -0.6457, -0.2748, -0.9892,  0.7752,  0.3780,  0.1494,\n",
       "         -0.4580, -0.6380, -0.9619,  0.8854,  0.1650,  0.9833, -0.3250, -0.9306,\n",
       "         -0.5682, -0.9348, -0.2212, -0.1823,  0.2422, -0.1038, -0.9702,  0.5281,\n",
       "          0.5707,  0.5068, -0.3112,  0.9983,  1.0000,  0.9805,  0.8844,  0.8857,\n",
       "         -0.9983, -0.6119,  1.0000, -0.9533, -1.0000, -0.9239, -0.6746,  0.2397,\n",
       "         -1.0000, -0.1235, -0.0725, -0.9380,  0.1567,  0.9808,  0.9917, -1.0000,\n",
       "          0.9008,  0.9440, -0.5201,  0.8251, -0.4824,  0.9775,  0.4022,  0.5217,\n",
       "         -0.2950,  0.4242, -0.7700, -0.8768, -0.1279, -0.4046,  0.9811,  0.1531,\n",
       "         -0.7156, -0.9465,  0.4008, -0.1710, -0.0315, -0.9656, -0.2111,  0.4102,\n",
       "          0.7231,  0.1516,  0.3509, -0.8021,  0.2328, -0.5455,  0.4320,  0.5908,\n",
       "         -0.9447, -0.6176,  0.2716, -0.3587, -0.2995, -0.9437,  0.9684, -0.4916,\n",
       "          0.6288,  1.0000,  0.4188, -0.8921,  0.5297,  0.2667, -0.2394,  1.0000,\n",
       "          0.7230, -0.9832, -0.4890,  0.6689, -0.5466, -0.4932,  0.9996, -0.2217,\n",
       "         -0.1167,  0.0490,  0.9794, -0.9923,  0.9471, -0.9063, -0.9776,  0.9691,\n",
       "          0.9429, -0.4869, -0.7447,  0.1666, -0.3527,  0.3335, -0.9478,  0.7168,\n",
       "          0.3545, -0.1353,  0.9109, -0.7881, -0.4324,  0.3767, -0.1721,  0.1382,\n",
       "          0.8000,  0.5948, -0.2708,  0.0650, -0.3323, -0.4880, -0.9694,  0.2312,\n",
       "          1.0000, -0.2423,  0.4368, -0.3108, -0.0890, -0.1536,  0.4792,  0.4995,\n",
       "         -0.3567, -0.8845,  0.5553, -0.9447, -0.9911,  0.6794,  0.2624, -0.2930,\n",
       "          1.0000,  0.4425,  0.2925,  0.1576,  0.8787, -0.0432,  0.4729,  0.3847,\n",
       "          0.9754, -0.2582,  0.4169,  0.8205, -0.4750, -0.2669, -0.7019,  0.0698,\n",
       "         -0.9207,  0.1223, -0.9688,  0.9624,  0.6146,  0.3767,  0.1965,  0.4386,\n",
       "          1.0000, -0.5764,  0.5277, -0.1075,  0.8040, -0.9955, -0.7789, -0.4554,\n",
       "         -0.0230, -0.3707, -0.2666,  0.2837, -0.9743,  0.1491,  0.5257, -0.9831,\n",
       "         -0.9945,  0.0898,  0.7444,  0.1715, -0.9190, -0.7186, -0.5349,  0.5420,\n",
       "         -0.2393, -0.9546,  0.3902, -0.2898,  0.4637, -0.2010,  0.4773,  0.2017,\n",
       "          0.7901, -0.2781, -0.0836, -0.1398, -0.7673,  0.7647, -0.7953, -0.7866,\n",
       "         -0.0740,  1.0000, -0.5140,  0.5606,  0.7284,  0.6431, -0.1287,  0.1687,\n",
       "          0.8059,  0.3201, -0.3073, -0.1484, -0.5094, -0.4046,  0.4966,  0.2570,\n",
       "          0.2268,  0.8138,  0.6051,  0.1701,  0.0970,  0.0365,  0.9994, -0.2530,\n",
       "         -0.3062, -0.4775, -0.0299, -0.3373, -0.0562,  1.0000,  0.3479,  0.3388,\n",
       "         -0.9930, -0.6483, -0.9312,  1.0000,  0.7832, -0.8142,  0.6100,  0.6160,\n",
       "         -0.0965,  0.7704, -0.2299, -0.2138,  0.3634,  0.1423,  0.9668, -0.4813,\n",
       "         -0.9708, -0.5214,  0.4172, -0.9622,  0.9989, -0.5598, -0.2905, -0.4267,\n",
       "         -0.4151,  0.2529,  0.1150, -0.9828, -0.2933,  0.1020,  0.9736,  0.2178,\n",
       "         -0.4881, -0.8858,  0.4018,  0.1948, -0.6173, -0.9628,  0.9806, -0.9815,\n",
       "          0.6556,  1.0000,  0.2375, -0.3275,  0.1889, -0.4338,  0.3769, -0.5125,\n",
       "          0.5513, -0.9591, -0.3053, -0.2294,  0.3810, -0.1581, -0.5999,  0.7795,\n",
       "          0.1466, -0.4206, -0.6070, -0.0838,  0.4119,  0.8152, -0.3367, -0.1378,\n",
       "          0.0598, -0.0126, -0.9555, -0.4236, -0.3401, -0.9998,  0.5610, -1.0000,\n",
       "          0.2936, -0.2596, -0.2057,  0.8384,  0.5396,  0.3741, -0.7824, -0.2065,\n",
       "          0.7995,  0.7801, -0.2754, -0.2632, -0.7891,  0.3725, -0.0966,  0.4469,\n",
       "         -0.2534,  0.7190, -0.2084,  1.0000,  0.0228, -0.5043, -0.9706,  0.2989,\n",
       "         -0.3006,  1.0000, -0.8886, -0.9492,  0.5443, -0.5613, -0.8245,  0.3681,\n",
       "         -0.0980, -0.7511, -0.7760,  0.9546,  0.7718, -0.4745,  0.5654, -0.2965,\n",
       "         -0.4881, -0.0135,  0.6650,  0.9903,  0.5524,  0.8905, -0.2984, -0.1938,\n",
       "          0.9551,  0.2327,  0.6217,  0.2077,  1.0000,  0.3327, -0.9078,  0.1122,\n",
       "         -0.9812, -0.1818, -0.9299,  0.3491,  0.2149,  0.8971, -0.2581,  0.9697,\n",
       "         -0.4896,  0.0960, -0.3364,  0.1812,  0.4807, -0.9276, -0.9868, -0.9900,\n",
       "          0.5835, -0.4884,  0.0305,  0.3250,  0.0817,  0.4666,  0.5004, -1.0000,\n",
       "          0.9463,  0.4286,  0.5428,  0.9733,  0.5760,  0.5608,  0.2607, -0.9877,\n",
       "         -0.9753, -0.4240, -0.2934,  0.8090,  0.7190,  0.8551,  0.4776, -0.4918,\n",
       "         -0.4156, -0.0276, -0.8160, -0.9934,  0.3963,  0.0233, -0.9409,  0.9629,\n",
       "         -0.4148, -0.1184,  0.3304, -0.5221,  0.9129,  0.8248,  0.4409,  0.2048,\n",
       "          0.4997,  0.9182,  0.9484,  0.9918, -0.5874,  0.7747, -0.3111,  0.5266,\n",
       "          0.6146, -0.9457,  0.1223,  0.1749, -0.2750,  0.3174, -0.2500, -0.9335,\n",
       "          0.7000, -0.2273,  0.5873, -0.4977,  0.0328, -0.4565, -0.1727, -0.7292,\n",
       "         -0.5687,  0.5303,  0.2038,  0.8994,  0.8242, -0.0432, -0.6686, -0.3017,\n",
       "         -0.2925, -0.9236,  0.9091, -0.1265,  0.0754,  0.1207,  0.0477,  0.8970,\n",
       "         -0.0236, -0.4224, -0.3772, -0.7444,  0.9107, -0.3409, -0.5596, -0.5428,\n",
       "          0.8507,  0.3878,  0.9998, -0.4650, -0.5662, -0.3292, -0.3968,  0.3775,\n",
       "         -0.5127, -1.0000,  0.4716, -0.1930,  0.5168, -0.3026,  0.5821, -0.3216,\n",
       "         -0.9742, -0.3125,  0.2638,  0.1447, -0.5504, -0.5584,  0.4720, -0.1662,\n",
       "          0.9081,  0.9046,  0.2194,  0.5707,  0.5176, -0.1037, -0.7264,  0.9025]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b12732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2327,  0.1515, -0.0448,  ..., -0.5192,  0.4195,  0.2948],\n",
       "         [ 0.3051, -0.6614,  0.2500,  ..., -0.9809,  0.2551,  0.2400],\n",
       "         [-0.3610, -0.8759,  0.4542,  ..., -1.1120,  0.1791,  0.0664],\n",
       "         ...,\n",
       "         [ 0.0689, -0.0364,  0.4940,  ..., -0.6558,  0.2227, -0.3868],\n",
       "         [-0.2657, -0.4257,  0.0056,  ...,  0.1352,  0.3596, -0.4585],\n",
       "         [ 0.6100,  0.0263, -0.2532,  ..., -0.0680, -0.3901, -0.3541]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding for each token, the first one being the [CLS] token\n",
    "response.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39199fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This layer is trained on top of the Embedding of the CLS token\n",
    "\n",
    "response.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c629f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPooler(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac1b30df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the final encoder's representation of the CLS token\n",
    "CLS_embedding = response.last_hidden_state[:, 0, :].unsqueeze(0)\n",
    "\n",
    "CLS_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d061f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pooler(CLS_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b80af031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running the embedding for CLS through the pooler gives the same output as the \"pooler_output\"\n",
    "(model.pooler(CLS_embedding) == response.pooler_output).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da451674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45091eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 109,360,128\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for p in model.parameters():\n",
    "    if len(p.shape) == 2:\n",
    "        total_params += p.shape[0] * p.shape[1]\n",
    "        \n",
    "print(f'Total Parameters: {total_params:,}')  # This is where the 110M parameter comes from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21daca46",
   "metadata": {},
   "source": [
    "## 4.2 Wordpiece tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee92760",
   "metadata": {},
   "source": [
    "## Let's start by taking a look at the Bert Tokenizer.\n",
    "\n",
    "Let's use the `from_pretrained` method to grab the uncased bert-base tokenizer\n",
    "\n",
    "A list of all available modules can be found on their site: https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3c1d8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dbc4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1bf5e805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of BERT base vocabulary: 30522\n"
     ]
    }
   ],
   "source": [
    "# load the bert-base uncased tokenizer. Quick check what does \"uncased\" mean?\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "print(f'Length of BERT base vocabulary: {len(tokenizer.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "533e22ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1037, 3722, 6251, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "text = \"A simple sentence!\"\n",
    "\n",
    "tokens = tokenizer.encode(text)  # get token ids per BERT-base's vocabulary\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2dcd1f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] a simple sentence! [SEP]'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode will re-construct the sentence with the added [CLS] and [SEP] token\n",
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff94fd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2026, 2767, 2409, 2033, 2055, 2023, 2465, 1998, 1045, 2293, 2009, 2061, 2521, 999, 2016, 2001, 2157, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "text = \"My friend told me about this class and I love it so far! She was right.\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "289885d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: My friend told me about this class and I love it so far! She was right.. Num tokens: 20\n",
      "Token: 101, subword: [CLS]\n",
      "Token: 2026, subword: my\n",
      "Token: 2767, subword: friend\n",
      "Token: 2409, subword: told\n",
      "Token: 2033, subword: me\n",
      "Token: 2055, subword: about\n",
      "Token: 2023, subword: this\n",
      "Token: 2465, subword: class\n",
      "Token: 1998, subword: and\n",
      "Token: 1045, subword: i\n",
      "Token: 2293, subword: love\n",
      "Token: 2009, subword: it\n",
      "Token: 2061, subword: so\n",
      "Token: 2521, subword: far\n",
      "Token: 999, subword: !\n",
      "Token: 2016, subword: she\n",
      "Token: 2001, subword: was\n",
      "Token: 2157, subword: right\n",
      "Token: 1012, subword: .\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "# A nicer printout  of token ids and token strings\n",
    "\n",
    "print(f'Text: {text}. Num tokens: {len(tokens)}')\n",
    "for t in tokens:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "252eaef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sinan is not in our vocab :'(\n",
    "\n",
    "'sinan' in tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2710f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 101, subword: [CLS]\n",
      "Token: 8254, subword: sin\n",
      "Token: 2319, subword: ##an\n",
      "Token: 7459, subword: loves\n",
      "Token: 1037, subword: a\n",
      "Token: 3376, subword: beautiful\n",
      "Token: 2154, subword: day\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "text_with_unknown_words = 'Sinan loves a beautiful day'\n",
    "tokens_with_unknown_words = tokenizer.encode(text_with_unknown_words)\n",
    "\n",
    "# We see our sub words in action!\n",
    "for t in tokens_with_unknown_words:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "509ccf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 8254, 2319, 102]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('sinan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "813dfcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2019, 102]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('an')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efa51549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 101, subword: [CLS]\n",
      "Token: 8254, subword: sin\n",
      "Token: 2319, subword: ##an\n",
      "Token: 2003, subword: is\n",
      "Token: 2256, subword: our\n",
      "Token: 9450, subword: instructor\n",
      "Token: 2005, subword: for\n",
      "Token: 2023, subword: this\n",
      "Token: 12476, subword: awesome\n",
      "Token: 23823, subword: ##sau\n",
      "Token: 3401, subword: ##ce\n",
      "Token: 2465, subword: class\n",
      "Token: 102, subword: [SEP]\n"
     ]
    }
   ],
   "source": [
    "text_with_unknown_words = 'Sinan is our instructor for this awesomesauce class'\n",
    "tokens_with_unknown_words = tokenizer.encode(text_with_unknown_words)\n",
    "\n",
    "for t in tokens_with_unknown_words:\n",
    "    print(f'Token: {t}, subword: {tokenizer.decode([t])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddb8c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2026, 2767, 2409, 2033, 2055, 2023, 2465, 1998, 1045, 2293, 2009, 2061, 2521, 999, 2016, 2001, 2157, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "text = \"My friend told me about this class and I love it so far! She was right.\"\n",
    "\n",
    "# encode_plus gives us token ids, attention mask and segment ids (A vs B). Useful for training time\n",
    "tokens = tokenizer.encode_plus(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c389a7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 2767, 2409, 2033, 2055, 2023, 2465, 1998, 1045, 2293, 2009, 2061, 2521, 999, 2016, 2001, 2157, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text)  # calling the tokenizer directly does the same thing as encode_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc199b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3bb04564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python is the 6th token (don't forget the [CLS] token!)\n",
    "python_pet = tokenizer.encode('I love my pet python')\n",
    "\n",
    "# python is the 6th token (don't forget the [CLS] token!)\n",
    "python_language = tokenizer.encode('I love coding in python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a197bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e57090b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contextful embedding of 'python' in 'I love my pet python'\n",
    "python_pet_embedding = model(torch.tensor(python_pet).unsqueeze(0))[0][:,5,:].detach().numpy()\n",
    "\n",
    "# contextful embedding of 'python' in 'I love coding in python'\n",
    "python_language_embedding = model(torch.tensor(python_language).unsqueeze(0))[0][:,5,:].detach().numpy()\n",
    "\n",
    "# contextful embedding of 'snake' in 'snake'\n",
    "snake_alone_embedding = model(torch.tensor(tokenizer.encode('snake')).unsqueeze(0))[0][:,1,:].detach().numpy()\n",
    "\n",
    "# contextful embedding of 'programming' in 'programming'\n",
    "programming_alone_embedding = model(torch.tensor(tokenizer.encode('programming')).unsqueeze(0))[0][:,1,:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc36a6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_pet_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "db56d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_language_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3350b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ca9f5ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5843483]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about coding to the word snake\n",
    "cosine_similarity(python_language_embedding, snake_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8f304c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69286585]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about pets to the word snake. More similar!\n",
    "cosine_similarity(python_pet_embedding, snake_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ccae9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49864468]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about pets to the word programming\n",
    "cosine_similarity(python_pet_embedding, programming_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "377d87e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.561475]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity of the representation of the word Python in a sentence about coding to the word programming. More similar!\n",
    "cosine_similarity(python_language_embedding, programming_alone_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d87ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbb006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8acbcb7",
   "metadata": {},
   "source": [
    "## 4.3 The many embeddings of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2176ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056d74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a0cf97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "679efc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEmbeddings(\n",
       "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "  (position_embeddings): Embedding(512, 768)\n",
       "  (token_type_embeddings): Embedding(2, 768)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "word_embeddings == context-free word embeddings\n",
    "position_embeddings == encodes word position\n",
    "token_type_embeddings == 0 or 1. Used to lookup the segment embedding\n",
    "\"\"\"\n",
    "\n",
    "model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3143e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a4c144cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1045, 2572, 8254, 2319,  102]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_phrase = 'I am Sinan'\n",
    "\n",
    "# return_tensors='pt' converts to pytorch automatically\n",
    "tokenizer.encode(example_phrase, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf13de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
       "         [-0.0211,  0.0059, -0.0179,  ...,  0.0163,  0.0122,  0.0073],\n",
       "         [-0.0437, -0.0150,  0.0029,  ..., -0.0282,  0.0474, -0.0448],\n",
       "         [-0.0022, -0.0876,  0.0143,  ...,  0.0232, -0.0024, -0.0213],\n",
       "         [-0.0614, -0.0044, -0.0755,  ..., -0.0522, -0.0310, -0.0248],\n",
       "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context-less embedding of each token in our sentence\n",
    "model.embeddings.word_embeddings(tokenizer.encode(example_phrase, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a60688e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0136, -0.0265, -0.0235,  ...,  0.0087,  0.0071,  0.0151],\n",
       "         [-0.0211,  0.0059, -0.0179,  ...,  0.0163,  0.0122,  0.0073],\n",
       "         [-0.0437, -0.0150,  0.0029,  ..., -0.0282,  0.0474, -0.0448],\n",
       "         [-0.0381, -0.0026,  0.0130,  ...,  0.0038, -0.0279, -0.0082],\n",
       "         [-0.0145, -0.0100,  0.0060,  ..., -0.0250,  0.0046, -0.0015]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the first and last row are the same because they are the \n",
    "#  [CLS] and [SEP] reserved tokens. They are the same without context for every input\n",
    "model.embeddings.word_embeddings(tokenizer.encode('I am Matt', return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087911bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "675627aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(512, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.position_embeddings  # 512 embeddings, one for each position in a max 512 input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82217746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "748eabee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "          6.8312e-04,  1.5441e-02],\n",
       "        [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "          2.9753e-02, -5.3247e-03],\n",
       "        [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "          1.8741e-02, -7.3140e-03],\n",
       "        [-4.1949e-03, -1.1852e-02, -2.1180e-02,  ...,  2.2455e-02,\n",
       "          5.2826e-03, -1.9723e-03],\n",
       "        [-5.6087e-03, -1.0445e-02, -7.2288e-03,  ...,  2.0837e-02,\n",
       "          3.5402e-03,  4.7708e-03],\n",
       "        [-3.0871e-03, -1.8956e-02, -1.8930e-02,  ...,  7.4045e-03,\n",
       "          2.0183e-02,  3.4077e-03]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.position_embeddings(torch.LongTensor(range(6)))  # positional embeddings for our example_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694dcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c1e482b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2, 768)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.token_type_embeddings  # 2 embeddings. One for A and one for B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9443c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([0]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab167901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086],\n",
       "        [ 0.0004,  0.0110,  0.0037,  ..., -0.0066, -0.0034, -0.0086]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.token_type_embeddings(torch.LongTensor([0]*6))  # All tokens have the same embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fe9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5208b132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "           3.8253e-02,  1.6400e-01],\n",
       "         [-3.4025e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
       "           8.9008e-01,  1.6575e-01],\n",
       "         [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
       "           1.3468e+00, -6.9357e-01],\n",
       "         [ 2.8197e-01, -1.0037e+00,  3.5063e-01,  ...,  8.5378e-01,\n",
       "           3.9389e-01, -8.4527e-02],\n",
       "         [-7.3509e-01,  3.3429e-01, -8.3037e-01,  ..., -2.1545e-01,\n",
       "          -6.6517e-02, -2.6881e-02],\n",
       "         [-3.2507e-01, -3.1879e-01, -1.1632e-01,  ..., -3.9602e-01,\n",
       "           4.1120e-01, -7.7552e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply feed forward normalization layer\n",
    "\n",
    "model.embeddings.LayerNorm(\n",
    "    model.embeddings.word_embeddings(tokenizer.encode(example_phrase, return_tensors='pt')) + \\\n",
    "    model.embeddings.position_embeddings(torch.LongTensor(range(6))) + \\\n",
    "    model.embeddings.token_type_embeddings(torch.LongTensor([0]*6))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90c64cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6855e-01, -2.8577e-01, -3.2613e-01,  ..., -2.7571e-02,\n",
       "           3.8253e-02,  1.6400e-01],\n",
       "         [-3.4026e-04,  5.3974e-01, -2.8805e-01,  ...,  7.5731e-01,\n",
       "           8.9008e-01,  1.6575e-01],\n",
       "         [-6.3496e-01,  1.9748e-01,  2.5116e-01,  ..., -4.0819e-02,\n",
       "           1.3468e+00, -6.9357e-01],\n",
       "         [ 2.8197e-01, -1.0037e+00,  3.5063e-01,  ...,  8.5378e-01,\n",
       "           3.9389e-01, -8.4527e-02],\n",
       "         [-7.3509e-01,  3.3429e-01, -8.3037e-01,  ..., -2.1545e-01,\n",
       "          -6.6517e-02, -2.6881e-02],\n",
       "         [-3.2507e-01, -3.1879e-01, -1.1632e-01,  ..., -3.9602e-01,\n",
       "           4.1120e-01, -7.7552e-02]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Et Voilà! The many embeddings of BERT become one embedding per token\n",
    "model.embeddings(tokenizer.encode(example_phrase, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d1f696a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings(tokenizer.encode(example_phrase, return_tensors='pt')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec011d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
