{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b97d18c",
   "metadata": {},
   "source": [
    "## 6.1 Flavors of BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55fc4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3af241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "90a1c04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForMaskedLM were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n",
      "If you don’t *** at the sign, you will get a ticket\n",
      "Token:look. Score: 51.35%\n",
      "Token:stop. Score: 39.66%\n",
      "Token:glance. Score: 1.02%\n",
      "Token:wait. Score: 0.60%\n",
      "Token:turn. Score: 0.57%\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\", model='bert-base-cased')\n",
    "\n",
    "print(type(nlp.model))\n",
    "\n",
    "preds = nlp(f\"If you don’t {nlp.tokenizer.mask_token} at the sign, you will get a ticket\")\n",
    "\n",
    "print('If you don’t *** at the sign, you will get a ticket')\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"Token:{p['token_str']}. Score: {100*p['score']:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f192f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c993940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForMaskedLM'>\n",
      "If you don’t *** at the sign, you will get a ticket\n",
      "Token: look. Score: 47.69%\n",
      "Token: stop. Score: 36.82%\n",
      "Token: stand. Score: 2.54%\n",
      "Token: stay. Score: 2.52%\n",
      "Token: wave. Score: 1.01%\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\", model='roberta-base')\n",
    "\n",
    "print(type(nlp.model))\n",
    "\n",
    "preds = nlp(f\"If you don’t {nlp.tokenizer.mask_token} at the sign, you will get a ticket\")\n",
    "\n",
    "print('If you don’t *** at the sign, you will get a ticket')\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"Token:{p['token_str']}. Score: {100*p['score']:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "81cceeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at distilroberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/23e0f7484fc8a320856b168861166b48c2976bb4e0861602422e1b0c3fe5bf61.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c7e8020011da613ff5a9175ddad64cd47238a9525db975eb50ecb965e9f7302f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/b6a9ca6504e67903474c3fdf82ba249882406e61c2176a9d4dc9c3691c663767.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilroberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"distilroberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.roberta.modeling_roberta.RobertaForMaskedLM'>\n",
      "If you don’t *** at the sign, you will get a ticket\n",
      "Token: stop. Score: 42.11%\n",
      "Token: look. Score: 7.53%\n",
      "Token: park. Score: 4.92%\n",
      "Token: arrive. Score: 4.65%\n",
      "Token: sign. Score: 4.27%\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\", model='distilroberta-base')\n",
    "\n",
    "print(type(nlp.model))\n",
    "\n",
    "preds = nlp(f\"If you don’t {nlp.tokenizer.mask_token} at the sign, you will get a ticket\")\n",
    "\n",
    "print('If you don’t *** at the sign, you will get a ticket')\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"Token:{p['token_str']}. Score: {100*p['score']:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfa6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6dbf2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.distilbert.modeling_distilbert.DistilBertForMaskedLM'>\n",
      "If you don’t *** at the sign, you will get a ticket\n",
      "Token:look. Score: 57.47%\n",
      "Token:stop. Score: 7.37%\n",
      "Token:glance. Score: 3.74%\n",
      "Token:arrive. Score: 2.16%\n",
      "Token:appear. Score: 1.87%\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"fill-mask\", model='distilbert-base-cased')  # Using a flavor of BERT called DistilBERT\n",
    "\n",
    "print(type(nlp.model))  \n",
    "\n",
    "preds = nlp(f\"If you don’t {nlp.tokenizer.mask_token} at the sign, you will get a ticket\")\n",
    "\n",
    "print('If you don’t *** at the sign, you will get a ticket')\n",
    "\n",
    "for p in preds:\n",
    "    print(f\"Token:{p['token_str']}. Score: {100*p['score']:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64a7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9098dcb1",
   "metadata": {},
   "source": [
    "## 6.2 BERT for sequence classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2484167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification, DistilBertTokenizerFast, \\\n",
    "     DataCollatorWithPadding, pipeline\n",
    "from datasets import load_metric, Dataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac898e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e4e17957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'listen O\\r\\n',\n",
       " b'to O\\r\\n',\n",
       " b'westbam B-artist\\r\\n',\n",
       " b'alumb O\\r\\n',\n",
       " b'allergic B-album\\r\\n',\n",
       " b'on O\\r\\n',\n",
       " b'google B-service\\r\\n',\n",
       " b'music I-service\\r\\n',\n",
       " b'PlayMusic\\r\\n',\n",
       " b'\\r\\n',\n",
       " b'add O\\r\\n',\n",
       " b'step B-entity_name\\r\\n',\n",
       " b'to I-entity_name\\r\\n',\n",
       " b'me I-entity_name\\r\\n',\n",
       " b'to O\\r\\n',\n",
       " b'the O\\r\\n',\n",
       " b'50 B-playlist\\r\\n',\n",
       " b'cl\\xc3\\xa1sicos I-playlist\\r\\n',\n",
       " b'playlist O\\r\\n',\n",
       " b'AddToPlaylist\\r\\n']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_file = open('../data/snips.train.txt', 'rb')\n",
    "\n",
    "snips_rows = snips_file.readlines()\n",
    "\n",
    "snips_rows[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9f7b8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code segment parses the snips dataset into a more manageable format\n",
    "\n",
    "utterances = []\n",
    "tokenized_utterances = []\n",
    "labels_for_tokens = []\n",
    "sequence_labels = []\n",
    "\n",
    "utterance, tokenized_utterance, label_for_utterances = '', [], []\n",
    "for snip_row in snips_rows:\n",
    "    if len(snip_row) == 2:  # skip over rows with no data\n",
    "        continue\n",
    "    if ' ' not in snip_row.decode():  # we've hit a sequence label\n",
    "        sequence_labels.append(snip_row.decode().strip())\n",
    "        utterances.append(utterance.strip())\n",
    "        tokenized_utterances.append(tokenized_utterance)\n",
    "        labels_for_tokens.append(label_for_utterances)\n",
    "        utterance = ''\n",
    "        tokenized_utterance = []\n",
    "        label_for_utterances = []\n",
    "        continue\n",
    "    token, token_label = snip_row.decode().split(' ')\n",
    "    token_label = token_label.strip()\n",
    "    utterance += f'{token} '\n",
    "    tokenized_utterance.append(token)\n",
    "    label_for_utterances.append(token_label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c78793ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13084, 13084, 13084, 13084)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_for_tokens), len(tokenized_utterances), len(utterances), len(sequence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "774c7c64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bb5d631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PlayMusic',\n",
       " 'RateBook',\n",
       " 'SearchScreeningEvent',\n",
       " 'SearchCreativeWork',\n",
       " 'BookRestaurant',\n",
       " 'GetWeather',\n",
       " 'AddToPlaylist']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_sequence_labels = list(set(sequence_labels))\n",
    "unique_sequence_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3e9fce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 unique sequence labels\n"
     ]
    }
   ],
   "source": [
    "sequence_labels = [unique_sequence_labels.index(l) for l in sequence_labels]\n",
    "\n",
    "print(f'There are {len(unique_sequence_labels)} unique sequence labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6de12c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 72 unique token labels\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "unique_token_labels = list(set(reduce(lambda x, y: x + y, labels_for_tokens)))\n",
    "labels_for_tokens = [[unique_token_labels.index(_) for _ in l] for l in labels_for_tokens]\n",
    "\n",
    "print(f'There are {len(unique_token_labels)} unique token labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3a5251b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['listen', 'to', 'westbam', 'alumb', 'allergic', 'on', 'google', 'music']\n",
      "[22, 22, 68, 22, 58, 22, 51, 4]\n",
      "['O', 'O', 'B-artist', 'O', 'B-album', 'O', 'B-service', 'I-service']\n",
      "listen to westbam alumb allergic on google music\n",
      "0\n",
      "PlayMusic\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_utterances[0])\n",
    "print(labels_for_tokens[0])\n",
    "print([unique_token_labels[l] for l in labels_for_tokens[0]])\n",
    "print(utterances[0])\n",
    "print(sequence_labels[0])\n",
    "print(unique_sequence_labels[sequence_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "eec863af",
   "metadata": {},
   "outputs": [],
   "source": [
    "snips_dataset = Dataset.from_dict(\n",
    "    dict(\n",
    "        utterance=utterances, \n",
    "        label=sequence_labels,\n",
    "        tokens=tokenized_utterances,\n",
    "        token_labels=labels_for_tokens\n",
    "    )\n",
    ")\n",
    "snips_dataset = snips_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "67a6b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'rate homicide: a year on the killing streets five stars',\n",
       " 'label': 1,\n",
       " 'tokens': ['rate',\n",
       "  'homicide:',\n",
       "  'a',\n",
       "  'year',\n",
       "  'on',\n",
       "  'the',\n",
       "  'killing',\n",
       "  'streets',\n",
       "  'five',\n",
       "  'stars'],\n",
       " 'token_labels': [22, 44, 13, 13, 13, 13, 13, 13, 53, 29]}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc13ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to batch tokenize utterances with truncation\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"utterance\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee6381f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383065db38084bd1a0cec52c5f3dd274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170c76177e9f46f498d31d1a85d2edd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_clf_tokenized_snips = snips_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da2a0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'play a twenties song',\n",
       " 'label': 0,\n",
       " 'tokens': ['play', 'a', 'twenties', 'song'],\n",
       " 'token_labels': [22, 22, 37, 7],\n",
       " 'input_ids': [101, 1505, 170, 21708, 1461, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_clf_tokenized_snips['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a2333ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataCollatorWithPadding creates batch of data. It also dynamically pads text to the \n",
    "#  length of the longest element in the batch, making them all the same length. \n",
    "#  It's possible to pad your text in the tokenizer function with padding=True, dynamic padding is more efficient.\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54954b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b14125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collator will pad data so that all examples are the same input length.\n",
    "#  Attention mask is how we ignore attention scores for padding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154039ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d647d950",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sequence_clf_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-cased', \n",
    "    num_labels=len(unique_sequence_labels),\n",
    ")\n",
    "\n",
    "# set an index -> label dictionary\n",
    "sequence_clf_model.config.id2label = {i: l for i, l in enumerate(unique_sequence_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a4db4d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_clf_model.config.id2label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6352abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):  # custom method to take in logits and calculate accuracy of the eval set\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a04da07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./snips_clf/results\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # some deep learning parameters that the Trainer is able to take in\n",
    "    warmup_steps=len(seq_clf_tokenized_snips['train']) // 5,  # number of warmup steps for learning rate scheduler,\n",
    "    weight_decay = 0.05,\n",
    "    \n",
    "    logging_steps=1,\n",
    "    log_level='info',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=50,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=sequence_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=seq_clf_tokenized_snips['train'],\n",
    "    eval_dataset=seq_clf_tokenized_snips['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c7d229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 12:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9550352096557617,\n",
       " 'eval_accuracy': 0.09973251815055408,\n",
       " 'eval_runtime': 64.0129,\n",
       " 'eval_samples_per_second': 40.882,\n",
       " 'eval_steps_per_second': 1.281}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08f1cf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running training *****\n",
      "  Num examples = 10467\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='656' max='656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [656/656 22:53, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>0.159812</td>\n",
       "      <td>0.971341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.051554</td>\n",
       "      <td>0.987008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_clf/results/checkpoint-328\n",
      "Configuration saved in ./snips_clf/results/checkpoint-328/config.json\n",
      "Model weights saved in ./snips_clf/results/checkpoint-328/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_clf/results/checkpoint-656\n",
      "Configuration saved in ./snips_clf/results/checkpoint-656/config.json\n",
      "Model weights saved in ./snips_clf/results/checkpoint-656/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./snips_clf/results/checkpoint-656 (score: 0.05155394226312637).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=656, training_loss=0.6844381606277283, metrics={'train_runtime': 1376.1424, 'train_samples_per_second': 15.212, 'train_steps_per_second': 0.477, 'total_flos': 131576695874496.0, 'train_loss': 0.6844381606277283, 'epoch': 2.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8fe9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05155394226312637,\n",
       " 'eval_accuracy': 0.9870080244554834,\n",
       " 'eval_runtime': 51.0558,\n",
       " 'eval_samples_per_second': 51.258,\n",
       " 'eval_steps_per_second': 1.606,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e93471e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'AddToPlaylist', 'score': 0.9956121444702148}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", sequence_clf_model, tokenizer=tokenizer)\n",
    "pipe('Please add Here We Go by Dispatch to my road trip playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b373004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./snips_clf/results\n",
      "Configuration saved in ./snips_clf/results/config.json\n",
      "Model weights saved in ./snips_clf/results/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d7d27bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./snips_clf/results/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./snips_clf/results\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"PlayMusic\",\n",
      "    \"1\": \"RateBook\",\n",
      "    \"2\": \"SearchScreeningEvent\",\n",
      "    \"3\": \"SearchCreativeWork\",\n",
      "    \"4\": \"BookRestaurant\",\n",
      "    \"5\": \"GetWeather\",\n",
      "    \"6\": \"AddToPlaylist\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading configuration file ./snips_clf/results/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./snips_clf/results\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"PlayMusic\",\n",
      "    \"1\": \"RateBook\",\n",
      "    \"2\": \"SearchScreeningEvent\",\n",
      "    \"3\": \"SearchCreativeWork\",\n",
      "    \"4\": \"BookRestaurant\",\n",
      "    \"5\": \"GetWeather\",\n",
      "    \"6\": \"AddToPlaylist\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./snips_clf/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at ./snips_clf/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'AddToPlaylist', 'score': 0.9956121444702148}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", \"./snips_clf/results\", tokenizer=tokenizer)\n",
    "pipe('Please add Here We Go by Dispatch to my road trip playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15302def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52fef242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "frozen_sequence_clf_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-cased', \n",
    "    num_labels=len(unique_sequence_labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8fa35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in frozen_sequence_clf_model.distilbert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8dad2bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./snips_clf/results\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # some deep learning parameters that the Trainer is able to take in\n",
    "    warmup_steps=len(seq_clf_tokenized_snips['train']) // 5,  # number of warmup steps for learning rate scheduler,\n",
    "    weight_decay = 0.05,\n",
    "    \n",
    "    logging_steps=1,\n",
    "    log_level='info',\n",
    "    evaluation_strategy='epoch',\n",
    "    eval_steps=50,\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=frozen_sequence_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=seq_clf_tokenized_snips['train'],\n",
    "    eval_dataset=seq_clf_tokenized_snips['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cc1d2ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 03:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9511256217956543,\n",
       " 'eval_accuracy': 0.13870844478410393,\n",
       " 'eval_runtime': 33.0914,\n",
       " 'eval_samples_per_second': 79.084,\n",
       " 'eval_steps_per_second': 2.478}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bfa45688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running training *****\n",
      "  Num examples = 10467\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='656' max='656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [656/656 06:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.894000</td>\n",
       "      <td>1.889941</td>\n",
       "      <td>0.356133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.652300</td>\n",
       "      <td>1.679589</td>\n",
       "      <td>0.872755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_clf/results/checkpoint-328\n",
      "Configuration saved in ./snips_clf/results/checkpoint-328/config.json\n",
      "Model weights saved in ./snips_clf/results/checkpoint-328/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_clf/results/checkpoint-656\n",
      "Configuration saved in ./snips_clf/results/checkpoint-656/config.json\n",
      "Model weights saved in ./snips_clf/results/checkpoint-656/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./snips_clf/results/checkpoint-656 (score: 1.679589033126831).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=656, training_loss=1.8726866072634372, metrics={'train_runtime': 377.717, 'train_samples_per_second': 55.422, 'train_steps_per_second': 1.737, 'total_flos': 131576695874496.0, 'train_loss': 1.8726866072634372, 'epoch': 2.0})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()  # ~23min -> ~6min on my laptop with all of distilbert frozen with a worse loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b911ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: token_labels, tokens, utterance.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.679589033126831,\n",
       " 'eval_accuracy': 0.8727550630492931,\n",
       " 'eval_runtime': 32.8797,\n",
       " 'eval_samples_per_second': 79.593,\n",
       " 'eval_steps_per_second': 2.494,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3b0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d99579a",
   "metadata": {},
   "source": [
    "## 6.3 BERT for token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb6edfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification, DistilBertForTokenClassification, \\\n",
    "                         DistilBertTokenizerFast, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cdb1bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/vocab.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ba377304984dc63e3ede0e23a938bbbf04d5c3835b66d5bb48343aecca188429.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/acb5c2138c1f8c84f074b86dafce3631667fccd6efcb1a7ea1320cf75c386a36.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-cased/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/81e970e5e6ec68be12da0f8f3b2f2469c78d579282299a2ea65b4b7441719107.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using a cased tokenizer because I think case will matter\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "446479c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'play a twenties song',\n",
       " 'label': 0,\n",
       " 'tokens': ['play', 'a', 'twenties', 'song'],\n",
       " 'token_labels': [22, 22, 37, 7]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e652f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "36d41d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The given \"token_labels\" may not match up with the BERT wordpiece tokenization so\n",
    "#  this function will map them to the tokenization that BERT uses\n",
    "#  -100 is a reserved for labels where we do not want to calculate losses so BERT doesn't waste time\n",
    "#  trying to predict tokens like CLS or SEP\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"token_labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:  # Set the special tokens to -100.\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)  # CLS and SEP are labeled as -100\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "50a7ac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'play a twenties song',\n",
       " 'label': 0,\n",
       " 'tokens': ['play', 'a', 'twenties', 'song'],\n",
       " 'token_labels': [22, 22, 37, 7]}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "832dd8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13ff442399a4a7daf54f746012dde79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b5c3598b0c40ebb97545a02faa2e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map our dataset from sequence classification to be for token classification\n",
    "tok_clf_tokenized_snips = snips_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d4b31d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterance': 'play a twenties song',\n",
       " 'label': 0,\n",
       " 'tokens': ['play', 'a', 'twenties', 'song'],\n",
       " 'token_labels': [22, 22, 37, 7],\n",
       " 'input_ids': [101, 1505, 170, 21708, 1461, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1],\n",
       " 'labels': [-100, 22, 22, 37, 7, -100]}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_clf_tokenized_snips['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f4b4c9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10467\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2617\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_clf_tokenized_snips['train'] = tok_clf_tokenized_snips['train'].remove_columns(\n",
    "    ['utterance', 'label', 'tokens', 'token_labels']\n",
    ")\n",
    "\n",
    "tok_clf_tokenized_snips['test'] = tok_clf_tokenized_snips['test'].remove_columns(\n",
    "    ['utterance', 'label', 'tokens', 'token_labels']\n",
    ")\n",
    "\n",
    "tok_clf_tokenized_snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f29865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b715cf3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-cased/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/ebe1ea24d11aa664488b8de5b21e33989008ca78f207d4e30ec6350b693f073f.302bfd1b5e031cc1b17796e0b6e5b242ba2045d31d00f97589e12b458ebff27a\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-cased/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/9c9f39769dba4c5fe379b4bc82973eb01297bd607954621434eb9f1bc85a23a0.06b428c87335c1bb22eae46fdab31c8286efa0aa09e898a7ac42ddf5c3f5dc19\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tok_clf_model = DistilBertForTokenClassification.from_pretrained(\n",
    "    'distilbert-base-cased', num_labels=len(unique_token_labels)\n",
    ")\n",
    "\n",
    "# Set our label dictionary\n",
    "tok_clf_model.config.id2label = {i: l for i, l in enumerate(unique_token_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "08bda49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('B-country', 'B-timeRange')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_clf_model.config.id2label[0], tok_clf_model.config.id2label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c848c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./snips_tok_clf/results\",\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    load_best_model_at_end=True,\n",
    "        \n",
    "    logging_steps=10,\n",
    "    log_level='info',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch'\n",
    ")\n",
    "\n",
    "# Define the trainer:\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tok_clf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tok_clf_tokenized_snips['train'],\n",
    "    eval_dataset=tok_clf_tokenized_snips['test'],\n",
    "    data_collator=tok_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c1c1b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='164' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 17:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.45733642578125,\n",
       " 'eval_runtime': 40.4286,\n",
       " 'eval_samples_per_second': 64.731,\n",
       " 'eval_steps_per_second': 2.028}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4f9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6cd1c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10467\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='656' max='656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [656/656 30:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.172545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.130660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_tok_clf/results/checkpoint-328\n",
      "Configuration saved in ./snips_tok_clf/results/checkpoint-328/config.json\n",
      "Model weights saved in ./snips_tok_clf/results/checkpoint-328/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./snips_tok_clf/results/checkpoint-656\n",
      "Configuration saved in ./snips_tok_clf/results/checkpoint-656/config.json\n",
      "Model weights saved in ./snips_tok_clf/results/checkpoint-656/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./snips_tok_clf/results/checkpoint-656 (score: 0.13066013157367706).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=656, training_loss=0.397148780070427, metrics={'train_runtime': 1851.7923, 'train_samples_per_second': 11.305, 'train_steps_per_second': 0.354, 'total_flos': 129927264993792.0, 'train_loss': 0.397148780070427, 'epoch': 2.0})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "01b18ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2617\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13066013157367706,\n",
       " 'eval_runtime': 34.3515,\n",
       " 'eval_samples_per_second': 76.183,\n",
       " 'eval_steps_per_second': 2.387,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8fb6a994",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-entity_name',\n",
       "  'score': 0.887767,\n",
       "  'index': 3,\n",
       "  'word': 'Here',\n",
       "  'start': 11,\n",
       "  'end': 15},\n",
       " {'entity': 'I-entity_name',\n",
       "  'score': 0.88551474,\n",
       "  'index': 4,\n",
       "  'word': 'We',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'I-entity_name',\n",
       "  'score': 0.9170048,\n",
       "  'index': 5,\n",
       "  'word': 'Go',\n",
       "  'start': 19,\n",
       "  'end': 21},\n",
       " {'entity': 'B-artist',\n",
       "  'score': 0.93062943,\n",
       "  'index': 7,\n",
       "  'word': 'Di',\n",
       "  'start': 25,\n",
       "  'end': 27},\n",
       " {'entity': 'I-artist',\n",
       "  'score': 0.94451386,\n",
       "  'index': 8,\n",
       "  'word': '##sp',\n",
       "  'start': 27,\n",
       "  'end': 29},\n",
       " {'entity': 'I-artist',\n",
       "  'score': 0.78699875,\n",
       "  'index': 9,\n",
       "  'word': '##atch',\n",
       "  'start': 29,\n",
       "  'end': 33},\n",
       " {'entity': 'B-playlist_owner',\n",
       "  'score': 0.9935272,\n",
       "  'index': 11,\n",
       "  'word': 'my',\n",
       "  'start': 37,\n",
       "  'end': 39},\n",
       " {'entity': 'B-playlist',\n",
       "  'score': 0.994918,\n",
       "  'index': 12,\n",
       "  'word': 'road',\n",
       "  'start': 40,\n",
       "  'end': 44},\n",
       " {'entity': 'I-playlist',\n",
       "  'score': 0.9942649,\n",
       "  'index': 13,\n",
       "  'word': 'trip',\n",
       "  'start': 45,\n",
       "  'end': 49}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", tok_clf_model, tokenizer=tokenizer)\n",
    "pipe('Please add Here We Go by Dispatch to my road trip playlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6749678a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-object_name',\n",
       "  'score': 0.94716674,\n",
       "  'index': 2,\n",
       "  'word': 'the',\n",
       "  'start': 5,\n",
       "  'end': 8},\n",
       " {'entity': 'I-object_name',\n",
       "  'score': 0.95756745,\n",
       "  'index': 3,\n",
       "  'word': 'do',\n",
       "  'start': 9,\n",
       "  'end': 11},\n",
       " {'entity': 'I-object_name',\n",
       "  'score': 0.9812471,\n",
       "  'index': 4,\n",
       "  'word': '##og',\n",
       "  'start': 11,\n",
       "  'end': 13},\n",
       " {'entity': 'I-object_name',\n",
       "  'score': 0.97237736,\n",
       "  'index': 5,\n",
       "  'word': 'food',\n",
       "  'start': 14,\n",
       "  'end': 18},\n",
       " {'entity': 'B-rating_value',\n",
       "  'score': 0.9964361,\n",
       "  'index': 6,\n",
       "  'word': '5',\n",
       "  'start': 19,\n",
       "  'end': 20},\n",
       " {'entity': 'B-best_rating',\n",
       "  'score': 0.97492224,\n",
       "  'index': 9,\n",
       "  'word': '5',\n",
       "  'start': 28,\n",
       "  'end': 29}]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", tok_clf_model, tokenizer=tokenizer)\n",
    "pipe('Rate the doog food 5 out of 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09ac8a2a",
   "metadata": {},
   "source": [
    "## 6.4 BERT for question/answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb67c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, BertForQuestionAnswering, pipeline, \\\n",
    "                         DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a8066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81682de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizerFast.from_pretrained('bert-large-uncased', return_token_type_ids=True)\n",
    "\n",
    "qa_bert = BertForQuestionAnswering.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9bc928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29989, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_csv('../data/qa.csv')\n",
    "\n",
    "qa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75464a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What sare the benifts of the blood brain barrir?</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>isolated from the bloodstream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is surrounded by cerebrospinal fluid?</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does the skull protect?</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What has been injected into rats to produce pr...</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>chemicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What can cause issues with how the brain works?</td>\n",
       "      <td>Another approach to brain function is to exami...</td>\n",
       "      <td>93</td>\n",
       "      <td>94</td>\n",
       "      <td>brain damage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   What sare the benifts of the blood brain barrir?   \n",
       "1         What is surrounded by cerebrospinal fluid?   \n",
       "2                       What does the skull protect?   \n",
       "3  What has been injected into rats to produce pr...   \n",
       "4    What can cause issues with how the brain works?   \n",
       "\n",
       "                                             context  start_positions  \\\n",
       "0  Another approach to brain function is to exami...               56   \n",
       "1  Another approach to brain function is to exami...               16   \n",
       "2  Another approach to brain function is to exami...               11   \n",
       "3  Another approach to brain function is to exami...              153   \n",
       "4  Another approach to brain function is to exami...               93   \n",
       "\n",
       "   end_positions                         answer  \n",
       "0             60  isolated from the bloodstream  \n",
       "1             16                          brain  \n",
       "2             11                          brain  \n",
       "3            153                      chemicals  \n",
       "4             94                   brain damage  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65283a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question            What sare the benifts of the blood brain barrir?\n",
       "context            Another approach to brain function is to exami...\n",
       "start_positions                                                   56\n",
       "end_positions                                                     60\n",
       "answer                                 isolated from the bloodstream\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1159f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isolated from the bloodstream'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 56, 57, 58, 59, and 60 including question while encoding\n",
    "bert_tokenizer.decode(bert_tokenizer.encode(qa_df.iloc[0].question, qa_df.iloc[0].context)[56:61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1431874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645f97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only grab 4,000 examples\n",
    "qa_dataset = Dataset.from_pandas(qa_df.sample(4000, random_state=42))\n",
    "\n",
    "# Dataset has a built in train test split method\n",
    "qa_dataset = qa_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c29b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91087a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f984729ef6a4640a8a05a498dd41b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3f29de452b4e99b641a2da21565a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# standard preprocessing here\n",
    "def preprocess(data):\n",
    "    return bert_tokenizer(data['question'], data['context'], truncation=True)\n",
    "\n",
    "qa_dataset = qa_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf73c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all but the last 2 encoder layers in BERT to speed up training\n",
    "for name, param in qa_bert.bert.named_parameters():\n",
    "    if 'encoder.layer.22' in name:\n",
    "        break\n",
    "    param.requires_grad = False  # disable training in BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55062347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bad0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)  # collator with padding to dynamically pad our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c6f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: __index_level_0__, answer, question, context.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qa/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_dir='./qa/logs',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=qa_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=qa_dataset['train'],\n",
    "    eval_dataset=qa_dataset['test'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e29d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: __index_level_0__, context, answer, question.\n",
      "***** Running training *****\n",
      "  Num examples = 3200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [269/400 7:34:33 < 3:43:01, 0.01 it/s, Epoch 2.68/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.314100</td>\n",
       "      <td>4.248008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.009000</td>\n",
       "      <td>4.084617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: __index_level_0__, context, answer, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./qa/results/checkpoint-100\n",
      "Configuration saved in ./qa/results/checkpoint-100/config.json\n",
      "Model weights saved in ./qa/results/checkpoint-100/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: __index_level_0__, context, answer, question.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./qa/results/checkpoint-200\n",
      "Configuration saved in ./qa/results/checkpoint-200/config.json\n",
      "Model weights saved in ./qa/results/checkpoint-200/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/trainer.py:1332\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1332\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1335\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1338\u001b[0m ):\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/trainer.py:1891\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocast_smart_context_manager():\n\u001b[0;32m-> 1891\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1894\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/trainer.py:1923\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1923\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1839\u001b[0m, in \u001b[0;36mBertForQuestionAnswering.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;124;03mstart_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;124;03m    Labels for position (index) of the start of the labelled span for computing the token classification loss.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[38;5;124;03m    are not taken into account for computing the loss.\u001b[39;00m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1837\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1839\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1851\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1853\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqa_outputs(sequence_output)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[0;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    578\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:513\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    511\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 513\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/modeling_utils.py:2370\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m-> 2370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:526\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    525\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 526\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:441\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    439\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    440\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 441\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/normalization.py:190\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/pytorch_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1164\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_full_backward_hook\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_full_backward_hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1166\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf31694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q/A models are very large and take a long time to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bb1fa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./qa/results\n",
      "Configuration saved in ./qa/results/config.json\n",
      "Model weights saved in ./qa/results/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024e15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a33b075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./qa/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qa/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file ./qa/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qa/results\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./qa/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./qa/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"question-answering\", './qa/results', tokenizer=bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b56c0676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.13000917434692383, 'start': 15, 'end': 25, 'answer': 'California'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Where is Sinan living these days?\", \"Sinan lives in California but Matt lives in Boston.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fad03889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.005417873617261648, 'start': 281, 'end': 286, 'answer': 'Keith'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "princeton = \"\"\"In 1675, a Quaker missionary from England, encouraged by New Jersey proprietors John Lord \n",
    "              \"Berkeley and Sir George Carteret, arrived to establish a settlement in this area near the \n",
    "              \"Delaware River, which was inhabited by the Lenni-Lenape Indians. The Keith survey of 1685 \n",
    "              \"established the western boundary of Middlesex and Somerset Counties and later, the Township \n",
    "              \"of Princeton. Today Keith's Line is recognized as Province Line Road. With the laying of the \n",
    "              \"cornerstone for Nassau Hall in 1754, Princeton began its development as a location for \n",
    "              \"quality education. Nassau Hall was named for William III, Prince of Orange-Nassau. This simple stone \n",
    "              \"edifice was one of the largest public buildings in the colonies and became a model for many other \n",
    "              \"structures in New Jersey and Pennsylvania.\"\"\"\n",
    "\n",
    "pipe(\"What survey led to the founding of Princeton?\", princeton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc0f857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0028718607500195503,\n",
       " 'start': 379,\n",
       " 'end': 401,\n",
       " 'answer': 'lecturer/mathematician'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON = 'Sinan Ozdemir'\n",
    "\n",
    "# Note this is NOT an efficient way to search on google. This is done simply for education purposes\n",
    "google_html = BeautifulSoup(requests.get(f'https://www.google.com/search?q={PERSON}').text).get_text()[:512]\n",
    "\n",
    "pipe(f'Who is {PERSON}?', google_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8b559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274a203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d54c484d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/pytorch_model.bin from cache at /Users/sinanozdemir/.cache/huggingface/transformers/eac3273a8097dda671e3bea1db32c616e74f36a306c65b4858171c98d6db83e9.084aa7284f3a51fa1c8f0641aa04c47d366fbd18711f29d0a995693cfdbc9c9e\n",
      "All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at deepset/roberta-base-squad2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/vocab.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/81c80edb4c6cefa5cae64ccfdb34b3b309ecaf60da99da7cd1c17e24a5d36eb5.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/merges.txt from cache at /Users/sinanozdemir/.cache/huggingface/transformers/b87d46371731376b11768b7839b1a5938a4f77d6bd2d9b683f167df0026af432.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/special_tokens_map.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c9d2c178fac8d40234baa1833a3b1903d393729bf93ea34da247c07db24900d0.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
      "loading file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/tokenizer_config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/e8a600814b69e3ee74bb4a7398cc6fef9812475010f16a6c9f151b2c2772b089.451739a2f3b82c3375da0dfc6af295bedc4567373b171f514dd09a4cc4b31513\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json from cache at /Users/sinanozdemir/.cache/huggingface/transformers/c40d0abb589629c48763f271020d0b1f602f5208c432c0874d420491ed37e28b.122ed338b3591c07dba452777c59ff52330edb340d3d56d67aa9117ad9905673\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"deepset/roberta-base-squad2\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"language\": \"english\",\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"name\": \"Roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From Huggingface: https://huggingface.co/deepset/roberta-base-squad2\n",
    "\n",
    "squad_pipe = pipeline(\"question-answering\", \"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86924a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9648360013961792, 'start': 15, 'end': 25, 'answer': 'California'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_pipe(\"Where is Sinan living these days?\", \"Sinan lives in California but Matt lives in Boston.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "11647ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3472403585910797,\n",
       " 'start': 281,\n",
       " 'end': 293,\n",
       " 'answer': 'Keith survey'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_pipe(\"What survey led to the founding of Princeton?\", princeton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627c910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3bee15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_input = bert_tokenizer(  # tokenize our example\n",
    "    \"Where is Sinan living these days?\", \"Sinan lives in California but Matt lives in Boston.\",\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efa803db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./qa/results/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ./qa/results/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at ./qa/results.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.8639, -0.9919, -3.9533,  4.4210,  2.9922,  2.1413, -0.5329, -1.6829,\n",
       "         -4.1338, -1.5555,  4.4860,  2.6627,  2.4715,  1.9536,  4.6590,  1.5530,\n",
       "          5.1868,  3.2874,  0.9691,  4.3806,  0.2219,  0.2125]],\n",
       "       grad_fn=<CloneBackward0>), end_logits=tensor([[-1.9033, -2.5288, -5.1312,  1.5285,  2.5609,  0.8077, -2.8993, -2.4631,\n",
       "         -5.0754, -3.7111,  0.5029,  2.2174,  0.0548, -1.1600,  5.4156, -0.2253,\n",
       "          2.7790,  1.6694, -1.6699,  4.4955, -1.0099, -1.0195]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_qa_bert = BertForQuestionAnswering.from_pretrained('./qa/results')\n",
    "\n",
    "output = finetuned_qa_bert(**qa_input)  # pass the input through our QA model\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "71fa3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_labels = bert_tokenizer.convert_ids_to_tokens(qa_input['input_ids'].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ddf6c4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot start and end logits for our fine-tuned model\n",
    "\n",
    "sns.set(rc={\"figure.figsize\":(20, 5)}) \n",
    "\n",
    "# Create a barplot showing the start word score for all of the tokens.\n",
    "ax = sns.barplot(x=[f'{i}_{t}' for i, t in enumerate(token_labels)], y=output.start_logits.squeeze().tolist(), ci=None)\n",
    "# Turn the xlabels vertical.\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# Turn on the vertical grid to help align words to scores.\n",
    "plt.title('Start Word Scores')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Create a barplot showing the start word score for all of the tokens.\n",
    "ax = sns.barplot(x=[f'{i}_{t}' for i, t in enumerate(token_labels)], y=output.end_logits.squeeze().tolist(), ci=None)\n",
    "# Turn the xlabels vertical.\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=\"center\")\n",
    "# Turn on the vertical grid to help align words to scores.\n",
    "plt.title('End Word Scores')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8804d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ff9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
