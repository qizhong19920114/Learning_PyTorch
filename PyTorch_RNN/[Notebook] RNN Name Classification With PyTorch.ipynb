{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e89147",
   "metadata": {},
   "source": [
    "### PyTorch RNN Tutorial - Name Classification Using A Recurrent Neural Net\n",
    "\n",
    "https://www.youtube.com/watch?v=WEV61GmmPrk&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=21\n",
    "\n",
    "__Note__: 这个 Tutorial 不是直接用 PyTorch 的 RNN 包，而是我们自己 implement 一个 RNN 来用!\n",
    "\n",
    "\n",
    "Project Process: \n",
    "1. preprocessing， 比如把有音标的单词给处理一下\n",
    "2. how to encode data. category/country 直接用index, 然后产生 tensor array, ```torch.tensor([all_categories.index(category)], dtype=torch.long)```. 然后 name 的话，就得对每个字母 1 hot, 然后一个name 的length作为一个 dimension, 输出一个 matrix (tensor). 感觉这里好多都是用 ```tensor = torch.zeros(len(line), 1, N_LETTERS)```, 然后再一个个 assign 值，来产生 encoded data in tensor format\n",
    "3. define model, 这个直接照图写\n",
    "4. training loop, 知道名字怎么 sequence 产生一个 tensor 然后跟 category/country 的 tensor 一起， 传到 loss function， 然后其他的都是照常的 training loop 的写法\n",
    "\n",
    "thoughts: \n",
    "- model 和 training loop 不难，主要是data 怎么预处理和 encoding 产生 input tensor 比较麻烦\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f91f7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# This is a nice trick to add other python file to this notebook, 这样就挺方便的!!!\n",
    "# 本质上就是告诉 python interpreter, 你也去看一下我给你添加的这个 file path， 然后正好是我要 import 的那个 path\n",
    "# 但是这个方法好像有点小问题，就是你 import 的文件改了，你这个kernel 也得 refresh\n",
    "# \"sys.path contains a list of directories that the interpreter will search in for the required module\"\n",
    "#  credit: https://stackoverflow.com/questions/49264194/import-py-file-in-another-directory-in-jupyter-notebook  \n",
    "\n",
    "# 这里好像非得 join \"..\" 才行\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path + \"/PyTorch_RNN/pytorch-examples/rnn-name-classification\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9695b677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/qizhong/Downloads/PyTorch_Learning/PyTorch_RNN', '/python', '/python/build', '/Users/qizhong/Downloads/PyTorch_Learning/PyTorch_RNN', '/opt/anaconda3/envs/pytorch/lib/python37.zip', '/opt/anaconda3/envs/pytorch/lib/python3.7', '/opt/anaconda3/envs/pytorch/lib/python3.7/lib-dynload', '', '/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages', '/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/IPython/extensions', '/Users/qizhong/.ipython', '/Users/qizhong/Downloads/PyTorch_Learning/PyTorch_RNN/pytorch-examples/rnn-name-classification']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12716611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5855f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16631cc5",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/rnn_model_arch.png\" width=800 height=800 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e02af04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这边主要就是 implement 上面这个图， 他这个图不准确？应该只有一个 hidden module\n",
    "# Question:  nn.Linear 是怎么把 size 128 + 57 -> output 成 18 size 的?\n",
    "# Answer: https://stackoverflow.com/questions/54916135/what-is-the-class-definition-of-nn-linear-in-pytorch\n",
    "#     - \"Note that the weights W have shape (out_features, in_features) and biases b have shape (out_features).\"\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    # nn.RNN\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # initialize 所有需要的 layer (这里先不连, forward 部分再连)\n",
    "        self.hidden_size = hidden_size\n",
    "        # 这边 input size 因为是 combine 所以是两个加起来，然后output给 hidden 所以用 hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # 为啥 dim 1? 因为softmax 就一个 array 的output\n",
    "        \n",
    "    \n",
    "    # 这边 forward 就是写怎么连，怎么去 model 这个 forward path， 这里没有写 loss 因为\n",
    "    # 根据签名说 loss 包括在 softmax 里面了，所有不用专门定\n",
    "    # 这边连 layer, 我 A 连 B 直接 self.A(B) 这要写就可以\n",
    "    def forward(self, input_tensor, hidden_tensor): \n",
    "        # 就是上图的 hidden 和 input combine 然后给 output 和 hidden 用\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), dim=1)\n",
    "        \n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    # 这个是因为我们需要 initial hidden state, \n",
    "    # 我们要 return 一个 empty tensor of 1 x hidden_size\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a77b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "category_lines, all_categories = load_data('./pytorch-examples/rnn-name-classification/data/names/*.txt')\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "088786eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(input_size=N_LETTERS, \n",
    "          hidden_size=n_hidden, \n",
    "          output_size=n_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2bd6b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# one step 试一下 output 长啥样\n",
    "input_tensor = letter_to_tensor('A') # 就只给一个字母作为 input\n",
    "hidden_tensor = rnn.init_hidden() #用我们上面的 init_hidden 来弄一个 dummy hidden tensor\n",
    "\n",
    "# 这边 rnn(..) 就相当于直接 call forward path 了, 但是 rnn.forward 这样写清楚一些\n",
    "output, next_hidden = rnn.forward(input_tensor, hidden_tensor)\n",
    "\n",
    "#  看一下 output size 和 next_hidden size 长啥样\n",
    "print(output.size())\n",
    "print(next_hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62485652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# whole sequence/name 试一下看直接给一个单词长啥样\n",
    "input_tensor = line_to_tensor('Albert')\n",
    "hidden_tensor = rnn.init_hidden()\n",
    "\n",
    "# 注意 line_to_tensor() output 的是 <line_length x 1 x n_letters>\n",
    "# 这里 input_tensor[0] 还是只看一个字母, 那么我整个 sequence 是咋写的? 估计后面 training 会有\n",
    "output, next_hidden = rnn(input_tensor[0], hidden_tensor)\n",
    "print(output.size())\n",
    "print(next_hidden.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d20ec0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese\n"
     ]
    }
   ],
   "source": [
    "# helper function to turn tensor output into a category name\n",
    "def category_from_output(output):\n",
    "    #通过 argmax 拿到 softmax output 的最大一个值的 index 然后就可以 look up for item name\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]\n",
    "\n",
    "# Italian 不对，因为没有 train 啦\n",
    "print(category_from_output(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93803035",
   "metadata": {},
   "source": [
    "<font color='red'>Question</font>: 为啥 loss 用这个？不用 cross entropy\n",
    "\n",
    "<font color='green'>Answer</font>: 查了一下，好像就是一个东西，只是在 pytorch 里面 input 略有不同\n",
    "\n",
    "NNLoss: Negative Likelihood Loss Func: The negative log likelihood loss. It is useful to \n",
    "train a classification problem with C classes.\n",
    "\n",
    "when designing a neural network multi-class classifier, you can you CrossEntropyLoss with no activation, \n",
    "or you can use NLLLoss with log-SoftMax activation. This applies only to multi-class classification\n",
    "\n",
    "有人说就是一个东西: The negative log likelihood (eq.80) is also known as the multiclass cross-entropy\n",
    "as they are in fact two different interpretations of the same formula. 因为:\n",
    "- Loss = - (y*log(y_hat) + (1-y) log(1-y_hat))  就是 punish 当 y 猜的是 1, 然后 y_hat 是接近0, 或者当 y 猜的是 0, 然后 y_hat 是 接近1, \n",
    "\n",
    "感觉就是 pytorch 里面，如果我明确的写 logSoftMax 那就要用 NLL, 如果我用 Cross Entropy， 那么 softmax 就包括到里面了\n",
    "\n",
    "\n",
    "突然想起来， [Notebook] Deep Learning With PyTorch - Full Course 这个 noteoobk 里面我有写到的\n",
    "- \"CrossEntropyLoss in PyTorch (applies Softmax) nn.LogSoftmax + nn.NLLLoss\"\n",
    "\n",
    "\n",
    "ref: \n",
    "- https://jamesmccaffrey.wordpress.com/2020/06/11/pytorch-crossentropyloss-vs-nllloss-cross-entropy-loss-vs-negative-log-likelihood-loss/\n",
    "- https://discuss.pytorch.org/t/difference-between-cross-entropy-loss-or-log-likelihood-loss/38816/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a211c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9096ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_tensor is the 1 hot encoding of name/word (1 x length x letter_n)\n",
    "# category_tensor is the 1 hot encoding of category (1 x category_n)\n",
    "# 这个就是 把每个 word/name 给一个个字母过一遍 rnn model, 然后 forward path (算 loss) 和 backword pass 算 gradient\n",
    "# 走一边\n",
    "def train_helper(name_tensor, category_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    # sequence model sliding window 1 by 1 to generate the rnn output tensor for each name\n",
    "    for i in range(name_tensor.size()[0]):\n",
    "        output, hidden = rnn(name_tensor[i], hidden)\n",
    "        \n",
    "    loss = loss_func(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bb344c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5.0 2.4462 Sauvageau / Greek WRONG (French)\n",
      "10000 10.0 1.7541 Cabrera / Spanish CORRECT\n",
      "15000 15.0 3.1696 Pech / Dutch WRONG (Czech)\n",
      "20000 20.0 0.8972 Tadhgan / Irish CORRECT\n",
      "25000 25.0 1.3320 Login / Irish CORRECT\n",
      "30000 30.0 2.0298 Mujdabaev / Russian CORRECT\n",
      "35000 35.0 1.2564 Ozimuk / Polish WRONG (Czech)\n",
      "40000 40.0 1.4679 Bock / Czech CORRECT\n",
      "45000 45.0 3.1013 Adams / Arabic WRONG (English)\n",
      "50000 50.0 1.9323 Eccott / French WRONG (English)\n",
      "55000 55.00000000000001 1.1734 Laren / Dutch CORRECT\n",
      "60000 60.0 1.2413 Daviau / French CORRECT\n",
      "65000 65.0 0.5176 Ryom / Korean CORRECT\n",
      "70000 70.0 0.2984 Savatier / French CORRECT\n",
      "75000 75.0 5.4240 Kan / Chinese WRONG (Dutch)\n",
      "80000 80.0 1.5307 Quintana / Japanese WRONG (Spanish)\n",
      "85000 85.0 0.8878 Watt / Scottish CORRECT\n",
      "90000 90.0 0.3297 Khoury / Arabic CORRECT\n",
      "95000 95.0 3.5032 Horri / Italian WRONG (Japanese)\n",
      "100000 100.0 3.1083 Grant / Vietnamese WRONG (Scottish)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv2ElEQVR4nO3deVyVZf7/8deHHWRT9lVUEBTEDVNbzKXSrLQmq6nG9imrmamZmpq+02/mW818m6aZpplpGy3b97I9szJzyRV3BBUURRAQRAQUZbt+f5wTIwhy0AMHzvk8Hw8ewbmvc9+f29ve3lznuq9LjDEopZTq/dwcXYBSSin70EBXSiknoYGulFJOQgNdKaWchAa6Uko5CQ9HHTg0NNQkJCQ46vBKKdUrrV+/vtwYE9bWNocFekJCApmZmY46vFJK9Uoisre9bdrlopRSTkIDXSmlnIQGulJKOQkNdKWUchIa6Eop5SQ00JVSyklooCullJPodYG+r+Ioj3y2jfrGJkeXopRSPUqvC/QdJdW8/MMeXl/V7th6pZRySb0u0KcMCee8pFD+8e1ODtYcd3Q5SinVY/S6QBcR/njZUGrrGvnb1zsdXY5SSvUYvS7QARLDA7hhfALvrCtg2/7Dji5HKaV6hF4Z6AD3XJBEXz8vHvk0G10XVSmlbAh0EYkTkSUiki0i20TknjbaBInIZyKy2drm5q4p97+CfD25/6Jk1u6p4KONRV19OKWU6vFsuUNvAO4zxgwFxgF3i8jQVm3uBrKNMcOBicDfRcTLrpW24ZoxcYyKD+bRz7Mp1w9IlVIursNAN8YUG2M2WL+vBnKAmNbNgAAREcAfqMDyD0GXcncTnrgynSPHG3j0s+yuPpxSSvVonepDF5EEYCSwptWmZ4AhwH5gK3CPMeakJ39E5HYRyRSRzLKystOruJWkiADunpTIp5v38932UrvsUymleiObA11E/IEPgXuNMVWtNk8FNgHRwAjgGREJbL0PY8xcY0yGMSYjLKzNFZROy10TExkc4c/vP8qi+li93farlFK9iU2BLiKeWML8TWPMgjaa3AwsMBZ5QD6QYr8yT83Lw43Hf5JO8eFjvLtuX3cdVimlehRbRrkI8BKQY4x5qp1mBcAUa/sIIBnYba8ibTG6f1+GxwXzwfpCHcaolHJJttyhnwPMBiaLyCbr13QRmSMic6xtHgPOFpGtwGLgQWNMeRfV3K6rM2LZXlLN1iJ92Egp5Xo8OmpgjFkBSAdt9gMX2auo03XZ8Gge/Syb9zL3kR4b7OhylFKqW/XaJ0XbEujjycVpkXy6aT/H6hsdXY5SSnUrpwp0gKsy4qg61sCibSWOLkUppbqV0wX6+IEhxAT78sH6QkeXopRS3crpAt3NTbgqI5YVeeUUVdY6uhyllOo2ThfoAFeOisUYWJSl3S5KKdfhlIEe18+P6CAfNu6rdHQpSinVbZwy0AFGxvdlY8EhR5ehlFLdxmkDfURcMIWHaimr1ml1lVKuwWkDfWR8MACbtNtFKeUinDbQ02KC8HAT7XZRSrkMpw10H093hkQFsrGg0tGlKKVUt3DaQAdLt8uWwkoam3T2RaWU83P6QD9S10jugWpHl6KUUl3OuQM9ri+AdrsopVyCUwd6/xA/+vp56gejSimX4NSBLiKMiAvWoYtKKZdgyxJ0cSKyRESyRWSbiNzTTruJ1tWMtonIUvuXenpGxvcl90ANVbp4tFLKydlyh94A3GeMGQqMA+4WkaEnNhCRYOA5YIYxJhW4yt6Fnq4RccEYA1v26bJ0Sinn1mGgG2OKjTEbrN9XAzlATKtm1wELjDEF1nYH7F3o6RoeFwzA5sJKh9ahlFJdrVN96CKSAIwE1rTaNBjoKyLfi8h6EbmhnfffLiKZIpJZVlZ2WgV3VpCvJ7F9fckpruqW4ymllKPYHOgi4g98CNxrjGmdjh7AaOASYCrw/0RkcOt9GGPmGmMyjDEZYWFhZ1B256REBrCjRMeiK6Wcm02BLiKeWML8TWPMgjaaFAKLjDFHjDHlwDJguP3KPDMpkYHsLj/C8QZdOFop5bxsGeUiwEtAjjHmqXaafQKcKyIeIuIHjMXS194jJEcG0NhkyDtQ4+hSlFKqy3jY0OYcYDawVUQ2WV/7HyAewBjzgjEmR0S+ArYATcCLxpisLqj3tKREBgCwo6Sa1OggB1ejlFJdo8NAN8asAMSGdk8CT9qjKHsbENoHL3c3tms/ulLKiTn1k6I/8nB3IzHcXwNdKeXUXCLQAVKiAthRokMXlVLOy3UCPTKA0qrjHDpS5+hSlFKqS7hMoCdHBgJot4tSymm5TKAPsY502a7dLkopJ+UygR4W4E1fP099YlQp5bRcJtBFhJTIQHI00JVSTsplAh0sT4zmllbTpItGK6WckEsFekpkAEfrGtl36KijS1FKKbtzrUCPsox0ySnWbhellPNxqUAfHOGPCGTr3OhKKSfkUoHu5+XByLhgvskudXQpSilldy4V6ACXDY8mp7iKvAPa7aKUci4uF+iXDItCBD7bXOzoUpRSyq5cLtDDA30YNyCEz7bsxxgdvqiUch4uF+hg6XbZXXZEPxxVSjkVW5agixORJSKSLSLbROSeU7QdIyINIjLLvmXa17S0SDzcRLtdlFJOxZY79AbgPmPMUGAccLeIDG3dSETcgSeAr+1bov316+PFuUmhfLZZu12UUs6jw0A3xhQbYzZYv6/GsvhzTBtNfwl8CBywa4Vd5LL0aIoqa9m4r9LRpSillF10qg9dRBKAkcCaVq/HAFcAz3fw/ttFJFNEMsvKyjpZqn1dmBqBl4cbn27a79A6lFLKXmwOdBHxx3IHfq8xpvWniU8DDxpjmk61D2PMXGNMhjEmIywsrNPF2lOgjycTB4exMKtYJ+tSSjkFmwJdRDyxhPmbxpgFbTTJAN4RkT3ALOA5EbncXkV2lUuHR1NadZzMvYccXYpSSp0xW0a5CPASkGOMeaqtNsaYAcaYBGNMAvABcJcx5mN7FtoVpqSE4+3hxhdbtNtFKdX72XKHfg4wG5gsIpusX9NFZI6IzOni+rpUH28PJqeE82VWCY3a7aKU6uU8OmpgjFkBiK07NMbcdCYFdbdL0qNYmFXCuj0VjBsY4uhylFLqtLnkk6InmpwSjo+nG59rt4tSqpdz+UD38/JgSkoEX2WV0NB4ykE6SinVo7l8oIOl26W8po61+RWOLkUppU6bBjowKTkcX093Plhf6OhSlFLqtGmgA75e7lw/Np4FG4tYutOxT7AqpdTp0kC3un9qMknh/vz2/c0cOlLn6HKUUqrTNNCtfDzd+cc1Izh0tI6HP87SWRiVUr2OBvoJ0mKC+PWFg/liazEfbSxydDlKKdUpGuit3DFhECPigvn71zt10i6lVK+igd6Ku5twy7kDKKqsZfXug44uRymlbKaB3oaLhkYQ4OOhwxiVUr2KBnobfDzduTQ9moVZJdQcb3B0OUopZRMN9HbMGh1LbX0jX27VhaSVUr2DBno7RsUHMzC0j3a7KKV6DQ30dogIV46OZW1+BXsPHnF0OUop1SFbViyKE5ElIpItIttE5J422lwvIltEZKuIrBSR4V1Tbvf6yagYRODDDTomXSnV89lyh94A3GeMGQqMA+4WkaGt2uQD5xtjhgGPAXPtW6ZjRAX5cm5iKB9tLNQnR5VSPV6HgW6MKTbGbLB+Xw3kADGt2qw0xvy40vJqINbehTrK9GFR7KuoJae42tGlKKXUKXWqD11EEoCRwJpTNLsVWNjO+28XkUwRySwr6x2zGl4wJAIRWLStxNGlKKXUKdkc6CLiD3wI3GuMqWqnzSQsgf5gW9uNMXONMRnGmIywsLDTqbfbhQV4k9G/rwa6UqrHsynQRcQTS5i/aYxZ0E6bdOBFYKYxxqmemZ+aGsn2kmoKDh51dClKKdUuW0a5CPASkGOMeaqdNvHAAmC2MWanfUt0vKmpkYB2uyilejZb7tDPAWYDk0Vkk/VruojMEZE51jZ/AEKA56zbM7uqYEeI6+fH0KhAvtJAV0r1YB4dNTDGrACkgza3AbfZq6ieaGpqJE8v3smB6mOEB/g4uhyllDqJPilqo6lpERgD32SXOroUpZRqkwa6jZIjAugf4seibRroSqmeSQPdRiLCZenRLM8tY3tJm6M2lVLKoTTQO+G28wbg7+3Bk1/tcHQpSil1Eg30Tgj28+KuiYks3n6ANbo8nVKqh9FA76Sbz0kgMtCHxxdu1wm7lFI9igZ6J/l4uvPrC5PYtK9SHzRSSvUoGuin4cpRsSSG+/PEVzs43tDo6HKUUgrQQD8tHu5u/H76EPLLjzB36W5Hl6OUUoAG+mmblBLOJcOi+PeSPPaU6xJ1SinH00A/A3+4bCje7m48/HGWfkCqlHI4DfQzEBHowwPTklmRV84nm/Y7uhyllIvTQD9D143tz4i4YB79PJuiylpHl6OUcmEa6GfI3U3421Xp1Dc0cfPLazlcW+/okpRSLkoD3Q4SwwP4z+zR5JcfYc7r66lraHJ0SUopF6SBbidnJ4byxJXprNp9kAc/3KIfkiqlup0tS9DFicgSEckWkW0ick8bbURE/iUieSKyRURGdU25PdtPRsXymwsH89HGIj7fUuzocpRSLsaWO/QG4D5jzFBgHHC3iAxt1eZiIMn6dTvwvF2r7EXunpTI0KhAHv8yh9o6fYpUKdV9Ogx0Y0yxMWaD9ftqIAeIadVsJvCasVgNBItIlN2r7QXc3YT/nZHK/sPHeGHpLkeXo5RyIZ3qQxeRBGAksKbVphhg3wk/F3Jy6CMit4tIpohklpWVdbLU3uOsAf24ND2KF5buovDQUUeXo5RyETYHuoj4Ax8C9xpjTmvJHmPMXGNMhjEmIyws7HR20Ws8NH0IIvD4l9sdXYpSykXYFOgi4oklzN80xixoo0kREHfCz7HW11xWTLAvc84fxBdbi1m4VT8gVUp1PVtGuQjwEpBjjHmqnWafAjdYR7uMAw4bY1w+xeacP4gRccH85r3NbNt/uN1232SX6gNJSqkzZssd+jnAbGCyiGyyfk0XkTkiMsfa5ktgN5AHzAPu6ppyexcfT3fm3jCaYD9Pfv5qJgeqj53UZm1+BT9/LZNnvst1QIVKKWdiyyiXFcYYMcakG2NGWL++NMa8YIx5wdrGGGPuNsYMMsYMM8Zkdn3pvUN4gA/zbsjg0NF67nh9PcfqWw5lfHZJHgCfbt5PY5M+jKSUOn36pGg3SIsJ4u9XD2djQSV/W7Sj+fWsosMs3VnGyPhgSquOs1oXnlZKnQEN9G4yfVgUs8f158UV+azcVQ7Ac9/nEeDjwdzZGfh7e/DxRpf+HFkpdYY00LvRQ9NTGBjah/vf28zGgkMszCrhxvEJhAV4My0tkoVZJSd1ySillK000LuRn5cHT10zgtLq41w3bw3eHm7cfE4CAJePiKHmeAOLcw44tkilVK+lgd7NRsQF88vJidTWN3LtWfGE+HsDMH5QCOEB3ny8SbtdlFKnx8PRBbiiX0xKJLavHxelRjS/5u4mzBgezaur9lB5tI5gPy8HVqiU6o30Dt0BPNzdmDU6lkAfzxavXz4yhvpGw2ebdX1SpVTnaaD3IKnRgaTHBjFveT4NjbrqkVKqczTQexAR4ReTEimoOMonm/QuXSnVORroPcyFQyMYEhXIs0vy9MlRpVSnaKD3MCLCLycnsrv8CJ9v0bt0pZTtNNB7oGmpkSSF+/Pskjya9C5dKWUjDfQeyM1N+MXkRHaW1vD4whxW5JZzsOa4o8tSSvVwOg69h7o0PZq31xYwb3k+85bnA3DJsCj+cc0IvDz032Gl1Mk00HsodzfhndvHc7DmONtLqlmeW84LS3dxvKGRZ68fhbeHu6NLVEr1MHqr18OF+HtzTmIov7s4hcdmpvJtzgHufGMDxxt0Ei+lVEu2LEE3X0QOiEhWO9uDROQzEdksIttE5Gb7l6kAZo9P4E+Xp/Hd9gM8/FGbl0Mp5cJsuUN/BZh2iu13A9nGmOHARODvIqITkXSRn43rz01nJ/DRxiIOVJ28pJ1SynXZsgTdMqDiVE2AAOti0v7Wtg32KU+15aazE2hoMryzbl+L17ftP8xXWSUOqkop5Wj26EN/BhgC7Ae2AvcYY9qciEREbheRTBHJLCsrs8OhXVNCaB8mDA7jrTUFzXO+1Bxv4JZX1nH3WxvYV3G03ffWNTSxaV9lN1WqlOpO9gj0qcAmIBoYATwjIoFtNTTGzDXGZBhjMsLCwuxwaNc1e1x/SqqO8a11QYynv9nJgerjCDB32e523zdv+W6ueO4Hiipru6lSpVR3sUeg3wwsMBZ5QD6QYof9qlOYnBJOTLAvb6zey/aSKl5euYefjonnylGxvJe5j7Lqkx9EMsbwwfpCjIGc/VUOqFop1ZXsEegFwBQAEYkAkoH2bxGVXbi7CdeNjWdFXjm/ensjgT4ePDA1mTvOH0hdYxPzf8g/6T0bCg6RX34EgB2l1d1dslKqi9kybPFtYBWQLCKFInKriMwRkTnWJo8BZ4vIVmAx8KAxprzrSlY/ujojDk93YWdpDQ9dPIS+fbwYGObP9LQo3li1l6pj9S3af7C+CF9Pd8ICvNlRooGulLPp8ElRY8y1HWzfD1xkt4qUzcICvLnurHj2HDzKrNGxza/fOXEQX2wt5vVVe7l7UiIAx+ob+XzLfqalRVJVW6+BrpQT0kf/e7lHZqad9FpaTBATBocxd9luLhgSQXJkAN9kl1J9rIErR8Xyw65ylu4so66hSeeFUcqJ6P/NTurRGan4errz07mr2Lb/MB9uKCQqyIfxg0JIiQygock096crpZyDBrqTSgjtw7t3jMPX053r5q1h2c4yrhgZg7ubkBwZAMD2Eh3popQz0UB3Yv1D+vDuHeMJ8PGgycCV1n72gaH+eLiJ9qMr5WS0D93JxfXzY8GdZ7O9pJpBYf4AeHm4MTCsDzt16KJSTkXv0F1AeKAPEwa3fDI3OTKQ7e3coTc0NvHuugKKD+vTpEr1JhroLiolMoDCQ7XUHD95HrU31xTw4IdbmfL3pbywdBd1DW1OzaOU6mE00F3U4AjLB6Ot+9GrjtXz9Lc7Gd2/L2cPCuUvC7dz8T+XUXCw/Qm/lFI9gwa6i0qxjnRp3Y/+7JI8KmvreWRGKi/emMH8mzLYd6i2zakElFI9iwa6i4oJ9qWPl3uLO/R9FUd5+Yc9XDEyhrSYIAAmp0QwISmMRdtKaGoyjipXKWUDDXQX5eYmJEUEtBiL/uSiHQjw26nJLdpenBZJ8eFjbC6s7N4ilVKdooHuwlIiA9hRUs2GgkPc995mPt28n5+fN5CoIN8W7S4YEoGnu+hqSEr1cBroLiw5MoBDR+v5yXMr+SqrmNnj+nPXpEEntQvy8+TsQaEszCrBGO12Uaqn0geLXNiFQyP4Ie8gk1LCmDkiBn/v9v86XJwWye8WbCW7uIrU6KBurFIpZSu9Q3dhsX39ePHGDK4f2/+UYQ6W8HcTWLhVu12U6qk00JVNQvy9GTsghIVZxY4uRSnVDltWLJovIgdEJOsUbSaKyCYR2SYiS+1bouopLh4Wya6yI+S2Grve1GR46usdvLWmQPvYlXIgW+7QXwGmtbdRRIKB54AZxphU4Cq7VKZ6nKmpkbgJPPJZNtXW5e2MMTz8SRb/+i6P//loK7e/vp5DR+owxrA4p5SrXljJ7z/a6uDKlXINYssdlYgkAJ8bY05aHkdE7gKijTEPd+bAGRkZJjMzszNvUT3Ae+v28dBHWxkcEcDLN41h3vLdvLQinzsnDiLU35u/LMwh1N+bfn282La/Ci93N5qMIfPhCwj283J0+Ur1eiKy3hiT0dY2e/ShDwb6isj3IrJeRG44RSG3i0imiGSWlZXZ4dCqu109Jo75N42h4OARLnhqKS+tyOemsxN4YGoyt547gAV3noOvpztH6xp5clY679wxjoYmw9fbSh1dulJOzx536M8AGcAUwBdYBVxijNl5qn3qHXrvtm3/Yea8sZ7zB4fx6Iw03NykeVtTk0EERARjDOc/+T0JoX147Zaz7F5HU5PhzbUFzEiPJsjP0+77V6qn6eo79EJgkTHmiDGmHFgGDLfDflUPlhodxLLfTuJPlw9rEeZgmVZAxPKaiHBJehQ/5JVTcaSuuc3cZbuY9vQy5i3bzaETXm9Lec1xHlqwhfT/XUTegZoW21bnH+T/fZzFyyt18jCl7BHonwDnioiHiPgBY4EcO+xX9XA/hnZHLk2PorHJsGibZQz77rIa/rZoJ2XVx/nzlzmMe3wxf/gki8ZWk381NDbx4vLdTHrye97PLKT6eAOfbipq0ebb7AMAOi2BUtg2bPFtLN0oySJSKCK3isgcEZkDYIzJAb4CtgBrgReNMe0OcVSuZ2hUIANC+/D5lv0YY/jjp9vw9nBj4b3nsfCe85gxPJrXVu3l2SV5ze8xxvCHT7fxpy9yGNW/L1/dO4ExCf1YdEJfvDGGxdtL8XATtpdUk19+xBGnp1SP0WGgG2OuNcZEGWM8jTGxxpiXjDEvGGNeOKHNk8aYocaYNGPM011asep1RIRL06NYtesgb6wpYHluOb+5aDDhAT4MiQrkr7PSuXxENE9/u5PVuw8C8Prqvby1poA7zh/IKzePITHcn6mpkeworWaPNbh3ldWw9+BRfj5hINB1d+lNTYbjDY1dsm+l7EmfFFXd4pL0KJoM/OGTLIZEBTJ7XP/mbSLCn68YRkJoH3719kY+2VTEI59lc8GQcB6YmtLctTM1NQKguevmG2t3yw3j+5MeG8RXXfQU6/NLdzHpye9paNSl+FTPpoGuukVyRACJ4f4YA4/NTMXDveVfvT7eHjx73SgO19ZzzzubSAzz5+mfjsT9hA9cY/v6kRYT2Bzoi3NKSY0OJCrIl2lpkWwuPExRpf0Xtv46u5T9h4+xufCw3fetlD1poKtuISL8fvoQHpmRSkZCvzbbDIkK5PGfDCMlMoAXb8xoc8KwqUMj2VBQyfaSKjYUHGLKEMtd+7TUSAAW2bnbpfpYPVlFliBfkVtu130rZW8a6KrbTEoJ58azE07Z5iejYvnq3gnE9fNrc/vUNEtw//6jLJoMXGgN9IFh/iRHBPDVNvsG+ro9FTQ2GXw93VmRpw/DqZ5NA131Kknh/gwI7cP6vYeICPQmLSawedu0tEjW7amgrPq43Y63atdBvNzduG5sPBsKKpvnsFGqJ9JAV72KiDDV2r0yOSWixVj4i4dFYgw8812u3WZ9XL27gpHxwVwwJILGJsPq3RV22a9SXUEDXfU6lw2Pwt1NuCw9qsXryREB3DC+P6+u2svDH2fR1HRmoX64tp5t+w8zflAIo/oH4+vpzvJc7XZRPZcuQad6ndToIDb+4UICfVrO3SIiPDIjFV8vd/6zdHfzBGEnjqg5Vt/IG6v3crSukfGDQhgeG4yXR9v3NWvzK2gyMH5gCN4e7owb2E8/GFU9mga66pVah/mPRISHLh5CoI8nTy7awYaCQ/xsbH+uyohl5a6D/PmLHIoqaxGBp74BX093rh8bz+8vGXLSVAardh3E28ONEfHBAJybFMaSHdkUHjpKbN+2P7RVypE00JVTuntSIknh/sxbvps/f5nDX77aTmOTISUygHduH0dKZABr8itYuLWYF1fk4+XhxgPTUlrsY9Xug2Qk9MXbwx2ACUmhgGX44k/Pij+tujYWHGJodGDzPpWyJw105bQuSo3kotRIsvdXsWBDIQPC+nBNRlxzF8zU1EguGhqBn7cHz32/i1B/b245dwAAh47UkVNcxX0XDm7eX2K4PxGB3izPLSctJohvsksprTrGby4cTHigT4f17Cip5ornVnLnxEE82Oofj++2l5IUHtDucE2lbKGBrpze0OhAhkYPbXObiPDYzDQqaup49PNsausbGZPQj/xyyzS94weFtGh7XlIYH6wv5IutxYiAp5sbK/LKefWWsxgU5k9DYxPzf8jn7bX7eOFno0mODGh+/4INhQC8sWovd04c1NxtlL2/iltfzWRScjjzbxrTVX8MygVooCuX5+4mPP3TEdz66jqeXLSj+XVfT3fSY4NbtL1xfAKNTYbxg0KYkhJOUWUtt7yyjiufX8nDlwzllZX5ZBVVIQL/WbqLp64ZAUBjk+HjTUUkhfuTe6CG11ft5e5JiQA88dV2jIHvdxygqLKWmGDf7jp15WRsWrGoK+iKRaqnaWoyFB6qJf/gEfaUHyEm2JcLhkZ0+L6Cg0e5Yf4a9hw8Sqi/N4/OTGVtfgVvrtnLD7+bTHiAD8tzy5j90lqevW4U72buI3v/YVY8OJn1ew9x/YtruHF8f15bvZdfTU7i1yd08yjV2qlWLNI7dKWs3NyE+BA/4kP8OH9wmM3viw/x48M7z+azzfu5YmQsQX6eDIkK5NVVe3hjdQG/uXAwH20oIsDHgylDwgnx9+Knc1fz7rp9vL9+HzHBvjw0fQh7Dh7l3XX7+OXkxJMmL1M9R21dI4u3lzI9Leqk1bocTf/WKGUHIf7e3HTOgOZ1TQeE9mFycjhvrdnLoSN1LMwq4dL0KHw83Rk7oB+j4oP5vy9zyCqq4v6pg/HxdOfas+IpqTrG9zvafngpq+gw6/ce6s7TUm34bMt+fvHWRj7ZXNRx425my4pF80XkgIicchUiERkjIg0iMst+5SnVe91y7gDKa+r41Tsbqa1v5IqRsYDlw9W7JiZyvKGJoVGBzBweA8CUIeGEBXjz9tqCk/ZVdayeG+ev5dp5q9lSWNnpWsprjvOPb3byXuY+Nu2r5Mjxhg7fU3Wsnsw9Fby3bh9//Wo7CzYUnnIum3nLdvOfpbs6XVtvk1taDcA/vsmlrqFnzZFvS5fLK8AzwGvtNRARd+AJ4Gv7lKVU73f2oBCSIwJYnltObF9fMvr3bd42OSWcOycOavFru6e7G1dnxPL897vYX1lL9Akfjj67JI+DR+oIC/Bmzuvr+eyX5xLi721THU1Nhl+/u4nlJzzl6uXhxpOz0pk5IqbN92wtPMy181ZTYw1+ETDG8r5JyWHcd1EygyP+O4LnyPEGnvpmJw1NTcwcEUNkUMfDOO3pxeW7OX9wGEkn1NRV8g7U4OPpRkHFUd7L3MfPTlisxdFsWYJuGdDRjES/BD4EDtijKKWcgYhw8zkJAFwxMqZFf6ubm/DgtBSGxQa1eM9Px8RjgOe/39U8wVjBwaO8vGIPV46KZf6NYyg/Uscv395o8wpKr63aw/Lcch6dmcqS+yfyn9mjGREXzL3vbuK9dftOar+/spZbX11HkK8nL92YwdLfTmTnny7mwzvP5vqx8azadZAHP9zS4j2LtpVQW99IfaPhpRW7O/GndOaKKmv50xc53P/+ZrtNynYqeWU1XDAkgjEJffnX4lyO1fec5QnPuA9dRGKAK4DnbWh7u4hkikhmWZlOcqSc3xWjYvj1BYO5qYN54H8U18+P68fG8/rqvfzPR1tpaGzi8YU5uLsJD0xLZlhsEP93xTBW7jrIX08YYtmenaXVPL5wO5NTwpk9rj8DQvswNTWSV28+i/OSwnjgwy28unJPcxDWHG/g1lczOVrXyPybxjBlSAT9Q/rg6e7G6P59+eNlqfz6wsFsLKhk877K5uN8tLGI2L6+zBgezVtrCjh8tONphpfuLOPON9azcGsx9WewvN+6fMv95ubCw3y+pWuWIfzRsfpGCg/Vkhjuz/0XJXOg+jivrdrTpcfsDHuMcnkaeNAY09R6LozWjDFzgblgGbZoh2Mr1aN5e7hzzwVJnXrPYzPTCPb14pkleWQXV7N5XyW/uXAwEdanUWeNjmVjwSHmLtvNpOTwFg8/naiuoYl739mEv7cHT1yZ3mKuGl8vd+bdMJpfvLWRP366jX9/l8vQ6CCqj9Wzs7Sa+TeNafFQ1IlmjY7lb4t28OrKPTx1zQhKq47xQ145d09KZPqwKD7dvJ/XV+/hF5PbP+/Vuw9y+2uZNDYZFmaVEBbgzbVj4rjj/EH0aWOlqlNZt6eCAG8PYvr68tdF27koNaLLplbYVVaDMZanhscODGHC4DCeXbKLzYWHOXSkjtr6Rp64Mr1Fd1R3sscolwzgHRHZA8wCnhORy+2wX6Vckohw/9Rk/u+KYWwtrCQqyIefnzewRZvfXzKE/iF+PPDh5jY/4CyqrOWG+WvILq7iL1emExZwcn+7t4c7z10/ij9fkcbE5HDKqo+Td6CGx2amnXLYZoCPJ7NGx/L5lmLKa47z6ab9NBlLt9KQqEAmJYfx8g97qK1ruytiS2Elt72aSVw/P1Y9NIX5N2UwPDaIfy/JY9o/l7FyV+dmtFy3p4JR/fvy0PQh7Kuo5Y3VJ3+obC95ByxPECeG+wPwu2kp+Ht7kFNcRV1DE7mlNTz2eXaXHb8jZ3yHbowZ8OP3IvIK8Lkx5uMz3a9Sru66sfGkRgfSx9sdX6+Wd5x+Xh789cp0rpm7mie+2s6jM9Oat32yqah5Pvi/XTWcC0/xcJSnuxvXj+3P9WMtH+wZY06adbItN5ydwKur9vL2mgK+zCpheFwwA8MsIXfnxESu/s8q3l+/jxvGJ7R4X96BGm6cv5ZgP0/euHUsYQHeTE6JYHJKBOv2VPDb9zdz3bw1XD82nvsuSqZfH69T1nHoSB07S2uYOSKGCUmhnJsYyr+/y2XW6FiCfNuekfNM7DpQg5tYhqWCZVqJH343uXn7i8t386cvclieW8Z5SW3/o9jUZLps/LotwxbfBlYBySJSKCK3isgcEZnTJRUppZoNjwsmMbztX9/HDgzh5nMSeG3VXhZsKOTZJXlc8q/l3PPOJgZHBLDwngnMGh3bqePZEuYAg8L8OS8plLnLdpNTXMVPRv53tMyYhL6Mig/mP0t3n9Q3/ucvsjHAm7eNPWkkzJiEfiy8ZwK3nTuAt9YWMOGvS/jHNzupPlZPY5OhtOoYO0qqW3zwmWkdlz8moZ9l6uTpKRyurWf+ivxOnbet8spqiO/n126Xzuzx/Ynt68tfFm5vc4GV+sYmZr2wktdX7+2S+mwZ5XKtMSbKGONpjIk1xrxkjHnBGPNCG21vMsZ80CWVKqVO8sDUFBJC/PjNe5t5ctEOvDzceHRmKu/ePo74kK6dufHmcxKoPt6Ah5tw6QmrR4kId05MpKiyli9O+JAyt7SaJTvKuOWcAfQP6dPmPn293Hn40qF8fe8EzksK5Z+Lcxnz529JfnghY/9vMVOfXsa7J4zMWbenAi93N9Kto4VSo4MY078fi7eXdsk55x2oae5uaYu3hzv3X5TMtv1VfLp5/0nbn/9+FxsKKgnzP/VvHqdLH/1Xqhfz9XLnxRszWLW7gikp4S3Grne1iYPDSQz3Jync/6Qx8VNSwkkK9+eFpbuYOSIaEeHF5fn4eLrZNG47KSKA5382mq2Fh/lg/T78fTyIDPLl7TUFPL90F1dlxOHuJqzbU0F6bBA+nv+9Yz4vKZS/f7OTgzXHbR6rb4uGxibyy48wKSX8lO1mDI9m3vLdPLloB9PSIptryymu4t/f5XLZ8GimpUWdch+nSx/9V6qXSwwPYPa4/t0a5mAZS7/grrP5h3VGydbb5pw/iO0l1Xy/o4wD1cf4aGMRs0bHdtgvfqJhsUE8MjON305NYfa4/vxqShJ7Dx5lYVYxtXWNbC08zJgB/Vq8Z4L1A90VefZdLrCg4ij1jYbEsPbv0MFy7g9dPMTywfRLa9ldVkN9YxP3v7+ZIF9PHpmRate6Why7y/aslHJ6gT6eLe6OTzRjRDTRQT48//0uXl+1l/qmJm49d2CbbW110dAIBob14bklu9hYcIiGJsNZCS0DPS0miGA/T5bttG+gtx7hcirnJoXy5Kx0tpdUMe2fy7nllXVs21/Fny4f1ql/0DpLA10p1SU83d34+YSBrN1Twbzlu7lwSETz6JDT9eOdf3ZxFU9/m4sIjDphSgWwzG9/bmIoy3PLOnxytKGxiX0VR6k4UtfhsfPKLIE+yIZAB7gqI45vf3M+U1LCWZ5bzozh0UxLi7TpvadL+9CVUl3mmjFx/GtxLoeO1vPzCWd2d/6jy0fE8NTXO1m7p4IhUYFtDk+ckBTG51uK2VFaTUpk4Enbn12Sx1trCiipOkZjkyEi0JvF903E/xQPNeUdqCEi0LvdBcrbEh7ow/M/G01W0WGb7uzPlN6hK6W6jJ+XBw9dPIRrMuJaTE52Jrw83LjtPMvjL2MS2t7neYMtC3ovb6Pb5ZvsUp5ctIP4fn7cNXEQv7s4hdKq4/x7ce4pj7vrQA1J7Qwh7UhaTFC7XVP2pHfoSqkudfWYOK4eE2fXfV57Vjwr8sq5fGTbs0VGBfmSFO7PstyyFr8ZFB+u5bcfbCY1OpBXbhnTPJ58d1kN83/I5+oxcQyyfuiZVXSYVbsOcsPZ/fFyd2NX2ZFOj+vvbnqHrpTqdfp4e/DKzWcxKr79u/4Jg8NYk1/RPBtiY5Phnnc2Ud/QxDPXjWrxcNAD01Lw8XTnfz/dhjGGL7cWM+uFlfz5yxyufH4la/IrqDneYHP/uaNooCulnNJ5SaHUNTSxdGcZK3LL+e37m1mbX8Fjl6ed9OFsqL83v75gMMtzy7n7rQ3c9eYGhkYF8verhrOvopbr5q0G6HDIoqNpl4tSyimNHRCCl4cbd7y+HrCMfrnp7AR+MqrtbpPZ4/vzzroCvtxawuUjovnLlemWJQMH9uMXb20kp7iq3Rkoewrpjgnh25KRkWEyMzMdcmyllGt4fdUeCg/VMm5QCGMS+p1yFAtY+tK3Fh1mxvDoFvPaNDQ2cfBIXfMUxo4kIuuNMRltbdM7dKWU05rdarbHjgwM82+eNfJEHu5uPSLMO6J96Eop5SQ00JVSyklooCullJOwZYGL+SJyQESy2tl+vYhsEZGtIrJSRIbbv0yllFIdseUO/RVg2im25wPnG2OGAY9hXQRaKaVU9+pwlIsxZpmIJJxi+8oTflwN9OxnY5VSyknZuw/9VmChnfeplFLKBnYbhy4ik7AE+rmnaHM7cDtAfHy8vQ6tlFIKG58UtXa5fG6MSWtnezrwEXCxMWanTQcWKQNOd+nrUMC+y5H0Dq543q54zuCa5+2K5wydP+/+xpiwtjac8R26iMQDC4DZtoY5QHsF2XjMzPYefXVmrnjernjO4Jrn7YrnDPY97w4DXUTeBiYCoSJSCPwR8AQwxrwA/AEIAZ6zzn3Q4IoXRSmlHM2WUS7XdrD9NuA2u1WklFLqtPTWJ0Vdday7K563K54zuOZ5u+I5gx3P22HT5yqllLKv3nqHrpRSqhUNdKWUchK9LtBFZJqI7BCRPBH5naPr6QoiEiciS0QkW0S2icg91tf7icg3IpJr/W/7K+T2YiLiLiIbReRz688DRGSN9Zq/KyJejq7RnkQkWEQ+EJHtIpIjIuNd4VqLyK+tf7+zRORtEfFxxmvd1gSH7V1fsfiX9fy3iMiozhyrVwW6iLgDzwIXA0OBa0VkqGOr6hINwH3GmKHAOOBu63n+DlhsjEkCFlt/dkb3ADkn/PwE8A9jTCJwCMsTyc7kn8BXxpgUYDiWc3fqay0iMcCvgAzrA4vuwE9xzmv9CidPcNje9b0YSLJ+3Q4835kD9apAB84C8owxu40xdcA7wEwH12R3xphiY8wG6/fVWP4Hj8Fyrq9am70KXO6QAruQiMQClwAvWn8WYDLwgbWJU523iAQBE4CXAIwxdcaYSlzgWmMZNu0rIh6AH1CME15rY8wyoKLVy+1d35nAa8ZiNRAsIlG2Hqu3BXoMsO+Enwutrzkt67QLI4E1QIQxpti6qQSIcFRdXehp4AGgyfpzCFBpjGmw/uxs13wAUAa8bO1melFE+uDk19oYUwT8DSjAEuSHgfU497U+UXvX94wyrrcFuksREX/gQ+BeY0zViduMZbypU405FZFLgQPGmPWOrqUbeQCjgOeNMSOBI7TqXnHSa90Xy93oACAa6MOp111wWva8vr0t0IuAuBN+jrW+5nRExBNLmL9pjFlgfbn0x1+/rP894Kj6usg5wAwR2YOlO20ylv7lYOuv5eB817wQKDTGrLH+/AGWgHf2a30BkG+MKTPG1GOZD+ocnPtan6i963tGGdfbAn0dkGT9JNwLy4conzq4Jruz9hu/BOQYY546YdOnwI3W728EPunu2rqSMeYhY0ysMSYBy7X9zhhzPbAEmGVt5lTnbYwpAfaJSLL1pSlANk5+rbF0tYwTET/r3/cfz9tpr3Ur7V3fT4EbrKNdxgGHT+ia6Zgxpld9AdOBncAu4PeOrqeLzvFcLL+CbQE2Wb+mY+lPXgzkAt8C/Rxdaxf+GUzEMmUzwEBgLZAHvA94O7o+O5/rCCDTer0/Bvq6wrUGHgG2A1nA64C3M15r4G0snxPUY/mN7Nb2ri8gWEby7QK2YhkFZPOx9NF/pZRyEr2ty0UppVQ7NNCVUspJaKArpZST0EBXSiknoYGulFJOQgNdKaWchAa6Uko5if8PmbzyvXyOs+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_loss = 0\n",
    "all_losses_list = [] #为了后面画图用\n",
    "plot_steps, print_steps = 1000, 5000\n",
    "n_iters = 100000 #10000 个 epoch?\n",
    "\n",
    "for i in range(n_iters):\n",
    "    # category_lines is a category to name list map\n",
    "    category, name, category_tensor, name_tensor = random_training_example(category_lines, all_categories)\n",
    "    \n",
    "    output, loss = train_helper(name_tensor, category_tensor)\n",
    "    current_loss += loss \n",
    "    \n",
    "    if (i+1) % plot_steps == 0:\n",
    "        all_losses_list.append(current_loss / plot_steps)\n",
    "        current_loss = 0\n",
    "        \n",
    "    if (i+1) % print_steps == 0:\n",
    "        guess = category_from_output(output)\n",
    "        correct = \"CORRECT\" if guess == category else f\"WRONG ({category})\"\n",
    "        print(f\"{i+1} {(i+1)/n_iters*100} {loss:.4f} {name} / {guess} {correct}\")\n",
    "        \n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(all_losses_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6275b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 57.9\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation (自己写的，试一下..)\n",
    "\n",
    "total = 1000\n",
    "n_correct = 0\n",
    "for i in range(total):\n",
    "    with torch.no_grad():\n",
    "        category, name, category_tensor, name_tensor = random_training_example_with_split(category_lines, all_categories, True)\n",
    "\n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(name_tensor.size()[0]):\n",
    "            output, hidden = rnn(name_tensor[i], hidden)\n",
    "\n",
    "        guess = category_from_output(output[0])\n",
    "        \n",
    "#         print(f'name {name} guess {guess}, category {category}')\n",
    "        if(category == guess):\n",
    "            n_correct+=1\n",
    "            \n",
    "\n",
    "print(f'Accuracy {100 * n_correct / total}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc3df3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line):\n",
    "    print(f\"\\n> {input_line}\")\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "        guess = category_from_output(output)\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5f42628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Ashley\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "predict(\"Ashley\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d10bc6",
   "metadata": {},
   "source": [
    "----------------------\n",
    "----------------------\n",
    "\n",
    "### PyTorch Tutorial - RNN & LSTM & GRU - Recurrent Neural Nets\n",
    "\n",
    "https://www.youtube.com/watch?v=0_PgWWmauHk&list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4&index=20\n",
    "\n",
    "他这里很骚的非得 RNN 来做 image classification: We treat one image dim as sequence and the other as dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f955f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 784 # 28x28\n",
    "num_classes = 10 # 10 个数字 0->9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# We treat one image dim as sequence and the other as dimensions\n",
    "# 因为 picture 是 28x28\n",
    "input_size = 28 \n",
    "sequence_length = 28\n",
    "\n",
    "hidden_size = 128\n",
    "# RNN 的 layer 不懂啥意思。。 可能就是两层 hidden layer\n",
    "#  input -> hidden1 (self loop) -> hidden2 (self loop) -> output (linear+softmax)\n",
    "# \"setting num_layers=2 would mean stacking two RNNs together to form a stacked RNN, with\n",
    "# the second RNN taking in outputs of the first RNN and computing the final results\"\n",
    "num_layers = 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb5925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8dde173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # batch_first=True means  input and output tensors are \n",
    "        # provided as (batch, seq, feature) instead of (seq, batch, feature).\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        # Question： 为啥 hidden0 是这个 shape?? 2 x ? x 128  x.size(0) 是 batch size? 100?? what??\n",
    "        # Answer: \n",
    "        #  h0 是 initialized hidden state, 0 这里表示是 time (initial) 而不是第0 层\n",
    "        #  根据官方文档, hidden laysers initial state 就是\n",
    "        #   （D * number_layers, batch_size, hidden_size)\n",
    "        #     D=2 if bidirectional=True otherwise 1\n",
    "        # ref: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html \n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        #我的 input 长这样： x: (n, 28, 28), h0: (2, n, 128)，  n 这里是 batch_size 即一次多少个 training sample\n",
    "        \n",
    "        # Output: 即 每个 h_t (t from 0-> seq_len) 都给你, 所以是 (batch_size, seq_len, hidden_size) ， \n",
    "        #    这里 t 的长度，对应的是 seq_len, 那么在我们这个例子里，就是 28 , 因为我们把图的一个 dim 作为 seq_len, 另一个 dim 作为 input_size\n",
    "        # H_n: 即 给你 每个 batch 的最后一个 t 的 hidden state (比如两层 RNN 就两个 hidden state 都给你） ，\n",
    "        #    所以 dim 是 (num_layers, batch_size, output_size)\n",
    "        # 所以其实最后算 output 两个方法都可以\n",
    "        out, h_n = self.rnn(x, h0)\n",
    "        \n",
    "        \n",
    "        # Question: 这里为啥不能用 h_n? Answer: 试了一下就是可以\n",
    "        # h_n: (2, n, 128) but we want n, 128\n",
    "        # 拿最终 h_t 的 output 的写法1\n",
    "        # output shape: (num_layers, batch_size, output_size)\n",
    "        out = h_n[-1, :, :]\n",
    "        \n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        # 拿最终 h_t 的 output 的写法2:\n",
    "        # tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        # out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "         \n",
    "        out = self.fc(out)\n",
    "        # out: (n, 10)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a8d6302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 1.0107\n",
      "Epoch [1/2], Step [200/600], Loss: 0.7195\n",
      "Epoch [1/2], Step [300/600], Loss: 0.3752\n",
      "Epoch [1/2], Step [400/600], Loss: 0.4237\n",
      "Epoch [1/2], Step [500/600], Loss: 0.2348\n",
      "Epoch [1/2], Step [600/600], Loss: 0.2227\n",
      "Epoch [2/2], Step [100/600], Loss: 0.3031\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1686\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1467\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1627\n",
      "Epoch [2/2], Step [500/600], Loss: 0.2621\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1903\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "# Training loop 跟之前 CNN 是一样\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [N, 1, 28, 28]\n",
    "        # resized: [N, 28, 28]\n",
    "        # Question: 诶？？这边 reshape 跟之前还不太一样...  之前是 images = images.reshape(-1, 28*28).to(device)\n",
    "        # Answer: 哦，因为我之前是 CNN 的例子，这里是 RNN, 而且我 input 期待的就是 x: (n, 28, 28), batch_size x seq_len x input_feature_len 这么用\n",
    "        # 然后这里 -1 是一个 reshape 的默认计算，而不是指倒数第一个\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c632a3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93.83 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
